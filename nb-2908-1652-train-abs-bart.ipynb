{"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9040667,"sourceType":"datasetVersion","datasetId":5430249}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"09513166db494a318fe4bd2ff4fe8b73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bad09d132dcc420fbad7ace8cc25aa06","placeholder":"​","style":"IPY_MODEL_20787ae61e94452aae73869c5382ff1b","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"19649549a1ad47368ec9f6eeba1e80ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20787ae61e94452aae73869c5382ff1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25bd97f157d8485fb15438d25d83421c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c792771c4604d9b8f6bcda700f2ad74","placeholder":"​","style":"IPY_MODEL_36781c62f1164acabc7371ceb966e8cc","value":"Token is valid (permission: write)."}},"26b0af06bf1549bd8f16e297a3d5c4fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34efbeb9bdcf42b28bcfdf48289bb943":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36781c62f1164acabc7371ceb966e8cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3bd1b8a5cbdf4345b34a6042ad3c6383":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d0bb7ba88104e458caaaf9c72914b97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44d30b0ecad54f818f27bbd1858cdf3f","placeholder":"​","style":"IPY_MODEL_85e73a9905ba41c286b0645f0c667362","value":"Login successful"}},"44d30b0ecad54f818f27bbd1858cdf3f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5685a3fe6b084791b1c41bede0ee8429":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5764ccc3c9b943ac9031bb4fbf65ee84":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dcb4bd1b7424f698dcfe1586ecaaa87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7393008614c94b7f9aee294715d1f9c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6eb7b2e427a4fb3b984a0346394555a","placeholder":"​","style":"IPY_MODEL_34efbeb9bdcf42b28bcfdf48289bb943","value":"Your token has been saved in your configured git credential helpers (store)."}},"7b5d107e75ec4226b2f951fa5eac32c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"85e73a9905ba41c286b0645f0c667362":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c792771c4604d9b8f6bcda700f2ad74":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91cf6c949361472e8cdc02a27371892b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"PasswordModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_5764ccc3c9b943ac9031bb4fbf65ee84","placeholder":"​","style":"IPY_MODEL_f6f5badeb1f749d8a1a74c737ea45b81","value":""}},"9d286f232614404eac3e78415a823171":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26b0af06bf1549bd8f16e297a3d5c4fa","placeholder":"​","style":"IPY_MODEL_b289ce6929414af38bd4cd4ddf68bfe4","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"a6333daeaf584192b2d8222134dc02a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb0ffca70a4645458b4650ff588f82cc","placeholder":"​","style":"IPY_MODEL_fec956e2f3ac4760a951569986ebb5c2","value":"Your token has been saved to /root/.cache/huggingface/token"}},"b289ce6929414af38bd4cd4ddf68bfe4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b292b711914d4f14abd2436aeb8050f8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3bfd48d65b748349afd7e3e5000baff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"b6eb7b2e427a4fb3b984a0346394555a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bad09d132dcc420fbad7ace8cc25aa06":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcab8a3e3c3f45d48890e88d50d8e982":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_b292b711914d4f14abd2436aeb8050f8","style":"IPY_MODEL_b3bfd48d65b748349afd7e3e5000baff","tooltip":""}},"c42b74a51b7843c7b8a9fca7d90bfd1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19649549a1ad47368ec9f6eeba1e80ff","placeholder":"​","style":"IPY_MODEL_3bd1b8a5cbdf4345b34a6042ad3c6383","value":"Connecting..."}},"d1a558c379ac48cc80c19ef9898d871d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_25bd97f157d8485fb15438d25d83421c","IPY_MODEL_7393008614c94b7f9aee294715d1f9c8","IPY_MODEL_a6333daeaf584192b2d8222134dc02a9","IPY_MODEL_3d0bb7ba88104e458caaaf9c72914b97"],"layout":"IPY_MODEL_7b5d107e75ec4226b2f951fa5eac32c7"}},"dbbfbb222a7d4ce18c1c7b655fc89ae1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"CheckboxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_5685a3fe6b084791b1c41bede0ee8429","style":"IPY_MODEL_6dcb4bd1b7424f698dcfe1586ecaaa87","value":true}},"f6f5badeb1f749d8a1a74c737ea45b81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb0ffca70a4645458b4650ff588f82cc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fec956e2f3ac4760a951569986ebb5c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Abstractive summaries - Train DistilBART on TWEETSUMM dataset","metadata":{"id":"AvCot6IFw3LG"}},{"cell_type":"code","source":"import json, re\nfrom huggingface_hub import notebook_login\nimport pandas as pd\nimport numpy as np\nimport os, time, datetime\n\ntry:\n    from datasets import load_dataset, Dataset, DatasetDict\nexcept:\n    !pip install datasets\n    from datasets import load_dataset, Dataset, DatasetDict\n\ntry:\n    import accelerate\nexcept:\n    !pip install -U 'accelerate==0.27.2'\n    import accelerate\n\n\nimport transformers\nfrom transformers import AutoTokenizer, DataCollatorForSeq2Seq, pipeline, set_seed, BartTokenizer\nfrom transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, BartForConditionalGeneration\nfrom transformers import GenerationConfig\n\ntry:\n    import wandb\nexcept:\n    !pip install wandb\n\nprint(transformers.__version__, accelerate.__version__)\n","metadata":{"id":"csIsnw2147iB","outputId":"b1168797-2e98-4a6a-81e1-9e079f98ab53","scrolled":true,"execution":{"iopub.status.busy":"2024-08-29T14:22:57.949031Z","iopub.execute_input":"2024-08-29T14:22:57.949573Z","iopub.status.idle":"2024-08-29T14:22:57.971025Z","shell.execute_reply.started":"2024-08-29T14:22:57.949527Z","shell.execute_reply":"2024-08-29T14:22:57.969853Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"4.44.0 0.33.0\n","output_type":"stream"}]},{"cell_type":"code","source":"ds_dir = \"\"\ntry:\n    HF_TOKEN =  os.environ['HF_TOKEN']\nexcept:\n    HF_TOKEN = \"\"\n\nif 'google.colab' in str(get_ipython()):\n    print(\"Running on Colab\")\n    from google.colab import drive, userdata\n    drive.mount('/content/drive')\n    HF_TOKEN = userdata.get('HF_TOKEN')\nelif os.environ['KAGGLE_KERNEL_RUN_TYPE']:\n    from kaggle_secrets import UserSecretsClient\n    print(\"Running on Kaggle\")\n    ds_dir = \"/kaggle/input/tweet-data-2106-1512/\"\n    user_secrets = UserSecretsClient()\n    HF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")\n    WANDB_API_KEY = user_secrets.get_secret(\"WANDB_API_KEY\")\n    os.environ['WANDB_API_KEY'] = WANDB_API_KEY\n","metadata":{"id":"D7StYsAaxJLT","outputId":"3690cf47-554a-424d-b42e-e8f77bb4bbf5","execution":{"iopub.status.busy":"2024-08-29T14:22:57.973370Z","iopub.execute_input":"2024-08-29T14:22:57.973732Z","iopub.status.idle":"2024-08-29T14:22:58.200549Z","shell.execute_reply.started":"2024-08-29T14:22:57.973694Z","shell.execute_reply":"2024-08-29T14:22:58.199294Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Running on Kaggle\n","output_type":"stream"}]},{"cell_type":"code","source":"set_seed(17)\n\nos.environ[\"WANDB_PROJECT\"] = \"aiml-thesis-train\"\nwandb.init(settings=wandb.Settings(start_method=\"thread\"))","metadata":{"id":"XCVrFPA4GL-h","outputId":"228dbbaf-c276-495e-e759-0ecb0b4a1ebb","scrolled":true,"execution":{"iopub.status.busy":"2024-08-29T14:22:58.201963Z","iopub.execute_input":"2024-08-29T14:22:58.202360Z","iopub.status.idle":"2024-08-29T14:23:18.570044Z","shell.execute_reply.started":"2024-08-29T14:22:58.202322Z","shell.execute_reply":"2024-08-29T14:23:18.568945Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:e5p0j626) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.032 MB of 0.032 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">snowy-galaxy-31</strong> at: <a href='https://wandb.ai/dawidk5ul/aiml-thesis-train/runs/e5p0j626' target=\"_blank\">https://wandb.ai/dawidk5ul/aiml-thesis-train/runs/e5p0j626</a><br/> View project at: <a href='https://wandb.ai/dawidk5ul/aiml-thesis-train' target=\"_blank\">https://wandb.ai/dawidk5ul/aiml-thesis-train</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240829_134929-e5p0j626/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:e5p0j626). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.8 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240829_142258-jox21ycj</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dawidk5ul/aiml-thesis-train/runs/jox21ycj' target=\"_blank\">lucky-sky-32</a></strong> to <a href='https://wandb.ai/dawidk5ul/aiml-thesis-train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dawidk5ul/aiml-thesis-train' target=\"_blank\">https://wandb.ai/dawidk5ul/aiml-thesis-train</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dawidk5ul/aiml-thesis-train/runs/jox21ycj' target=\"_blank\">https://wandb.ai/dawidk5ul/aiml-thesis-train/runs/jox21ycj</a>"},"metadata":{}},{"execution_count":30,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dawidk5ul/aiml-thesis-train/runs/jox21ycj?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x790ccb25eef0>"},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token=HF_TOKEN)","metadata":{"id":"QoMm76b2i2NX","outputId":"f5df06b4-ac4d-4be9-8044-20010745149b","execution":{"iopub.status.busy":"2024-08-29T14:23:18.572269Z","iopub.execute_input":"2024-08-29T14:23:18.572625Z","iopub.status.idle":"2024-08-29T14:23:18.694984Z","shell.execute_reply.started":"2024-08-29T14:23:18.572587Z","shell.execute_reply":"2024-08-29T14:23:18.693921Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load data","metadata":{"id":"xP2HgEaKi2Nk"}},{"cell_type":"code","source":"ds_dir=\"/kaggle/input/bertdata2207/\"\ncheckpoint_bart = \"sshleifer/distilbart-xsum-12-6\"","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:23:18.696752Z","iopub.execute_input":"2024-08-29T14:23:18.697716Z","iopub.status.idle":"2024-08-29T14:23:18.702586Z","shell.execute_reply.started":"2024-08-29T14:23:18.697660Z","shell.execute_reply":"2024-08-29T14:23:18.701349Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"train_df_temp = pd.read_csv(ds_dir + f\"dials_abs_2607_1312_train_spc.csv\", names=['conv_id','dialogue','summary'], encoding='utf-8', dtype={'conv_id':'string', 'dialogue':'string', 'summary': 'string'})\ntrain_df_temp.convert_dtypes()\ntrain_df_temp.drop(columns=['conv_id'], inplace=True)\ntrain_df_temp.reset_index(drop=True, inplace=True)\n\nval_df_temp = pd.read_csv(ds_dir + \"dials_abs_2607_1312_valid_spc.csv\", names=['conv_id','dialogue','summary'], encoding='utf-8', dtype={'conv_id':'string', 'dialogue':'string', 'summary': 'string'})\nval_df_temp.convert_dtypes()\nval_df_temp.drop(columns=['conv_id'], inplace=True)\nval_df_temp.reset_index(drop=True, inplace=True)\n\ntest_df_temp = pd.read_csv(ds_dir + \"dials_abs_2607_1312_test_spc.csv\", names=['conv_id','dialogue','summary'], encoding='utf-8', dtype={'conv_id':'string', 'dialogue':'string', 'summary': 'string'})\ntest_df_temp.convert_dtypes()\n# test_df_temp.drop(columns=['conv_id'], inplace=True)\ntest_df_temp.reset_index(drop=True, inplace=True)\n\nprint(train_df_temp.dtypes)\nprint(train_df_temp.head())","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:23:18.703945Z","iopub.execute_input":"2024-08-29T14:23:18.704320Z","iopub.status.idle":"2024-08-29T14:23:18.766427Z","shell.execute_reply.started":"2024-08-29T14:23:18.704283Z","shell.execute_reply":"2024-08-29T14:23:18.765337Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"dialogue    string[python]\nsummary     string[python]\ndtype: object\n                                            dialogue  \\\n0  Customer: So neither my iPhone nor my Apple Wa...   \n1  Customer: @115850 hi team! i m planning to get...   \n2  Customer: @AskAmex Where do I write to address...   \n3  Customer: @AmazonHelp @115821 Wow, expected 4 ...   \n4  Customer: @GWRHelp I'd rather you spent some t...   \n\n                                             summary  \n0  Customer enquired about his Iphone and Apple w...  \n1  Customer is eager to know about the replacemen...  \n2  Signed up for an AmexCard with Delta but it di...  \n3  The customer have a problem. The agent is very...  \n4  Customer cannot purchase a train ticket on the...  \n","output_type":"stream"}]},{"cell_type":"code","source":"tweetsumm_abs = DatasetDict(\n    {\n        'train': Dataset.from_pandas(train_df_temp),\n        'validation': Dataset.from_pandas(val_df_temp),\n        'test': Dataset.from_pandas(test_df_temp)\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:23:18.767965Z","iopub.execute_input":"2024-08-29T14:23:18.768471Z","iopub.status.idle":"2024-08-29T14:23:18.807467Z","shell.execute_reply.started":"2024-08-29T14:23:18.768418Z","shell.execute_reply":"2024-08-29T14:23:18.806249Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"bart_tokenizer = BartTokenizer.from_pretrained(checkpoint_bart)\ntokenizer = bart_tokenizer","metadata":{"id":"F-hzIHQ9w3Lb","execution":{"iopub.status.busy":"2024-08-29T14:23:18.808807Z","iopub.execute_input":"2024-08-29T14:23:18.809221Z","iopub.status.idle":"2024-08-29T14:23:18.973871Z","shell.execute_reply.started":"2024-08-29T14:23:18.809164Z","shell.execute_reply":"2024-08-29T14:23:18.972875Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# arrr = [0,1,2,3,4,5,6,7]\n# valsss = ['a','b','c','d','e','f','g','h']\n\n# kwkwk = {f\"id-{x}\": vall for x, vall in enumerate(valsss)}\n# origindict = {'alpha':5, **kwkwk}\n# print(origindict)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:23:18.975009Z","iopub.execute_input":"2024-08-29T14:23:18.975330Z","iopub.status.idle":"2024-08-29T14:23:18.980384Z","shell.execute_reply.started":"2024-08-29T14:23:18.975295Z","shell.execute_reply":"2024-08-29T14:23:18.979120Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Source: https://huggingface.co/docs/transformers/en/tasks/summarization\n\ndef preprocess_function(examples):\n    prefix = \"summarize: \"\n    inputs = [str(prefix) + str(dial) for dial in examples[\"dialogue\"]]\n    model_inputs = tokenizer(inputs, max_length=512, truncation=True) # same params as tweetsumm paper\n    labels = tokenizer(text_target=examples[\"summary\"], max_length=80, truncation=True)\n    # print(inputs, model_inputs['input_ids'])\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"id":"vVQdGPfZw3Lb","execution":{"iopub.status.busy":"2024-08-29T14:23:18.987724Z","iopub.execute_input":"2024-08-29T14:23:18.988101Z","iopub.status.idle":"2024-08-29T14:23:18.995183Z","shell.execute_reply.started":"2024-08-29T14:23:18.988061Z","shell.execute_reply":"2024-08-29T14:23:18.994046Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# encc = bart_tokenizer.encode_plus(\"qwerty Q.\\nQwerty Q. \\n Qwerty x.\") # train_df_temp.iloc[5,0][:320])\n# print(encc)\n# print(bart_tokenizer.decode(encc['input_ids'], skip_special_tokens=False))\n# for i in sorted(set(encc['input_ids'])):\n#     print(i, repr(bart_tokenizer.decode(i, skip_special_tokens=False)))\n# tokenizer = bart_tokenizer\n# tokenized_tweetsumm_abs = tweetsum_train_val_abs.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:23:18.996729Z","iopub.execute_input":"2024-08-29T14:23:18.997223Z","iopub.status.idle":"2024-08-29T14:23:19.006320Z","shell.execute_reply.started":"2024-08-29T14:23:18.997162Z","shell.execute_reply":"2024-08-29T14:23:19.005212Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"tokenized_tweetsumm_abs = tweetsumm_abs.map(preprocess_function, batched=True)\nprint(tokenized_tweetsumm_abs[\"train\"][0])","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:23:19.007474Z","iopub.execute_input":"2024-08-29T14:23:19.007823Z","iopub.status.idle":"2024-08-29T14:23:32.197656Z","shell.execute_reply.started":"2024-08-29T14:23:19.007768Z","shell.execute_reply":"2024-08-29T14:23:32.196591Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/867 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca1648ef382346648a1d182f6c38a38c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/110 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71f951def4c34e63b7c83636f6e8dd95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/109 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d109dcf2bd3c4329811c5055bea48a7e"}},"metadata":{}},{"name":"stdout","text":"{'dialogue': 'Customer: So neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesn’t recognise either source anymore for some reason. Any ideas? https://t.co/m9DPQbkftD\\nCustomer: @AppleSupport please read the above.\\nAgent: @135060 Let’s investigate this together. To start, can you tell us the software versions your iPhone and Apple Watch are running currently?\\nCustomer: @AppleSupport My iPhone is on 11.1.2, and my watch is on 4.1.\\nAgent: @135060 Thank you. Have you tried restarting both devices since this started happening?\\nCustomer: @AppleSupport I’ve restarted both, also un-paired then re-paired the watch.\\nAgent: @135060 Got it. When did you first notice that the two devices were not talking to each other. Do the two devices communicate through other apps such as Messages?\\nCustomer: @AppleSupport Yes, everything seems fine, it’s just Health and activity.\\nAgent: @135060 Let’s move to DM and look into this a bit more. When reaching out in DM, let us know when this first started happening please. For example, did it start after an update or after installing a certain app? https://t.co/GDrqU22YpT', 'summary': 'Customer enquired about his Iphone and Apple watch which is not showing his any steps/activity and health activities. Agent is asking to move to DM and look into it.', 'input_ids': [0, 18581, 3916, 2072, 35, 19458, 35, 407, 5063, 127, 2733, 3486, 127, 1257, 3075, 32, 5492, 127, 2402, 73, 30280, 6, 8, 1309, 630, 17, 27, 90, 11865, 1169, 1300, 5988, 13, 103, 1219, 4, 5053, 2956, 116, 1205, 640, 90, 4, 876, 73, 119, 466, 5174, 1864, 428, 330, 2543, 495, 50118, 44799, 35, 787, 20770, 38873, 2540, 1166, 5, 1065, 4, 50118, 45443, 35, 787, 1558, 1096, 2466, 2780, 17, 27, 29, 4830, 42, 561, 4, 598, 386, 6, 64, 47, 1137, 201, 5, 2257, 7952, 110, 2733, 8, 1257, 3075, 32, 878, 855, 116, 50118, 44799, 35, 787, 20770, 38873, 1308, 2733, 16, 15, 365, 4, 134, 4, 176, 6, 8, 127, 1183, 16, 15, 204, 4, 134, 4, 50118, 45443, 35, 787, 1558, 1096, 2466, 3837, 47, 4, 6319, 47, 1381, 12721, 154, 258, 2110, 187, 42, 554, 2909, 116, 50118, 44799, 35, 787, 20770, 38873, 38, 17, 27, 548, 12721, 196, 258, 6, 67, 542, 12, 6709, 7651, 172, 769, 12, 6709, 7651, 5, 1183, 4, 50118, 45443, 35, 787, 1558, 1096, 2466, 8432, 24, 4, 520, 222, 47, 78, 3120, 14, 5, 80, 2110, 58, 45, 1686, 7, 349, 97, 4, 1832, 5, 80, 2110, 8469, 149, 97, 3798, 215, 25, 34692, 116, 50118, 44799, 35, 787, 20770, 38873, 3216, 6, 960, 1302, 2051, 6, 24, 17, 27, 29, 95, 1309, 8, 1940, 4, 50118, 45443, 35, 787, 1558, 1096, 2466, 2780, 17, 27, 29, 517, 7, 18695, 8, 356, 88, 42, 10, 828, 55, 4, 520, 3970, 66, 11, 18695, 6, 905, 201, 216, 77, 42, 78, 554, 2909, 2540, 4, 286, 1246, 6, 222, 24, 386, 71, 41, 2935, 50, 71, 15602, 10, 1402, 1553, 116, 1205, 640, 90, 4, 876, 73, 534, 14043, 1343, 791, 2036, 975, 642, 565, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [0, 44799, 17730, 7651, 59, 39, 38, 17283, 8, 1257, 1183, 61, 16, 45, 2018, 39, 143, 2402, 73, 30280, 8, 474, 1713, 4, 18497, 16, 1996, 7, 517, 7, 18695, 8, 356, 88, 24, 4, 2]}\n","output_type":"stream"}]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint_bart)","metadata":{"id":"irJUvr6gi2No","execution":{"iopub.status.busy":"2024-08-29T14:23:32.198983Z","iopub.execute_input":"2024-08-29T14:23:32.199372Z","iopub.status.idle":"2024-08-29T14:23:32.218598Z","shell.execute_reply.started":"2024-08-29T14:23:32.199333Z","shell.execute_reply":"2024-08-29T14:23:32.217466Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"## Setup Training Evaluation","metadata":{"id":"97ha331Ii2Np"}},{"cell_type":"code","source":"try:\n    import evaluate\n    rouge = evaluate.load(\"rouge\")\n    meteor = evaluate.load(\"meteor\")\n    bertscore = evaluate.load(\"bertscore\")\nexcept:\n    !pip install evaluate nltk rouge_score bert_score\n    import evaluate\n    rouge = evaluate.load(\"rouge\")\n    meteor = evaluate.load(\"meteor\")\n    bertscore = evaluate.load(\"bertscore\")","metadata":{"id":"dHQv7Aeai2Nr","outputId":"6c4222bd-bf8f-4588-9871-716bd2cee0ca","scrolled":true,"execution":{"iopub.status.busy":"2024-08-29T14:23:32.220191Z","iopub.execute_input":"2024-08-29T14:23:32.220649Z","iopub.status.idle":"2024-08-29T14:23:33.262246Z","shell.execute_reply.started":"2024-08-29T14:23:32.220598Z","shell.execute_reply":"2024-08-29T14:23:33.261278Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"def compute_metrics_abs(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    rouge_scores = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n    bert_scores = bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")\n    bert_scores.pop('hashcode')\n    result = {\n      **{f\"rouge/{k}\": round(v, 4) for k,v in rouge_scores.items()},\n      **{f\"bertscore/bertscore-{k}\": round(np.mean(v), 4) for k,v in bert_scores.items()},\n      'meteor': round(meteor.compute(predictions=decoded_preds, references=decoded_labels)['meteor'], 4),\n    }\n    predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    return result\n","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:23:33.271187Z","iopub.execute_input":"2024-08-29T14:23:33.271507Z","iopub.status.idle":"2024-08-29T14:23:33.282650Z","shell.execute_reply.started":"2024-08-29T14:23:33.271472Z","shell.execute_reply":"2024-08-29T14:23:33.281622Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"test_eval_data = {'input_ids': [0, 18581, 3916, 2072, 35, 19458, 35, 407, 5063, 127, 2733, 3486, 127, 1257, 3075, 32, 5492, 127, 2402, 73, 30280, 6, 8, 1309, 630, 17, 27, 90, 11865, 1169, 1300, 5988, 13, 103, 1219, 4, 5053, 2956, 116, 1205, 640, 90, 4, 876, 73, 119, 466, 5174, 1864, 428, 330, 2543, 495, 50118, 44799, 35, 787, 20770, 38873, 2540, 1166, 5, 1065, 4, 50118, 45443, 35, 787, 1558, 1096, 2466, 2780, 17, 27, 29, 4830, 42, 561, 4, 598, 386, 6, 64, 47, 1137, 201, 5, 2257, 7952, 110, 2733, 8, 1257, 3075, 32, 878, 855, 116, 50118, 44799, 35, 787, 20770, 38873, 1308, 2733, 16, 15, 365, 4, 134, 4, 176, 6, 8, 127, 1183, 16, 15, 204, 4, 134, 4, 50118, 45443, 35, 787, 1558, 1096, 2466, 3837, 47, 4, 6319, 47, 1381, 12721, 154, 258, 2110, 187, 42, 554, 2909, 116, 50118, 44799, 35, 787, 20770, 38873, 38, 17, 27, 548, 12721, 196, 258, 6, 67, 542, 12, 6709, 7651, 172, 769, 12, 6709, 7651, 5, 1183, 4, 50118, 45443, 35, 787, 1558, 1096, 2466, 8432, 24, 4, 520, 222, 47, 78, 3120, 14, 5, 80, 2110, 58, 45, 1686, 7, 349, 97, 4, 1832, 5, 80, 2110, 8469, 149, 97, 3798, 215, 25, 34692, 116, 50118, 44799, 35, 787, 20770, 38873, 3216, 6, 960, 1302, 2051, 6, 24, 17, 27, 29, 95, 1309, 8, 1940, 4, 50118, 45443, 35, 787, 1558, 1096, 2466, 2780, 17, 27, 29, 517, 7, 18695, 8, 356, 88, 42, 10, 828, 55, 4, 520, 3970, 66, 11, 18695, 6, 905, 201, 216, 77, 42, 78, 554, 2909, 2540, 4, 286, 1246, 6, 222, 24, 386, 71, 41, 2935, 50, 71, 15602, 10, 1402, 1553, 116, 1205, 640, 90, 4, 876, 73, 534, 14043, 1343, 791, 2036, 975, 642, 565, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [0, 44799, 17730, 7651, 59, 39, 38, 17283, 8, 1257, 1183, 61, 16, 45, 2018, 39, 143, 2402, 73, 30280, 8, 474, 1713, 4, 18497, 16, 1996, 7, 517, 7, 18695, 8, 356, 88, 24, 4, 2]}\n","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:46:19.493650Z","iopub.execute_input":"2024-08-29T14:46:19.494099Z","iopub.status.idle":"2024-08-29T14:46:19.524491Z","shell.execute_reply.started":"2024-08-29T14:46:19.494045Z","shell.execute_reply":"2024-08-29T14:46:19.523308Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"data_collator","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:31:38.927738Z","iopub.execute_input":"2024-08-29T14:31:38.928613Z","iopub.status.idle":"2024-08-29T14:31:38.935503Z","shell.execute_reply.started":"2024-08-29T14:31:38.928569Z","shell.execute_reply":"2024-08-29T14:31:38.934366Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"DataCollatorForSeq2Seq(tokenizer=BartTokenizer(name_or_path='sshleifer/distilbart-xsum-12-6', vocab_size=50265, model_max_length=1024, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}, model='sshleifer/distilbart-xsum-12-6', padding=True, max_length=None, pad_to_multiple_of=None, label_pad_token_id=-100, return_tensors='pt')"},"metadata":{}}]},{"cell_type":"code","source":"data_collator([te_tokenised_batch])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for sample in tweetsumm_abs['train'].select(range(17,54))['dialogue']:\n    print(dir(sample))\n    break","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:41:37.405307Z","iopub.execute_input":"2024-08-29T14:41:37.406158Z","iopub.status.idle":"2024-08-29T14:41:37.415590Z","shell.execute_reply.started":"2024-08-29T14:41:37.406114Z","shell.execute_reply":"2024-08-29T14:41:37.414527Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isascii', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'removeprefix', 'removesuffix', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']\n","output_type":"stream"}]},{"cell_type":"code","source":"# test_eval_tok_batch = tokenizer(tweetsumm_abs['train'].select(range(17,21))['dialogue'])","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:42:35.830083Z","iopub.execute_input":"2024-08-29T14:42:35.830525Z","iopub.status.idle":"2024-08-29T14:42:35.866906Z","shell.execute_reply.started":"2024-08-29T14:42:35.830485Z","shell.execute_reply":"2024-08-29T14:42:35.865765Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"test_eval_coll_batch = data_collator([test_eval_data])","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:47:25.561133Z","iopub.execute_input":"2024-08-29T14:47:25.562361Z","iopub.status.idle":"2024-08-29T14:47:25.567743Z","shell.execute_reply.started":"2024-08-29T14:47:25.562313Z","shell.execute_reply":"2024-08-29T14:47:25.566631Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"compute_metrics_abs(test_eval_coll_batch)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:47:31.460612Z","iopub.execute_input":"2024-08-29T14:47:31.461607Z","iopub.status.idle":"2024-08-29T14:47:31.567286Z","shell.execute_reply.started":"2024-08-29T14:47:31.461561Z","shell.execute_reply":"2024-08-29T14:47:31.565743Z"},"trusted":true},"execution_count":71,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[71], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcompute_metrics_abs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_eval_coll_batch\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[43], line 2\u001b[0m, in \u001b[0;36mcompute_metrics_abs\u001b[0;34m(eval_pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_metrics_abs\u001b[39m(eval_pred):\n\u001b[0;32m----> 2\u001b[0m     predictions, labels \u001b[38;5;241m=\u001b[39m eval_pred\n\u001b[1;32m      3\u001b[0m     decoded_preds \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(predictions, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(labels \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m, labels, tokenizer\u001b[38;5;241m.\u001b[39mpad_token_id)\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"],"ename":"ValueError","evalue":"too many values to unpack (expected 2)","output_type":"error"}]},{"cell_type":"code","source":"# import numpy as np\n\n\n# def compute_metrics(eval_pred):\n#     predictions, labels = eval_pred\n#     decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n#     labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n#     decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n#     # result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n#     result = {\n#       'rouge': rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True),\n#       'bertscore': bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\"),\n#       'meteor': meteor.compute(predictions=decoded_preds, references=decoded_labels),\n#     }\n#     prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n#     result[\"gen_len\"] = np.mean(prediction_lens)\n#     print(json.dumps(result, indent=2))\n#     return {k: round(v, 4) if type(v) != list else v for k, v in result.items()}","metadata":{"id":"DgrUqOlXi2Nt","execution":{"iopub.status.busy":"2024-08-29T14:23:33.263712Z","iopub.execute_input":"2024-08-29T14:23:33.264094Z","iopub.status.idle":"2024-08-29T14:23:33.269709Z","shell.execute_reply.started":"2024-08-29T14:23:33.264029Z","shell.execute_reply":"2024-08-29T14:23:33.268594Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def compute_test_metrics_abs(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    rouge_scores = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n    bert_scores = bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")\n    bert_scores.pop('hashcode')\n    result = {\n      **{f\"test/rouge/{k}\": round(v, 4) for k,v in rouge_scores.items()},\n      **{f\"test/bertscore/bertscore-{k}\": round(np.mean(v), 4) for k,v in bert_scores.items()},\n      'test/meteor': round(meteor.compute(predictions=decoded_preds, references=decoded_labels)['meteor'], 4),\n    }\n    predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    result[\"test/gen_len\"] = np.mean(prediction_lens)\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:23:33.284219Z","iopub.execute_input":"2024-08-29T14:23:33.284932Z","iopub.status.idle":"2024-08-29T14:23:33.301989Z","shell.execute_reply.started":"2024-08-29T14:23:33.284880Z","shell.execute_reply":"2024-08-29T14:23:33.300937Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# print(json.dumps(bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\"), indent=2))\n# bertscores = bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")\n# np.mean(bertscores)\n# 'rouge': rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True,use_aggregator=False),\n# wandb.log({f\"losses/loss-{ii}\": loss for ii, loss in enumerate(losses)})\n# rouge_scores = {f\"rouge/rougerouge-id-{i}\": score for i, score in enumerate(rouge.compute(predictions=decoded_preds,\n#                                                                                references=decoded_labels,\n#                                                                                use_stemmer=True,\n#                                                                                use_aggregator=True))}\n# bert_scores = {f\"bertscore/bert-id-{i}\": score for i, score in enumerate(bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\"))},\n\n#   for k,v in result.items():\n#     print(k, type(v), v)\n# Bug fix source: https://discuss.huggingface.co/t/bug-in-summarization-tutorial/60566/2\n# {k: round(v, 4) if type(v) != list else v for k, v in result.items()}\n\n#       'rouge1': round(rouge_scores['rouge1'], 4),\n#       'rouge2': round(rouge_scores['rouge2'], 4),\n#       'rougeL': round(rouge_scores['rougeL'], 4),\n#       'rougeLsum': round(rouge_scores['rougeLsum'], 4),\n#       'bertscore/bertscore-precision': np.mean(bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")['precision']),\n#       'bertscore/bertscore-recall': np.mean(bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")['recall']),\n#       'bertscore/bertscore-f1': np.mean(bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")['f1']),","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:23:33.303329Z","iopub.execute_input":"2024-08-29T14:23:33.303688Z","iopub.status.idle":"2024-08-29T14:23:33.318500Z","shell.execute_reply.started":"2024-08-29T14:23:33.303651Z","shell.execute_reply":"2024-08-29T14:23:33.317430Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{"id":"4W_3h_eHi2Nu"}},{"cell_type":"code","source":"# print(json.dumps(), indent=2)\n# blah = bertscore.compute(predictions=['a', 'blue', 'car'], references=['a', 'black', 'car'], lang=\"en\")\n# for b,c in blah.items():\n#     print(c)\n#     print(np.round(sum(c)/len(c), 4))","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:23:33.319803Z","iopub.execute_input":"2024-08-29T14:23:33.320189Z","iopub.status.idle":"2024-08-29T14:23:33.336633Z","shell.execute_reply.started":"2024-08-29T14:23:33.320152Z","shell.execute_reply":"2024-08-29T14:23:33.334701Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# from transformers import AutoConfig\n# config = AutoConfig.from_pretrained(checkpoint_bart)\n# config.max_length = 80\n# config.min_length = 10\n# print(config)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:23:33.338422Z","iopub.execute_input":"2024-08-29T14:23:33.338922Z","iopub.status.idle":"2024-08-29T14:23:33.351549Z","shell.execute_reply.started":"2024-08-29T14:23:33.338865Z","shell.execute_reply":"2024-08-29T14:23:33.350245Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"model = BartForConditionalGeneration.from_pretrained(checkpoint_bart) #, config=config)","metadata":{"id":"YMJSYk6gi2Nv","execution":{"iopub.status.busy":"2024-08-29T14:23:33.353211Z","iopub.execute_input":"2024-08-29T14:23:33.353565Z","iopub.status.idle":"2024-08-29T14:23:34.815969Z","shell.execute_reply.started":"2024-08-29T14:23:33.353526Z","shell.execute_reply":"2024-08-29T14:23:34.814968Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# ppp = pipeline(\"summarization\", checkpoint_bart, device='cuda')\n# out_t = ppp(tokenized_tweetsumm_abs[\"test\"][0]['dialogue'])","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:23:34.817553Z","iopub.execute_input":"2024-08-29T14:23:34.818209Z","iopub.status.idle":"2024-08-29T14:23:34.824654Z","shell.execute_reply.started":"2024-08-29T14:23:34.818145Z","shell.execute_reply":"2024-08-29T14:23:34.823132Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# print(out_t)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:23:34.826629Z","iopub.execute_input":"2024-08-29T14:23:34.827667Z","iopub.status.idle":"2024-08-29T14:23:34.837172Z","shell.execute_reply.started":"2024-08-29T14:23:34.827614Z","shell.execute_reply":"2024-08-29T14:23:34.836105Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# out = model.generate(return_tensors='pt')\n# print(out, type(out), type(out[0]))\n# print(tokenizer.decode(out, skip_special_tokens=False))","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:23:34.838859Z","iopub.execute_input":"2024-08-29T14:23:34.839281Z","iopub.status.idle":"2024-08-29T14:23:34.848579Z","shell.execute_reply.started":"2024-08-29T14:23:34.839243Z","shell.execute_reply":"2024-08-29T14:23:34.847598Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# Print config\nprint(\"Tokenizer config:\", tokenizer.init_kwargs)\nprint(\"Model config:\", str(model.config).replace('\\n',''))","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:23:34.852367Z","iopub.execute_input":"2024-08-29T14:23:34.852843Z","iopub.status.idle":"2024-08-29T14:23:34.863474Z","shell.execute_reply.started":"2024-08-29T14:23:34.852801Z","shell.execute_reply":"2024-08-29T14:23:34.862227Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Tokenizer config: {'errors': 'replace', 'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False), 'sep_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False), 'cls_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False), 'pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False), 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=False), 'add_prefix_space': False, 'model_max_length': 1024, 'tokenizer_file': None, 'name_or_path': 'sshleifer/distilbart-xsum-12-6'}\nModel config: BartConfig {  \"_name_or_path\": \"sshleifer/distilbart-xsum-12-6\",  \"_num_labels\": 3,  \"activation_dropout\": 0.0,  \"activation_function\": \"gelu\",  \"add_bias_logits\": false,  \"add_final_layer_norm\": false,  \"architectures\": [    \"BartForConditionalGeneration\"  ],  \"attention_dropout\": 0.0,  \"bos_token_id\": 0,  \"classif_dropout\": 0.0,  \"classifier_dropout\": 0.0,  \"d_model\": 1024,  \"decoder_attention_heads\": 16,  \"decoder_ffn_dim\": 4096,  \"decoder_layerdrop\": 0.0,  \"decoder_layers\": 6,  \"decoder_start_token_id\": 2,  \"dropout\": 0.1,  \"early_stopping\": true,  \"encoder_attention_heads\": 16,  \"encoder_ffn_dim\": 4096,  \"encoder_layerdrop\": 0.0,  \"encoder_layers\": 12,  \"eos_token_id\": 2,  \"eos_token_ids\": [    2  ],  \"extra_pos_embeddings\": 2,  \"forced_eos_token_id\": 2,  \"gradient_checkpointing\": false,  \"id2label\": {    \"0\": \"LABEL_0\",    \"1\": \"LABEL_1\",    \"2\": \"LABEL_2\"  },  \"init_std\": 0.02,  \"is_encoder_decoder\": true,  \"label2id\": {    \"LABEL_0\": 0,    \"LABEL_1\": 1,    \"LABEL_2\": 2  },  \"length_penalty\": 0.5,  \"max_length\": 62,  \"max_position_embeddings\": 1024,  \"min_length\": 11,  \"model_type\": \"bart\",  \"no_repeat_ngram_size\": 3,  \"normalize_before\": false,  \"normalize_embedding\": true,  \"num_beams\": 6,  \"num_hidden_layers\": 12,  \"output_past\": true,  \"pad_token_id\": 1,  \"prefix\": \" \",  \"replacing_rate\": 0,  \"save_step\": 58,  \"scale_embedding\": false,  \"static_position_embeddings\": false,  \"student_decoder_layers\": null,  \"student_encoder_layers\": null,  \"task_specific_params\": {},  \"transformers_version\": \"4.44.0\",  \"use_cache\": true,  \"vocab_size\": 50264}\n","output_type":"stream"}]},{"cell_type":"code","source":"current_time = datetime.datetime.now().strftime(\"%d%m-%H%M\")\nprint(current_time)\nrun_name_model = f\"distilbart-abs-{current_time}\"\nwandb.run.name = run_name_model\nwandb.run.save()\n\ngen_config = GenerationConfig(max_source_length=512,bos_token_id=0)\ngen_config.save_pretrained(\"roequitz/distilbart-abs-tweetsumm-2908a\", push_to_hub=True)\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=f\"trained-distilbart-abs-{current_time[0:4]}\",\n    eval_strategy=\"epoch\",\n    logging_strategy=\"steps\",\n    logging_steps=10,\n    learning_rate=3e-3,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    weight_decay=0.01,\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    num_train_epochs=1,\n    predict_with_generate=True,\n    fp16=True,\n    generation_max_length=80,\n    generation_config=gen_config,\n    push_to_hub=False,\n    report_to=\"wandb\",\n    run_name=run_name_model\n)\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_tweetsumm_abs[\"train\"],\n    eval_dataset=tokenized_tweetsumm_abs[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics_abs,\n)\n\ntraining_start = time.time()\ntrainer.train()\ntraining_end = time.time()\nprint(\"Time it took for training:\", str(datetime.timedelta(seconds=(training_end-training_start))))","metadata":{"id":"nj5v3nT9i2Nw","outputId":"512d759b-0343-4f83-e36c-cf15fec503a3","execution":{"iopub.status.busy":"2024-08-29T14:23:34.865075Z","iopub.execute_input":"2024-08-29T14:23:34.865482Z","iopub.status.idle":"2024-08-29T14:26:10.316633Z","shell.execute_reply.started":"2024-08-29T14:23:34.865434Z","shell.execute_reply":"2024-08-29T14:26:10.314372Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n","output_type":"stream"},{"name":"stdout","text":"2908-1423\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='218' max='434' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [218/434 01:33 < 01:33, 2.32 it/s, Epoch 1/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>\n    <div>\n      \n      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [28/28 00:29]\n    </div>\n    "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"999b83f54a004ee4879ec47eea530d08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ffc4d84832f4e99aad17c4c539afc8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f60ccfbc3ea4983a3ad5633ff573e24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e6a46c71727422ab044d0576ff579f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0ed61cfa92e41a9b4409dc9641d22b3"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f478e8df12a041e99329ceed3e0ce94e"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[53], line 41\u001b[0m\n\u001b[1;32m     30\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m     31\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     32\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics_abs,\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     40\u001b[0m training_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 41\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m training_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime it took for training:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mtimedelta(seconds\u001b[38;5;241m=\u001b[39m(training_end\u001b[38;5;241m-\u001b[39mtraining_start))))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1948\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1946\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1949\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1953\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2386\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2383\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2385\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2386\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   2389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[1;32m   2390\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2814\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2812\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 2814\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m   2817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_checkpoint(model, trial, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2771\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   2770\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 2771\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2772\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2774\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer_seq2seq.py:180\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_kwargs \u001b[38;5;241m=\u001b[39m gen_kwargs\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3676\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3673\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3675\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3676\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3677\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3679\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3680\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3684\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3686\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3966\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3962\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[1;32m   3963\u001b[0m             EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels, inputs\u001b[38;5;241m=\u001b[39mall_inputs)\n\u001b[1;32m   3964\u001b[0m         )\n\u001b[1;32m   3965\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3966\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvalPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3967\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3968\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n","Cell \u001b[0;32mIn[43], line 13\u001b[0m, in \u001b[0;36mcompute_metrics_abs\u001b[0;34m(eval_pred)\u001b[0m\n\u001b[1;32m      8\u001b[0m bert_scores \u001b[38;5;241m=\u001b[39m bertscore\u001b[38;5;241m.\u001b[39mcompute(predictions\u001b[38;5;241m=\u001b[39mdecoded_preds, references\u001b[38;5;241m=\u001b[39mdecoded_labels, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m bert_scores\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhashcode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m result \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     11\u001b[0m   \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrouge/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mround\u001b[39m(v, \u001b[38;5;241m4\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m rouge_scores\u001b[38;5;241m.\u001b[39mitems()},\n\u001b[1;32m     12\u001b[0m   \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbertscore/bertscore-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mround\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(v), \u001b[38;5;241m4\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m bert_scores\u001b[38;5;241m.\u001b[39mitems()},\n\u001b[0;32m---> 13\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeteor\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mround\u001b[39m(\u001b[43mmeteor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoded_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoded_labels\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeteor\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m4\u001b[39m),\n\u001b[1;32m     14\u001b[0m }\n\u001b[1;32m     15\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(predictions \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m, predictions, tokenizer\u001b[38;5;241m.\u001b[39mpad_token_id)\n\u001b[1;32m     16\u001b[0m prediction_lens \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mcount_nonzero(pred \u001b[38;5;241m!=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mpad_token_id) \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m predictions]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/evaluate/module.py:467\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {input_name: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[input_name] \u001b[38;5;28;01mfor\u001b[39;00m input_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_names()}\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m temp_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed):\n\u001b[0;32m--> 467\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompute_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_writer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--meteor/ea1b63f27faab173b022be2d3cc3df2fc44a894247f833943ea98c8a7caeb1e8/meteor.py:144\u001b[0m, in \u001b[0;36mMeteor._compute\u001b[0;34m(self, predictions, references, alpha, beta, gamma)\u001b[0m\n\u001b[1;32m    133\u001b[0m         scores \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    134\u001b[0m             meteor_score\u001b[38;5;241m.\u001b[39mmeteor_score(\n\u001b[1;32m    135\u001b[0m                 [word_tokenize(ref) \u001b[38;5;28;01mfor\u001b[39;00m ref \u001b[38;5;129;01min\u001b[39;00m refs],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m refs, pred \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(references, predictions)\n\u001b[1;32m    142\u001b[0m         ]\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         scores \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    145\u001b[0m             meteor_score\u001b[38;5;241m.\u001b[39msingle_meteor_score(\n\u001b[1;32m    146\u001b[0m                 word_tokenize(ref), word_tokenize(pred), alpha\u001b[38;5;241m=\u001b[39malpha, beta\u001b[38;5;241m=\u001b[39mbeta, gamma\u001b[38;5;241m=\u001b[39mgamma\n\u001b[1;32m    147\u001b[0m             )\n\u001b[1;32m    148\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m ref, pred \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(references, predictions)\n\u001b[1;32m    149\u001b[0m         ]\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multiple_refs:\n","File \u001b[0;32m~/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--meteor/ea1b63f27faab173b022be2d3cc3df2fc44a894247f833943ea98c8a7caeb1e8/meteor.py:146\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    133\u001b[0m         scores \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    134\u001b[0m             meteor_score\u001b[38;5;241m.\u001b[39mmeteor_score(\n\u001b[1;32m    135\u001b[0m                 [word_tokenize(ref) \u001b[38;5;28;01mfor\u001b[39;00m ref \u001b[38;5;129;01min\u001b[39;00m refs],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m refs, pred \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(references, predictions)\n\u001b[1;32m    142\u001b[0m         ]\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m         scores \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    145\u001b[0m             meteor_score\u001b[38;5;241m.\u001b[39msingle_meteor_score(\n\u001b[0;32m--> 146\u001b[0m                 \u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref\u001b[49m\u001b[43m)\u001b[49m, word_tokenize(pred), alpha\u001b[38;5;241m=\u001b[39malpha, beta\u001b[38;5;241m=\u001b[39mbeta, gamma\u001b[38;5;241m=\u001b[39mgamma\n\u001b[1;32m    147\u001b[0m             )\n\u001b[1;32m    148\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m ref, pred \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(references, predictions)\n\u001b[1;32m    149\u001b[0m         ]\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multiple_refs:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/tokenize/__init__.py:142\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    144\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[1;32m    145\u001b[0m     ]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/tokenize/__init__.py:119\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/tokenize/__init__.py:105\u001b[0m, in \u001b[0;36m_get_punkt_tokenizer\u001b[0;34m(language)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_punkt_tokenizer\u001b[39m(language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    a lru cache for performance.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    :type language: str\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1744\u001b[0m, in \u001b[0;36mPunktTokenizer.__init__\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1743\u001b[0m     PunktSentenceTokenizer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1744\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/tokenize/punkt.py:1749\u001b[0m, in \u001b[0;36mPunktTokenizer.load_lang\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1747\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[0;32m-> 1749\u001b[0m     lang_dir \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m load_punkt_params(lang_dir)\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang \u001b[38;5;241m=\u001b[39m lang\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nltk/data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/opt/conda/nltk_data'\n    - '/opt/conda/share/nltk_data'\n    - '/opt/conda/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"],"ename":"LookupError","evalue":"\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/opt/conda/nltk_data'\n    - '/opt/conda/share/nltk_data'\n    - '/opt/conda/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n","output_type":"error"}]},{"cell_type":"code","source":"!ls -lha & df -h & du -h","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:26:10.317927Z","iopub.status.idle":"2024-08-29T14:26:10.318393Z","shell.execute_reply.started":"2024-08-29T14:26:10.318169Z","shell.execute_reply":"2024-08-29T14:26:10.318193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"id":"0z9pTauji2Nw","execution":{"iopub.status.busy":"2024-08-29T14:26:10.320719Z","iopub.status.idle":"2024-08-29T14:26:10.321171Z","shell.execute_reply.started":"2024-08-29T14:26:10.320945Z","shell.execute_reply":"2024-08-29T14:26:10.320967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions = trainer.predict(tokenized_tweetsumm_abs[\"test\"])\nprint(type(test_predictions), test_predictions)\n#print(test_df_temp.head())","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:26:10.322733Z","iopub.status.idle":"2024-08-29T14:26:10.323863Z","shell.execute_reply.started":"2024-08-29T14:26:10.323637Z","shell.execute_reply":"2024-08-29T14:26:10.323664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df_temp['predictions'] = test_predictions['predictions']\ntest_df_temp['metrics'] = test_predictions['metrics']","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:26:10.326287Z","iopub.status.idle":"2024-08-29T14:26:10.326726Z","shell.execute_reply.started":"2024-08-29T14:26:10.326513Z","shell.execute_reply":"2024-08-29T14:26:10.326536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tokenized_tweetsumm_abs[\"test\"][0][\"input_ids\"])\npreds = trainer.predict(tokenized_tweetsumm_abs[\"test\"])","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:26:10.327925Z","iopub.status.idle":"2024-08-29T14:26:10.328378Z","shell.execute_reply.started":"2024-08-29T14:26:10.328142Z","shell.execute_reply":"2024-08-29T14:26:10.328178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(preds.predictions)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:26:10.330330Z","iopub.status.idle":"2024-08-29T14:26:10.330734Z","shell.execute_reply.started":"2024-08-29T14:26:10.330533Z","shell.execute_reply":"2024-08-29T14:26:10.330554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\ntest_name = ds_dir + f\"test_preds_metrics_{current_time[0:2]}_{current_time[2:4]}_bart.csv\"\ntest_df_temp.to_csv(test_name, index=False, header=False, quoting=csv.QUOTE_ALL)\nwandb.log_artifact(test_name, results)\nwandb.log(test_predictions['metrics'])\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:26:10.331908Z","iopub.status.idle":"2024-08-29T14:26:10.332360Z","shell.execute_reply.started":"2024-08-29T14:26:10.332141Z","shell.execute_reply":"2024-08-29T14:26:10.332163Z"},"trusted":true},"execution_count":null,"outputs":[]}]}