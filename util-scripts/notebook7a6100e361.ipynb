{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T10:43:37.107805Z","iopub.status.busy":"2024-07-23T10:43:37.107106Z","iopub.status.idle":"2024-07-23T10:43:38.336855Z","shell.execute_reply":"2024-07-23T10:43:38.335783Z","shell.execute_reply.started":"2024-07-23T10:43:37.107770Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","dials_train = pd.read_csv(\"../../dials_2307_1158_dials_nl.csv\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Customer: @115850 hi team! i m planning to get Apple AirPods ! it shows on the website it has 10 days replacement warranty, can u explain me what is it ? \n"," Agent: @264322 We've a 10days replacement policy if the item you received is damaged or defective. ^SH \n"," Customer: @AmazonHelp Ok ! But what if i didnâ€™t like the product and want to return it \n"," Agent: @264322 We wouldn't be able to accept the remorse returns. For more information on mobile returns policy. Kindly click on the link shared here: https://t.co/gYYDFKUNPY. Appreciate your understanding. \n"," Customer: @AmazonHelp Ok thanks ! But these are earphones so does it mean same policy apply for these as well \n"," Agent: @264322 Yes, headsets/ earphones are not eligible for remorse returns. In case of any damage/ defect you can reach out to us, we'll check and help you accordingly. ^VN \n"," Customer: @AmazonHelp Oh ok ! Thanks for the help ! Much appreciated :) \n"," Agent: @264322 Thanks to you too for understanding. Do keep us posted for any further concerns. We'll be happy to help. ðŸ˜Š ^VN\n"]}],"source":["print(str(dials_train.iloc[0,0]))"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["from nltk.parse.corenlp import CoreNLPServer, CoreNLPParser\n","import os\n","server = CoreNLPServer(\n","  path_to_jar=os.path.join(os.getcwd(), \"stanford-corenlp-3.8.0.jar\"),\n","  path_to_models_jar=os.path.join(os.getcwd(), \"stanford-corenlp-3.8.0-models-english.jar\")\n","  )\n","try:\n","  server.start() \n","  parser = CoreNLPParser()\n","  parse = next(parser.raw_parse(\"the quick brown fox jumps over the lazy dog\"))\n","  server.stop() \n","\n","except:\n","  server.stop()\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'parse' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mparse\u001b[49m)\n","\u001b[1;31mNameError\u001b[0m: name 'parse' is not defined"]}],"source":["print(parse)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Python312\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n","  _torch_pytree._register_pytree_node(\n"]}],"source":["import stanza"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-07-23 15:34:11 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5adb7ef8642e4e6780dee4a29998e3cc","version_major":2,"version_minor":0},"text/plain":["Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   â€¦"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["2024-07-23 15:34:11 INFO: Downloaded file to C:\\Users\\gracz\\stanza_resources\\resources.json\n","2024-07-23 15:34:11 WARNING: Language en package default expects mwt, which has been added\n"]},{"ename":"UnknownProcessorError","evalue":"Unknown processor type requested: ssplit","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mUnknownProcessorError\u001b[0m                     Traceback (most recent call last)","Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mstanza\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokenize,ssplit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m doc \u001b[38;5;241m=\u001b[39m nlp(dials_train\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(doc)\n","File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\stanza\\pipeline\\core.py:242\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[1;34m(self, lang, dir, package, processors, logging_level, verbose, use_gpu, model_dir, download_method, resources_url, resources_branch, resources_version, resources_filepath, proxies, foundation_cache, device, allow_unknown_language, **kwargs)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# Maintain load list\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lang \u001b[38;5;129;01min\u001b[39;00m resources:\n\u001b[1;32m--> 242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_list \u001b[38;5;241m=\u001b[39m \u001b[43mmaintain_processor_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaybe_add_mwt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenize_pretokenized\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_list \u001b[38;5;241m=\u001b[39m add_dependencies(resources, lang, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_list)\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m download_method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DownloadMethod\u001b[38;5;241m.\u001b[39mNONE:\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;66;03m# skip processors which aren't downloaded from our collection\u001b[39;00m\n","File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\stanza\\resources\\common.py:222\u001b[0m, in \u001b[0;36mmaintain_processor_list\u001b[1;34m(resources, lang, package, processors, allow_pretrain, maybe_add_mwt)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m PIPELINE_NAMES:\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pretrain \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m PRETRAIN_NAMES:\n\u001b[1;32m--> 222\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UnknownProcessorError(key)\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m plist:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# check if keys and values can be found\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m resources[lang] \u001b[38;5;129;01mand\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m resources[lang][key]:\n","\u001b[1;31mUnknownProcessorError\u001b[0m: Unknown processor type requested: ssplit"]}],"source":["nlp = stanza.Pipeline(lang='en', processors='tokenize')\n","doc = nlp(dials_train.iloc[0,0])\n","print(doc)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Using the default treebank \"en_ewt\" for language \"en\".\n","Would you like to download the models for: en_ewt now? (Y/n)\n","\n","Default download directory: C:\\Users\\gracz\\stanfordnlp_resources\n","Hit enter to continue or type an alternate directory.\n","\n","Downloading models for: en_ewt\n","Download location: C:\\Users\\gracz\\stanfordnlp_resources\\en_ewt_models.zip\n"]},{"ename":"TypeError","evalue":"int() argument must be a string, a bytes-like object or a real number, not 'NoneType'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstanfordnlp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mstanfordnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m3.8.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis is ... sample input. I want to split this text into a list of sentences. Can you? Please help\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m nlp \u001b[38;5;241m=\u001b[39m stanfordnlp\u001b[38;5;241m.\u001b[39mPipeline(processors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokenize\u001b[39m\u001b[38;5;124m'\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\stanfordnlp\\utils\\resources.py:136\u001b[0m, in \u001b[0;36mdownload\u001b[1;34m(download_label, resource_dir, confirm_if_exists, force, version)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m download_label \u001b[38;5;129;01min\u001b[39;00m default_treebanks:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing the default treebank \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdefault_treebanks[download_label]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for language \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdownload_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 136\u001b[0m     \u001b[43mdownload_ud_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault_treebanks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdownload_label\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mconfirm_if_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfirm_if_exists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe language or treebank \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdownload_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not currently supported by this function. Please try again with other languages or treebanks.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\stanfordnlp\\utils\\resources.py:103\u001b[0m, in \u001b[0;36mdownload_ud_model\u001b[1;34m(lang_name, resource_dir, should_unzip, confirm_if_exists, force, version)\u001b[0m\n\u001b[0;32m    101\u001b[0m r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(download_url, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(download_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 103\u001b[0m     file_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent-length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m     default_chunk_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m67108864\u001b[39m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mfile_size, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n","\u001b[1;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'"]}],"source":["import stanfordnlp\n","\n","stanfordnlp.download('en', version='0.1.0', force=True)\n","text = \"this is ... sample input. I want to split this text into a list of sentences. Can you? Please help\"\n","\n","nlp = stanfordnlp.Pipeline(processors='tokenize', lang='en')\n","doc = nlp(text)\n","print(doc.sentences)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[Found java: C:\\Program Files\\Java\\jdk-22\\bin\\java.exe]\n","[Found java: C:\\Program Files\\Java\\jdk-22\\bin\\java.exe]\n"]},{"ename":"CoreNLPServerError","evalue":"Could not connect to the server.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mCoreNLPServerError\u001b[0m                        Traceback (most recent call last)","Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstanford\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StanfordTokenizer\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorenlp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CoreNLPServer\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mCoreNLPServer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m  \u001b[49m\u001b[43mpath_to_jar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./stanford-corenlp-3.8.0.jar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[43mpath_to_models_jar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./stanford-corenlp-3.8.0-models-english.jar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[43mjava_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-mx4g -preload tokenize,ssplit,pos,lemma,parse,depparse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m  \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m  \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msrv\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtokenized\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msrv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdials_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtokenized\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\nltk\\parse\\corenlp.py:170\u001b[0m, in \u001b[0;36mCoreNLPServer.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\nltk\\parse\\corenlp.py:152\u001b[0m, in \u001b[0;36mCoreNLPServer.start\u001b[1;34m(self, stdout, stderr)\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CoreNLPServerError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not connect to the server.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m60\u001b[39m):\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n","\u001b[1;31mCoreNLPServerError\u001b[0m: Could not connect to the server."]}],"source":["from nltk.tokenize.stanford import StanfordTokenizer\n","from nltk.parse.corenlp import CoreNLPServer\n","with CoreNLPServer(\n","  path_to_jar=\"./stanford-corenlp-3.8.0.jar\",\n","  path_to_models_jar=\"./stanford-corenlp-3.8.0-models-english.jar\",\n","  java_options=\"-mx4g -preload tokenize,ssplit,pos,lemma,parse,depparse\",\n","  port=9000,\n","  verbose=True\n","  ) as srv:\n","  tokenized = srv.tokenize(dials_train.iloc[0,0])\n","  print(tokenized)\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\gracz\\AppData\\Local\\Temp\\ipykernel_11612\\4228862792.py:3: DeprecationWarning: \n","The StanfordTokenizer will be deprecated in version 3.2.5.\n","Please use \u001b[91mnltk.parse.corenlp.CoreNLPParser\u001b[0m instead.'\n","  tokenizer = StanfordTokenizer(path_to_jar=\"./stanford-corenlp-3.8.0.jar\",\n"]}],"source":["\n","# tokenizer = StanfordTokenizer(path_to_jar=\"./stanford-corenlp-3.8.0.jar\",\n","#                               options={\"newlineIsSentenceBreak\": True},\n","#                               java_options='-mx3g')\n","\n","\n","# from nltk.parse.corenlp import CoreNLPServer\n","# with CoreNLPServer(path_to_jar=\"./stanford-corenlp-3.8.0.jar\", path_to_models_jar=\"./stanford-corenlp-3.8.0-models-english.jar\") as srv:\n","#   srv.start()\n","#   print(dir(srv))\n","#   srv.tokenize()\n","# print(StanfordTokenizer().tokenize(dials_train.iloc[0,0]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from stanfordcorenlp import StanfordCoreNLP\n","\n","nnp = StanfordCoreNLP(path='./stanford-corenlp-3.8.0.jar')\n","nnp.toke\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"'StanfordTokenizer' object is not callable","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdials_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(res)\n","\u001b[1;31mTypeError\u001b[0m: 'StanfordTokenizer' object is not callable"]}],"source":["res = tokenizer(dials_train.iloc[0,0])\n","print(res)"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T10:44:40.719840Z","iopub.status.busy":"2024-07-23T10:44:40.718925Z","iopub.status.idle":"2024-07-23T10:44:40.724964Z","shell.execute_reply":"2024-07-23T10:44:40.723932Z","shell.execute_reply.started":"2024-07-23T10:44:40.719802Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[CLS] Customer: @115850 hi team! i m planning to get Apple AirPods ! it shows on the website it has 10 days replacement warranty, can u explain me what is it ? Agent: @264322 We've a 10days replacement policy if the item you received is damaged or defective. ^SH [SEP] [CLS] Customer: @AmazonHelp Ok ! But what if i didnâ€™t like the product and want to return it [SEP] [CLS] Agent: @264322 We wouldn't be able to accept the remorse returns. For more information on mobile returns policy. Kindly click on the link shared here: https://t.co/gYYDFKUNPY. Appreciate your understanding. [SEP] [CLS] Customer: @AmazonHelp Ok thanks ! But these are earphones so does it mean same policy apply for these as well [SEP] [CLS] Agent: @264322 Yes, headsets/ earphones are not eligible for remorse returns. In case of any damage/ defect you can reach out to us, we'll check and help you accordingly. ^VN [SEP] [CLS] Customer: @AmazonHelp Oh ok ! Thanks for the help ! Much appreciated :) [SEP] [CLS] Agent: @264322 Thanks to you too for understanding. Do keep us posted for any further concerns. We'll be happy to help. ðŸ˜Š ^VN [SEP]\n"]}],"source":["print(dials_train.iloc[0,0])"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-23T10:45:33.612283Z","iopub.status.busy":"2024-07-23T10:45:33.611899Z","iopub.status.idle":"2024-07-23T10:45:39.248467Z","shell.execute_reply":"2024-07-23T10:45:39.247511Z","shell.execute_reply.started":"2024-07-23T10:45:33.612251Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Python312\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n","  _torch_pytree._register_pytree_node(\n","c:\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]}],"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","# text = \"This is a sample text to tokenize. That was a sentence. That was \\n 1. Just a newline\\n2. Something else.\""]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': [101, 8013, 1024, 1030, 10630, 27531, 2692, 7632, 2136, 999, 1045, 1049, 4041, 2000, 2131, 6207, 2250, 22925, 999, 2009, 3065, 2006, 1996, 4037, 2009, 2038, 2184, 2420, 6110, 10943, 2100, 1010, 2064, 1057, 4863, 2033, 2054, 2003, 2009, 1029, 4005, 1024, 1030, 21611, 16703, 2475, 2057, 1005, 2310, 1037, 2184, 10259, 2015, 6110, 3343, 2065, 1996, 8875, 2017, 2363, 2003, 5591, 2030, 28829, 1012, 1034, 14021, 102, 101, 8013, 1024, 1030, 9733, 16001, 2361, 7929, 999, 2021, 2054, 2065, 1045, 2134, 1521, 1056, 2066, 1996, 4031, 1998, 2215, 2000, 2709, 2009, 102, 101, 4005, 1024, 1030, 21611, 16703, 2475, 2057, 2876, 1005, 1056, 2022, 2583, 2000, 5138, 1996, 23124, 5651, 1012, 2005, 2062, 2592, 2006, 4684, 5651, 3343, 1012, 19045, 11562, 2006, 1996, 4957, 4207, 2182, 1024, 16770, 1024, 1013, 1013, 1056, 1012, 2522, 1013, 1043, 2100, 25688, 24316, 4609, 7685, 1012, 9120, 2115, 4824, 1012, 102, 101, 8013, 1024, 1030, 9733, 16001, 2361, 7929, 4283, 999, 2021, 2122, 2024, 4540, 19093, 2061, 2515, 2009, 2812, 2168, 3343, 6611, 2005, 2122, 2004, 2092, 102, 101, 4005, 1024, 1030, 21611, 16703, 2475, 2748, 1010, 4641, 8454, 1013, 4540, 19093, 2024, 2025, 7792, 2005, 23124, 5651, 1012, 1999, 2553, 1997, 2151, 4053, 1013, 21262, 2017, 2064, 3362, 2041, 2000, 2149, 1010, 2057, 1005, 2222, 4638, 1998, 2393, 2017, 11914, 1012, 1034, 1058, 2078, 102, 101, 8013, 1024, 1030, 9733, 16001, 2361, 2821, 7929, 999, 4283, 2005, 1996, 2393, 999, 2172, 12315, 1024, 1007, 102, 101, 4005, 1024, 1030, 21611, 16703, 2475, 4283, 2000, 2017, 2205, 2005, 4824, 1012, 2079, 2562, 2149, 6866, 2005, 2151, 2582, 5936, 1012, 2057, 1005, 2222, 2022, 3407, 2000, 2393, 1012, 100, 1034, 1058, 2078, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n","[CLS] customer : @ 115850 hi team! i m planning to get apple airpods! it shows on the website it has 10 days replacement warranty, can u explain me what is it? agent : @ 264322 we've a 10days replacement policy if the item you received is damaged or defective. ^ sh [SEP] [CLS] customer : @ amazonhelp ok! but what if i didn â€™ t like the product and want to return it [SEP] [CLS] agent : @ 264322 we wouldn't be able to accept the remorse returns. for more information on mobile returns policy. kindly click on the link shared here : https : / / t. co / gyydfkunpy. appreciate your understanding. [SEP] [CLS] customer : @ amazonhelp ok thanks! but these are earphones so does it mean same policy apply for these as well [SEP] [CLS] agent : @ 264322 yes, headsets / earphones are not eligible for remorse returns. in case of any damage / defect you can reach out to us, we'll check and help you accordingly. ^ vn [SEP] [CLS] customer : @ amazonhelp oh ok! thanks for the help! much appreciated : ) [SEP] [CLS] agent : @ 264322 thanks to you too for understanding. do keep us posted for any further concerns. we'll be happy to help. [UNK] ^ vn [SEP]\n"]}],"source":["tokenized = tokenizer.encode_plus(dials_train.iloc[0,0], add_special_tokens=False)\n","print(tokenized)\n","print(tokenizer.decode(tokenized['input_ids'], skip_special_tokens=False))\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]'] [100, 102, 0, 101, 103]\n"]}],"source":["print(tokenizer.all_special_tokens, tokenizer.all_special_ids)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["C:\\Users\\gracz\\OneDrive - University of Limerick\\University\\Masters\\Sem2\\Thesis\\notebooks\\CoreNLP-3.8.0\\CoreNLP-3.8.0\n"]}],"source":["import os\n","print(os.environ['CORENLP_HOME'])"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"ename":"PermanentlyFailedException","evalue":"Timed out waiting for service to come alive.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mPermanentlyFailedException\u001b[0m                Traceback (most recent call last)","Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m corenlp\u001b[38;5;241m.\u001b[39mCoreNLPClient(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30000\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m client:\n\u001b[0;32m      4\u001b[0m   text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustomer: blah blah. next sent. Agent: yes. of course.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m   ann \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mannotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mannotators\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokenize,ssplit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 'ssplit.newlineIsSentenceBreak': 'always',\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutputFormat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjson\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      9\u001b[0m \u001b[43m  \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(ann)\n","File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\corenlp\\client.py:225\u001b[0m, in \u001b[0;36mCoreNLPClient.annotate\u001b[1;34m(self, text, annotators, output_format, properties)\u001b[0m\n\u001b[0;32m    223\u001b[0m     properties[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputFormat\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m output_format\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# make the request\u001b[39;00m\n\u001b[1;32m--> 225\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproperties\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# customize what is returned based outputFormat\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m properties[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputFormat\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialized\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\corenlp\\client.py:178\u001b[0m, in \u001b[0;36mCoreNLPClient._request\u001b[1;34m(self, buf, properties)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, buf, properties):\n\u001b[0;32m    172\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request to the CoreNLP server.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03m    :param (str | unicode) text: raw text for the CoreNLPServer to parse\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m    :param (dict) properties: properties that the server expects\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m    :return: request result\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mensure_alive\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m         input_format \u001b[38;5;241m=\u001b[39m properties\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputFormat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\corenlp\\client.py:119\u001b[0m, in \u001b[0;36mRobustService.ensure_alive\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PermanentlyFailedException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimed out waiting for service to come alive.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# At this point we are guaranteed that the service is alive.\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n","\u001b[1;31mPermanentlyFailedException\u001b[0m: Timed out waiting for service to come alive."]}],"source":["import corenlp\n","\n","with corenlp.CoreNLPClient(timeout=30000) as client:\n","  text = \"Customer: blah blah. next sent. Agent: yes. of course.\"\n","  ann = client.annotate(text, properties={\n","    'annotators': 'tokenize,ssplit',\n","    # 'ssplit.newlineIsSentenceBreak': 'always',\n","    'outputFormat': 'json'\n","  })\n","print(ann)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5430249,"sourceId":9012538,"sourceType":"datasetVersion"},{"datasetId":5433232,"sourceId":9016808,"sourceType":"datasetVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":4}
