{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":193923985,"sourceType":"kernelVersion"}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BERT - continue training from older notebook","metadata":{}},{"cell_type":"code","source":"!pip install pytorch_pretrained_bert rouge_score pyrouge","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-26T12:38:54.180122Z","iopub.execute_input":"2024-08-26T12:38:54.180440Z","iopub.status.idle":"2024-08-26T12:39:23.518182Z","shell.execute_reply.started":"2024-08-26T12:38:54.180400Z","shell.execute_reply":"2024-08-26T12:39:23.517078Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pytorch_pretrained_bert\n  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl.metadata (86 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m819.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting pyrouge\n  Downloading pyrouge-0.1.3.tar.gz (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from pytorch_pretrained_bert) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pytorch_pretrained_bert) (1.26.4)\nRequirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from pytorch_pretrained_bert) (1.26.100)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from pytorch_pretrained_bert) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from pytorch_pretrained_bert) (4.66.4)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from pytorch_pretrained_bert) (2024.5.15)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2024.6.1)\nCollecting botocore<1.30.0,>=1.29.100 (from boto3->pytorch_pretrained_bert)\n  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->pytorch_pretrained_bert) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3->pytorch_pretrained_bert) (0.6.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch_pretrained_bert) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch_pretrained_bert) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch_pretrained_bert) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->pytorch_pretrained_bert) (2024.7.4)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.100->boto3->pytorch_pretrained_bert) (2.9.0.post0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=0.4.1->pytorch_pretrained_bert) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=0.4.1->pytorch_pretrained_bert) (1.3.0)\nDownloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge_score, pyrouge\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=fc60f06f6fa28133b6fc55892a8efd033167abf04c50ebd7b0b428e338b766e7\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n  Building wheel for pyrouge (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyrouge: filename=pyrouge-0.1.3-py3-none-any.whl size=191604 sha256=de4a43810ed49acd998d18bad76aed81e53f0c1f73a78b4ccbdf7e1c91a62b8b\n  Stored in directory: /root/.cache/pip/wheels/9a/67/12/c5dd8ef8b4152bb8789eafd2a74a734e2dc7bb9eae02b768e7\nSuccessfully built rouge_score pyrouge\nInstalling collected packages: pyrouge, rouge_score, botocore, pytorch_pretrained_bert\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.34.131\n    Uninstalling botocore-1.34.131:\n      Successfully uninstalled botocore-1.34.131\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naiobotocore 2.13.2 requires botocore<1.34.132,>=1.34.70, but you have botocore 1.29.165 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed botocore-1.29.165 pyrouge-0.1.3 pytorch_pretrained_bert-0.6.2 rouge_score-0.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"inputs_dir = \"/kaggle/input/bert-train-eval-2408-2023\"\naiml_dir = inputs_dir + \"/aiml-thesis\"\nbertsum_src_dir = aiml_dir + \"/submods/bertsum/src\"\nraw_dials_dir = aiml_dir + \"/data/raw_dialogues\"\nbertsum_dir = aiml_dir + \"/submods/bertsum\"\nberstum_wk_dir = \"/kaggle/working/aiml-thesis/submods/bertsum\"","metadata":{"execution":{"iopub.status.busy":"2024-08-26T12:39:23.520136Z","iopub.execute_input":"2024-08-26T12:39:23.520477Z","iopub.status.idle":"2024-08-26T12:39:23.525724Z","shell.execute_reply.started":"2024-08-26T12:39:23.520442Z","shell.execute_reply":"2024-08-26T12:39:23.524841Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport rouge_score\nfrom rouge_score import rouge_scorer","metadata":{"execution":{"iopub.status.busy":"2024-08-26T12:39:23.526867Z","iopub.execute_input":"2024-08-26T12:39:23.527246Z","iopub.status.idle":"2024-08-26T12:39:25.639190Z","shell.execute_reply.started":"2024-08-26T12:39:23.527206Z","shell.execute_reply":"2024-08-26T12:39:25.638208Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"%env BERTSUM_DIR={bertsum_dir}","metadata":{"execution":{"iopub.status.busy":"2024-08-26T12:39:25.641082Z","iopub.execute_input":"2024-08-26T12:39:25.641506Z","iopub.status.idle":"2024-08-26T12:39:25.646598Z","shell.execute_reply.started":"2024-08-26T12:39:25.641472Z","shell.execute_reply":"2024-08-26T12:39:25.645773Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"env: BERTSUM_DIR=/kaggle/input/bert-train-eval-2408-2023/aiml-thesis/submods/bertsum\n","output_type":"stream"}]},{"cell_type":"code","source":"os.chdir(\"/kaggle/working\")","metadata":{"execution":{"iopub.status.busy":"2024-08-26T12:40:19.266083Z","iopub.execute_input":"2024-08-26T12:40:19.266756Z","iopub.status.idle":"2024-08-26T12:40:19.270957Z","shell.execute_reply.started":"2024-08-26T12:40:19.266716Z","shell.execute_reply":"2024-08-26T12:40:19.270067Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"!mkdir results models logs","metadata":{"execution":{"iopub.status.busy":"2024-08-26T12:40:20.835191Z","iopub.execute_input":"2024-08-26T12:40:20.835549Z","iopub.status.idle":"2024-08-26T12:40:21.839724Z","shell.execute_reply.started":"2024-08-26T12:40:20.835517Z","shell.execute_reply":"2024-08-26T12:40:21.838639Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"!cp -r $BERTSUM_DIR/src .\n!cp -r $BERTSUM_DIR/models/bert_transformer/* ./models","metadata":{"execution":{"iopub.status.busy":"2024-08-26T12:40:23.149026Z","iopub.execute_input":"2024-08-26T12:40:23.149422Z","iopub.status.idle":"2024-08-26T12:42:43.857826Z","shell.execute_reply.started":"2024-08-26T12:40:23.149385Z","shell.execute_reply":"2024-08-26T12:42:43.856511Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"!ls -la","metadata":{"execution":{"iopub.status.busy":"2024-08-26T12:52:02.485919Z","iopub.execute_input":"2024-08-26T12:52:02.486639Z","iopub.status.idle":"2024-08-26T12:52:03.481575Z","shell.execute_reply.started":"2024-08-26T12:52:02.486598Z","shell.execute_reply":"2024-08-26T12:52:03.480634Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"total 28\ndrwxr-xr-x  7 root root 4096 Aug 26 12:40 .\ndrwxr-xr-x  5 root root 4096 Aug 26 12:38 ..\ndrwxr-xr-x  2 root root 4096 Aug 26 12:38 .virtual_documents\ndrwxr-xr-x  2 root root 4096 Aug 26 12:40 logs\ndrwxr-xr-x  2 root root 4096 Aug 26 12:42 models\ndrwxr-xr-x  2 root root 4096 Aug 26 12:40 results\ndrwxr-xr-x 10 root root 4096 Aug 26 12:40 src\n","output_type":"stream"}]},{"cell_type":"code","source":"os.chdir(\"./src\")","metadata":{"execution":{"iopub.status.busy":"2024-08-26T12:53:00.467383Z","iopub.execute_input":"2024-08-26T12:53:00.468100Z","iopub.status.idle":"2024-08-26T12:53:00.472751Z","shell.execute_reply.started":"2024-08-26T12:53:00.468059Z","shell.execute_reply":"2024-08-26T12:53:00.471767Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"!python train.py -mode train -train_from \"../models/model_step_35000.pt\" -encoder transformer -dropout 0.1 -bert_data_path ./bert_pt/bertsumdata_ind -model_path /kaggle/working/models -result_path /kaggle/working/results -lr 2e-3 -visible_gpus 0 -gpu_ranks 0 -world_size 1 -report_every 50 -save_checkpoint_steps 100 -batch_size 3000 -decay_method noam -train_steps 35100 -accum_count 2 -log_file /kaggle/working/logs/bert_transformer_2608_1354 -use_interval true -warmup_steps 10000 -ff_size 2048 -inter_layers 2 -heads 8","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-26T12:55:23.449403Z","iopub.execute_input":"2024-08-26T12:55:23.449795Z","iopub.status.idle":"2024-08-26T12:57:35.773435Z","shell.execute_reply.started":"2024-08-26T12:55:23.449761Z","shell.execute_reply":"2024-08-26T12:57:35.772245Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"[2024-08-26 12:55:30,488 INFO] Device ID 0\n[2024-08-26 12:55:30,488 INFO] Device cuda\n[2024-08-26 12:55:30,652 INFO] loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at ../temp/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n[2024-08-26 12:55:30,653 INFO] extracting archive file ../temp/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpcwuj1jsg\n[2024-08-26 12:55:34,319 INFO] Model config {\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"max_position_embeddings\": 512,\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"type_vocab_size\": 2,\n  \"vocab_size\": 30522\n}\n\n/opt/conda/lib/python3.10/site-packages/pytorch_pretrained_bert/modeling.py:603: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = torch.load(weights_path, map_location='cpu')\n[2024-08-26 12:55:36,603 INFO] Loading checkpoint from ../models/model_step_35000.pt\n/kaggle/working/src/train.py:259: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(args.train_from,\n[2024-08-26 12:55:39,728 INFO] Summarizer(\n  (bert): Bert(\n    (model): BertModel(\n      (embeddings): BertEmbeddings(\n        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n        (position_embeddings): Embedding(512, 768)\n        (token_type_embeddings): Embedding(2, 768)\n        (LayerNorm): BertLayerNorm()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (encoder): BertEncoder(\n        (layer): ModuleList(\n          (0-11): 12 x BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): BertLayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): BertLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (pooler): BertPooler(\n        (dense): Linear(in_features=768, out_features=768, bias=True)\n        (activation): Tanh()\n      )\n    )\n  )\n  (encoder): TransformerInterEncoder(\n    (pos_emb): PositionalEncoding(\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer_inter): ModuleList(\n      (0-1): 2 x TransformerEncoderLayer(\n        (self_attn): MultiHeadedAttention(\n          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n          (softmax): Softmax(dim=-1)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n        )\n        (feed_forward): PositionwiseFeedForward(\n          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n          (dropout_1): Dropout(p=0.1, inplace=False)\n          (dropout_2): Dropout(p=0.1, inplace=False)\n        )\n        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (dropout): Dropout(p=0.1, inplace=False)\n    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n    (wo): Linear(in_features=768, out_features=1, bias=True)\n    (sigmoid): Sigmoid()\n  )\n)\ngpu_rank 0\n[2024-08-26 12:55:39,736 INFO] * number of parameters: 120512513\n[2024-08-26 12:55:39,736 INFO] Start training...\n/kaggle/working/src/models/data_loader.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  dataset = torch.load(pt_file)\n[2024-08-26 12:55:39,932 INFO] Loading train dataset from ./bert_pt/bertsumdata_ind.train.0.bert.pt, number of examples: 867\n[2024-08-26 12:56:35,547 INFO] Step 35050/35100; xent: 0.00; lr: 0.0000107;  24 docs/s;     56 sec\n[2024-08-26 12:56:50,556 INFO] Loading train dataset from ./bert_pt/bertsumdata_ind.train.0.bert.pt, number of examples: 867\n[2024-08-26 12:57:32,594 INFO] Step 35100/35100; xent: 0.00; lr: 0.0000107;  24 docs/s;    113 sec\n[2024-08-26 12:57:32,597 INFO] Saving checkpoint /kaggle/working/models/model_step_35100.pt\n[2024-08-26 12:57:34,786 INFO] Loading train dataset from ./bert_pt/bertsumdata_ind.train.0.bert.pt, number of examples: 867\n","output_type":"stream"}]},{"cell_type":"code","source":"def calc_metrics_df(df, rouge_only=True):\n    df_test_results_lst = []\n    for idx, row in df.iterrows():\n        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'], use_stemmer=True)\n        rouge_scores = scorer.score(row['summary'], row['response'])\n        rouges = dict()\n        for k,v in rouge_scores.items():\n            rouges[f\"{k}_pr\"] = round(v.precision, 4)\n            rouges[f\"{k}_re\"] = round(v.recall, 4)\n            rouges[f\"{k}_f1\"] = round(v.fmeasure, 4)\n        if rouge_only == False:\n            bert_scores = bertscore.compute(predictions=[row['response']], references=[row['summary']], lang=\"en\")\n            bert_scores.pop('hashcode')\n            result = {\n                **rouges,\n                **{f\"bertscore_{k[:2]}\": round(v[0], 4) for k,v in bert_scores.items()},\n                'meteor': round(meteor.compute(predictions=[row['response']], references=[row['summary']])['meteor'], 4),\n            }\n            row_res = {\n                'conv_id': row['conv_id'],\n                **result,\n            }\n           \n        else:\n            result = {\n                **rouges,\n            }\n            row_res = {\n                **result,\n            }\n        df_test_results_lst.append(row_res)\n    return df_test_results_lst","metadata":{"execution":{"iopub.status.busy":"2024-08-26T12:58:33.054623Z","iopub.execute_input":"2024-08-26T12:58:33.055048Z","iopub.status.idle":"2024-08-26T12:58:33.078280Z","shell.execute_reply.started":"2024-08-26T12:58:33.055009Z","shell.execute_reply":"2024-08-26T12:58:33.077334Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"!ls -la","metadata":{"execution":{"iopub.status.busy":"2024-08-26T12:58:56.367882Z","iopub.execute_input":"2024-08-26T12:58:56.368657Z","iopub.status.idle":"2024-08-26T12:58:57.362020Z","shell.execute_reply.started":"2024-08-26T12:58:56.368617Z","shell.execute_reply":"2024-08-26T12:58:57.360827Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"total 64\ndrwxr-xr-x 10 root root  4096 Aug 26 12:40 .\ndrwxr-xr-x  8 root root  4096 Aug 26 12:54 ..\ndrwxr-xr-x  2 root root  4096 Aug 26 12:54 __pycache__\ndrwxr-xr-x  2 root root  4096 Aug 26 12:40 bert_pt\n-rw-r--r--  1 root root  3895 Aug 26 12:40 distributed.py\ndrwxr-xr-x  5 root root  4096 Aug 26 12:40 json_dialogues\ndrwxr-xr-x  2 root root  4096 Aug 26 12:40 logs\ndrwxr-xr-x  3 root root  4096 Aug 26 12:40 models\ndrwxr-xr-x  3 root root  4096 Aug 26 12:40 others\ndrwxr-xr-x  3 root root  4096 Aug 26 12:40 prepro\n-rw-r--r--  1 root root  2011 Aug 26 12:40 preprocess.py\ndrwxr-xr-x  5 root root  4096 Aug 26 12:40 tokenized_dialogues\n-rw-r--r--  1 root root 12927 Aug 26 12:40 train.py\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate_rouge(split_name):\n    for root, _, files in os.walk(\"/kaggle/working\", topdown=True):\n        for results_file in files:\n            if results_file.startswith(\"result\") and results_file.endswith(\".gold\"):\n                step_num = results_file[results_file.find(\"step\")+4:-5]\n                cand_filename = results_file[:-5] + \".candidate\"\n                with open(os.path.join(root, results_file), 'r') as gold_file:\n                    with open(os.path.join(root, cand_filename), 'r') as cand_file:\n                        df = pd.DataFrame(\n                            {\n                                'summary': gold_file.readlines(),\n                                'response': cand_file.readlines(),\n                            }\n                        )\n                results_df = pd.DataFrame(calc_metrics_df(df))\n                results_df.to_csv(f\"/kaggle/working/results/{split_name}_res_bertsum_s{step_num}_2408_1930.csv\", index=False, header=True)\n                print(\"CSV saved\")\n        break\n    print(\"Finished saving evaluation results\")","metadata":{"execution":{"iopub.status.busy":"2024-08-26T13:06:52.704473Z","iopub.execute_input":"2024-08-26T13:06:52.705296Z","iopub.status.idle":"2024-08-26T13:06:52.713002Z","shell.execute_reply.started":"2024-08-26T13:06:52.705256Z","shell.execute_reply":"2024-08-26T13:06:52.712074Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def test_model_checkpoints():\n    for (root, _, files) in os.walk(\"/kaggle/working/models\"):\n        for filename in files:\n            if filename.endswith(\".pt\"):\n                step_num = filename[11:-3]\n                %env TEST_FROM={os.path.join(root, filename)}\n                !python train.py -mode test -test_from \"$TEST_FROM\" -bert_data_path \"./bert_pt/bertsumdata_ind\" -model_path \"../models\" -visible_gpus 0 -gpu_ranks 0 -batch_size 30000 -log_file \"/kaggle/working/logs/bert_transformer_2608_1354_res\" -result_path \"/kaggle/working/results\" -test_all true -report_rouge false -block_trigram true\n#     for (root, _, files) in os.walk('/kaggle/working/models'):\n#         for filename in files:\n#             if filename.endswith(\".pt\"):\n#                 step_num = filename[11:-3]\n#                 %env TEST_FROM={os.path.join(root, filename)}\n#                 !python train.py -mode test -test_from \"$TEST_FROM\" -bert_data_path \"$BERTSUM_DIR/src/bert_pt/bertsumdata_ind\" -model_path \"/kaggle/working/models\" -visible_gpus 0 -gpu_ranks 0 -batch_size 30000 -log_file \"/kaggle/working/logs/bert_transformer_2508_1641_res\" -result_path \"/kaggle/working/results\" -test_all true -report_rouge false -block_trigram true\n    evaluate_rouge(\"test\")","metadata":{"execution":{"iopub.status.busy":"2024-08-26T13:06:55.302353Z","iopub.execute_input":"2024-08-26T13:06:55.302724Z","iopub.status.idle":"2024-08-26T13:06:55.313554Z","shell.execute_reply.started":"2024-08-26T13:06:55.302687Z","shell.execute_reply":"2024-08-26T13:06:55.312539Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"!cp $BERTSUM_DIR/bert_config_uncased_base.json ../","metadata":{"execution":{"iopub.status.busy":"2024-08-26T13:10:20.905225Z","iopub.execute_input":"2024-08-26T13:10:20.905628Z","iopub.status.idle":"2024-08-26T13:10:21.947340Z","shell.execute_reply.started":"2024-08-26T13:10:20.905591Z","shell.execute_reply":"2024-08-26T13:10:21.946273Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"!ls -la ../","metadata":{"execution":{"iopub.status.busy":"2024-08-26T13:10:31.843314Z","iopub.execute_input":"2024-08-26T13:10:31.843721Z","iopub.status.idle":"2024-08-26T13:10:32.831796Z","shell.execute_reply.started":"2024-08-26T13:10:31.843681Z","shell.execute_reply":"2024-08-26T13:10:32.830686Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"total 36\ndrwxr-xr-x  8 root root 4096 Aug 26 13:10 .\ndrwxr-xr-x  5 root root 4096 Aug 26 12:38 ..\ndrwxr-xr-x  2 root root 4096 Aug 26 12:38 .virtual_documents\n-rw-r--r--  1 root root  313 Aug 26 13:10 bert_config_uncased_base.json\ndrwxr-xr-x  2 root root 4096 Aug 26 13:08 logs\ndrwxr-xr-x  2 root root 4096 Aug 26 12:57 models\ndrwxr-xr-x  2 root root 4096 Aug 26 12:40 results\ndrwxr-xr-x 10 root root 4096 Aug 26 12:40 src\ndrwxr-xr-x  2 root root 4096 Aug 26 12:54 temp\n","output_type":"stream"}]},{"cell_type":"code","source":"test_model_checkpoints()","metadata":{"execution":{"iopub.status.busy":"2024-08-26T13:10:36.772534Z","iopub.execute_input":"2024-08-26T13:10:36.772954Z","iopub.status.idle":"2024-08-26T13:12:51.837237Z","shell.execute_reply.started":"2024-08-26T13:10:36.772913Z","shell.execute_reply":"2024-08-26T13:12:51.836264Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"env: TEST_FROM=/kaggle/working/models/model_step_35100.pt\n[2024-08-26 13:10:43,720 INFO] Loading checkpoint from /kaggle/working/models/model_step_35100.pt\n/kaggle/working/src/train.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(test_from, map_location=lambda storage, loc: storage)\nNamespace(encoder='transformer', mode='test', bert_data_path='./bert_pt/bertsumdata_ind', model_path='../models', result_path='/kaggle/working/results', temp_dir='../temp', bert_config_path='../bert_config_uncased_base.json', batch_size=30000, use_interval=True, hidden_size=128, ff_size=2048, heads=8, inter_layers=2, rnn_size=512, param_init=0, param_init_glorot=True, dropout=0.1, optim='adam', lr=1, beta1=0.9, beta2=0.999, decay_method='', warmup_steps=8000, max_grad_norm=0, save_checkpoint_steps=5, accum_count=1, world_size=1, report_every=1, train_steps=1000, recall_eval=False, visible_gpus='0', gpu_ranks=[0], log_file='/kaggle/working/logs/bert_transformer_2608_1354_res', dataset='', seed=666, test_all=True, test_from='/kaggle/working/models/model_step_35100.pt', train_from='', report_rouge=False, block_trigram=True)\n/kaggle/working/src/models/data_loader.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  dataset = torch.load(pt_file)\n[2024-08-26 13:10:46,535 INFO] Loading test dataset from ./bert_pt/bertsumdata_ind.test.0.bert.pt, number of examples: 109\ngpu_rank 0\n[2024-08-26 13:10:46,540 INFO] * number of parameters: 120512513\n[2024-08-26 13:10:50,543 INFO] Validation xent: 25.9064 at step 35100\nenv: TEST_FROM=/kaggle/working/models/model_step_15000.pt\n[2024-08-26 13:10:58,364 INFO] Loading checkpoint from /kaggle/working/models/model_step_15000.pt\n/kaggle/working/src/train.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(test_from, map_location=lambda storage, loc: storage)\nNamespace(encoder='transformer', mode='test', bert_data_path='./bert_pt/bertsumdata_ind', model_path='../models', result_path='/kaggle/working/results', temp_dir='../temp', bert_config_path='../bert_config_uncased_base.json', batch_size=30000, use_interval=True, hidden_size=128, ff_size=2048, heads=8, inter_layers=2, rnn_size=512, param_init=0, param_init_glorot=True, dropout=0.1, optim='adam', lr=1, beta1=0.9, beta2=0.999, decay_method='', warmup_steps=8000, max_grad_norm=0, save_checkpoint_steps=5, accum_count=1, world_size=1, report_every=1, train_steps=1000, recall_eval=False, visible_gpus='0', gpu_ranks=[0], log_file='/kaggle/working/logs/bert_transformer_2608_1354_res', dataset='', seed=666, test_all=True, test_from='/kaggle/working/models/model_step_15000.pt', train_from='', report_rouge=False, block_trigram=True)\n/kaggle/working/src/models/data_loader.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  dataset = torch.load(pt_file)\n[2024-08-26 13:11:04,282 INFO] Loading test dataset from ./bert_pt/bertsumdata_ind.test.0.bert.pt, number of examples: 109\ngpu_rank 0\n[2024-08-26 13:11:04,287 INFO] * number of parameters: 120512513\n[2024-08-26 13:11:08,260 INFO] Validation xent: 32.8069 at step 15000\nenv: TEST_FROM=/kaggle/working/models/model_step_5000.pt\n[2024-08-26 13:11:16,051 INFO] Loading checkpoint from /kaggle/working/models/model_step_5000.pt\n/kaggle/working/src/train.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(test_from, map_location=lambda storage, loc: storage)\nNamespace(encoder='transformer', mode='test', bert_data_path='./bert_pt/bertsumdata_ind', model_path='../models', result_path='/kaggle/working/results', temp_dir='../temp', bert_config_path='../bert_config_uncased_base.json', batch_size=30000, use_interval=True, hidden_size=128, ff_size=2048, heads=8, inter_layers=2, rnn_size=512, param_init=0, param_init_glorot=True, dropout=0.1, optim='adam', lr=1, beta1=0.9, beta2=0.999, decay_method='', warmup_steps=8000, max_grad_norm=0, save_checkpoint_steps=5, accum_count=1, world_size=1, report_every=1, train_steps=1000, recall_eval=False, visible_gpus='0', gpu_ranks=[0], log_file='/kaggle/working/logs/bert_transformer_2608_1354_res', dataset='', seed=666, test_all=True, test_from='/kaggle/working/models/model_step_5000.pt', train_from='', report_rouge=False, block_trigram=True)\n/kaggle/working/src/models/data_loader.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  dataset = torch.load(pt_file)\n[2024-08-26 13:11:18,845 INFO] Loading test dataset from ./bert_pt/bertsumdata_ind.test.0.bert.pt, number of examples: 109\ngpu_rank 0\n[2024-08-26 13:11:18,850 INFO] * number of parameters: 120512513\n[2024-08-26 13:11:22,820 INFO] Validation xent: 19.2643 at step 5000\nenv: TEST_FROM=/kaggle/working/models/model_step_25000.pt\n[2024-08-26 13:11:30,570 INFO] Loading checkpoint from /kaggle/working/models/model_step_25000.pt\n/kaggle/working/src/train.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(test_from, map_location=lambda storage, loc: storage)\nNamespace(encoder='transformer', mode='test', bert_data_path='./bert_pt/bertsumdata_ind', model_path='../models', result_path='/kaggle/working/results', temp_dir='../temp', bert_config_path='../bert_config_uncased_base.json', batch_size=30000, use_interval=True, hidden_size=128, ff_size=2048, heads=8, inter_layers=2, rnn_size=512, param_init=0, param_init_glorot=True, dropout=0.1, optim='adam', lr=1, beta1=0.9, beta2=0.999, decay_method='', warmup_steps=8000, max_grad_norm=0, save_checkpoint_steps=5, accum_count=1, world_size=1, report_every=1, train_steps=1000, recall_eval=False, visible_gpus='0', gpu_ranks=[0], log_file='/kaggle/working/logs/bert_transformer_2608_1354_res', dataset='', seed=666, test_all=True, test_from='/kaggle/working/models/model_step_25000.pt', train_from='', report_rouge=False, block_trigram=True)\n/kaggle/working/src/models/data_loader.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  dataset = torch.load(pt_file)\n[2024-08-26 13:11:38,099 INFO] Loading test dataset from ./bert_pt/bertsumdata_ind.test.0.bert.pt, number of examples: 109\ngpu_rank 0\n[2024-08-26 13:11:38,104 INFO] * number of parameters: 120512513\n[2024-08-26 13:11:42,100 INFO] Validation xent: 27.7237 at step 25000\nenv: TEST_FROM=/kaggle/working/models/model_step_10000.pt\n[2024-08-26 13:11:49,775 INFO] Loading checkpoint from /kaggle/working/models/model_step_10000.pt\n/kaggle/working/src/train.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(test_from, map_location=lambda storage, loc: storage)\nNamespace(encoder='transformer', mode='test', bert_data_path='./bert_pt/bertsumdata_ind', model_path='../models', result_path='/kaggle/working/results', temp_dir='../temp', bert_config_path='../bert_config_uncased_base.json', batch_size=30000, use_interval=True, hidden_size=128, ff_size=2048, heads=8, inter_layers=2, rnn_size=512, param_init=0, param_init_glorot=True, dropout=0.1, optim='adam', lr=1, beta1=0.9, beta2=0.999, decay_method='', warmup_steps=8000, max_grad_norm=0, save_checkpoint_steps=5, accum_count=1, world_size=1, report_every=1, train_steps=1000, recall_eval=False, visible_gpus='0', gpu_ranks=[0], log_file='/kaggle/working/logs/bert_transformer_2608_1354_res', dataset='', seed=666, test_all=True, test_from='/kaggle/working/models/model_step_10000.pt', train_from='', report_rouge=False, block_trigram=True)\n/kaggle/working/src/models/data_loader.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  dataset = torch.load(pt_file)\n[2024-08-26 13:11:52,619 INFO] Loading test dataset from ./bert_pt/bertsumdata_ind.test.0.bert.pt, number of examples: 109\ngpu_rank 0\n[2024-08-26 13:11:52,624 INFO] * number of parameters: 120512513\n[2024-08-26 13:11:56,638 INFO] Validation xent: 22.2143 at step 10000\nenv: TEST_FROM=/kaggle/working/models/model_step_20000.pt\n[2024-08-26 13:12:04,487 INFO] Loading checkpoint from /kaggle/working/models/model_step_20000.pt\n/kaggle/working/src/train.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(test_from, map_location=lambda storage, loc: storage)\nNamespace(encoder='transformer', mode='test', bert_data_path='./bert_pt/bertsumdata_ind', model_path='../models', result_path='/kaggle/working/results', temp_dir='../temp', bert_config_path='../bert_config_uncased_base.json', batch_size=30000, use_interval=True, hidden_size=128, ff_size=2048, heads=8, inter_layers=2, rnn_size=512, param_init=0, param_init_glorot=True, dropout=0.1, optim='adam', lr=1, beta1=0.9, beta2=0.999, decay_method='', warmup_steps=8000, max_grad_norm=0, save_checkpoint_steps=5, accum_count=1, world_size=1, report_every=1, train_steps=1000, recall_eval=False, visible_gpus='0', gpu_ranks=[0], log_file='/kaggle/working/logs/bert_transformer_2608_1354_res', dataset='', seed=666, test_all=True, test_from='/kaggle/working/models/model_step_20000.pt', train_from='', report_rouge=False, block_trigram=True)\n/kaggle/working/src/models/data_loader.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  dataset = torch.load(pt_file)\n[2024-08-26 13:12:07,286 INFO] Loading test dataset from ./bert_pt/bertsumdata_ind.test.0.bert.pt, number of examples: 109\ngpu_rank 0\n[2024-08-26 13:12:07,291 INFO] * number of parameters: 120512513\n[2024-08-26 13:12:11,321 INFO] Validation xent: 22.6329 at step 20000\nenv: TEST_FROM=/kaggle/working/models/model_step_35000.pt\n[2024-08-26 13:12:19,079 INFO] Loading checkpoint from /kaggle/working/models/model_step_35000.pt\n/kaggle/working/src/train.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(test_from, map_location=lambda storage, loc: storage)\nNamespace(encoder='transformer', mode='test', bert_data_path='./bert_pt/bertsumdata_ind', model_path='../models', result_path='/kaggle/working/results', temp_dir='../temp', bert_config_path='../bert_config_uncased_base.json', batch_size=30000, use_interval=True, hidden_size=128, ff_size=2048, heads=8, inter_layers=2, rnn_size=512, param_init=0, param_init_glorot=True, dropout=0.1, optim='adam', lr=1, beta1=0.9, beta2=0.999, decay_method='', warmup_steps=8000, max_grad_norm=0, save_checkpoint_steps=5, accum_count=1, world_size=1, report_every=1, train_steps=1000, recall_eval=False, visible_gpus='0', gpu_ranks=[0], log_file='/kaggle/working/logs/bert_transformer_2608_1354_res', dataset='', seed=666, test_all=True, test_from='/kaggle/working/models/model_step_35000.pt', train_from='', report_rouge=False, block_trigram=True)\n/kaggle/working/src/models/data_loader.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  dataset = torch.load(pt_file)\n[2024-08-26 13:12:21,830 INFO] Loading test dataset from ./bert_pt/bertsumdata_ind.test.0.bert.pt, number of examples: 109\ngpu_rank 0\n[2024-08-26 13:12:21,835 INFO] * number of parameters: 120512513\n[2024-08-26 13:12:25,901 INFO] Validation xent: 24.8395 at step 35000\nenv: TEST_FROM=/kaggle/working/models/model_step_30000.pt\n[2024-08-26 13:12:33,719 INFO] Loading checkpoint from /kaggle/working/models/model_step_30000.pt\n/kaggle/working/src/train.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(test_from, map_location=lambda storage, loc: storage)\nNamespace(encoder='transformer', mode='test', bert_data_path='./bert_pt/bertsumdata_ind', model_path='../models', result_path='/kaggle/working/results', temp_dir='../temp', bert_config_path='../bert_config_uncased_base.json', batch_size=30000, use_interval=True, hidden_size=128, ff_size=2048, heads=8, inter_layers=2, rnn_size=512, param_init=0, param_init_glorot=True, dropout=0.1, optim='adam', lr=1, beta1=0.9, beta2=0.999, decay_method='', warmup_steps=8000, max_grad_norm=0, save_checkpoint_steps=5, accum_count=1, world_size=1, report_every=1, train_steps=1000, recall_eval=False, visible_gpus='0', gpu_ranks=[0], log_file='/kaggle/working/logs/bert_transformer_2608_1354_res', dataset='', seed=666, test_all=True, test_from='/kaggle/working/models/model_step_30000.pt', train_from='', report_rouge=False, block_trigram=True)\n/kaggle/working/src/models/data_loader.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  dataset = torch.load(pt_file)\n[2024-08-26 13:12:37,498 INFO] Loading test dataset from ./bert_pt/bertsumdata_ind.test.0.bert.pt, number of examples: 109\ngpu_rank 0\n[2024-08-26 13:12:37,503 INFO] * number of parameters: 120512513\n[2024-08-26 13:12:41,600 INFO] Validation xent: 31.3549 at step 30000\nCSV saved\nCSV saved\nCSV saved\nCSV saved\nCSV saved\nCSV saved\nCSV saved\nCSV saved\nFinished saving evaluation results\n","output_type":"stream"}]},{"cell_type":"code","source":"# Log to wandb\n!pip install wandb","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Based on official docs: https://docs.wandb.ai/guides/track/log/working-with-csv\nimport wandb\nos.environ[\"WANDB_PROJECT\"] = \"aiml-thesis-train\"\nrun = wandb.init(settings=wandb.Settings(start_method=\"thread\"))\nfor root, _, files in os.walk(\"/kaggle/working/results\"):\n    for res_file in files:\n        file_path = os.path.join(root,res_file)\n        df = pd.read_csv(file_path)\n        tbl = wandb.Table(dataframe=df)\n#         artif = wandb.Artifact(res_file[:-4], type=\"dataset\")\n#         artif.add(tbl, res_file[:-4] + \"_table\")\n#         artif.add_file(file_path)\n#         run.log_artifact(artif)\n        run.log({\"bert-results-table\":tbl})","metadata":{"execution":{"iopub.status.busy":"2024-08-26T14:23:20.513097Z","iopub.execute_input":"2024-08-26T14:23:20.513483Z","iopub.status.idle":"2024-08-26T14:23:39.994373Z","shell.execute_reply.started":"2024-08-26T14:23:20.513445Z","shell.execute_reply":"2024-08-26T14:23:39.993205Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:rykhg502) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.176 MB of 0.176 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">earnest-sea-28</strong> at: <a href='https://wandb.ai/dawidk5ul/aiml-thesis-train/runs/rykhg502' target=\"_blank\">https://wandb.ai/dawidk5ul/aiml-thesis-train/runs/rykhg502</a><br/> View project at: <a href='https://wandb.ai/dawidk5ul/aiml-thesis-train' target=\"_blank\">https://wandb.ai/dawidk5ul/aiml-thesis-train</a><br/>Synced 4 W&B file(s), 0 media file(s), 16 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240826_141600-rykhg502/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:rykhg502). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/src/wandb/run-20240826_142320-ry941qpz</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dawidk5ul/aiml-thesis-train/runs/ry941qpz' target=\"_blank\">classic-hill-29</a></strong> to <a href='https://wandb.ai/dawidk5ul/aiml-thesis-train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dawidk5ul/aiml-thesis-train' target=\"_blank\">https://wandb.ai/dawidk5ul/aiml-thesis-train</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dawidk5ul/aiml-thesis-train/runs/ry941qpz' target=\"_blank\">https://wandb.ai/dawidk5ul/aiml-thesis-train/runs/ry941qpz</a>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 14\u001b[0m\n\u001b[1;32m      9\u001b[0m         tbl \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39mTable(dataframe\u001b[38;5;241m=\u001b[39mdf)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#         artif = wandb.Artifact(res_file[:-4], type=\"dataset\")\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#         artif.add(tbl, res_file[:-4] + \"_table\")\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#         artif.add_file(file_path)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#         run.log_artifact(artif)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m         \u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_table\u001b[49m(tbl)\n","\u001b[0;31mAttributeError\u001b[0m: 'Run' object has no attribute 'log_table'"],"ename":"AttributeError","evalue":"'Run' object has no attribute 'log_table'","output_type":"error"}]}]}