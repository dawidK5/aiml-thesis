{"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8748939,"sourceType":"datasetVersion","datasetId":5254425}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"09513166db494a318fe4bd2ff4fe8b73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bad09d132dcc420fbad7ace8cc25aa06","placeholder":"​","style":"IPY_MODEL_20787ae61e94452aae73869c5382ff1b","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"19649549a1ad47368ec9f6eeba1e80ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20787ae61e94452aae73869c5382ff1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25bd97f157d8485fb15438d25d83421c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c792771c4604d9b8f6bcda700f2ad74","placeholder":"​","style":"IPY_MODEL_36781c62f1164acabc7371ceb966e8cc","value":"Token is valid (permission: write)."}},"26b0af06bf1549bd8f16e297a3d5c4fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34efbeb9bdcf42b28bcfdf48289bb943":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36781c62f1164acabc7371ceb966e8cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3bd1b8a5cbdf4345b34a6042ad3c6383":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d0bb7ba88104e458caaaf9c72914b97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44d30b0ecad54f818f27bbd1858cdf3f","placeholder":"​","style":"IPY_MODEL_85e73a9905ba41c286b0645f0c667362","value":"Login successful"}},"44d30b0ecad54f818f27bbd1858cdf3f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5685a3fe6b084791b1c41bede0ee8429":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5764ccc3c9b943ac9031bb4fbf65ee84":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dcb4bd1b7424f698dcfe1586ecaaa87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7393008614c94b7f9aee294715d1f9c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6eb7b2e427a4fb3b984a0346394555a","placeholder":"​","style":"IPY_MODEL_34efbeb9bdcf42b28bcfdf48289bb943","value":"Your token has been saved in your configured git credential helpers (store)."}},"7b5d107e75ec4226b2f951fa5eac32c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"85e73a9905ba41c286b0645f0c667362":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c792771c4604d9b8f6bcda700f2ad74":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91cf6c949361472e8cdc02a27371892b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"PasswordModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_5764ccc3c9b943ac9031bb4fbf65ee84","placeholder":"​","style":"IPY_MODEL_f6f5badeb1f749d8a1a74c737ea45b81","value":""}},"9d286f232614404eac3e78415a823171":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26b0af06bf1549bd8f16e297a3d5c4fa","placeholder":"​","style":"IPY_MODEL_b289ce6929414af38bd4cd4ddf68bfe4","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"a6333daeaf584192b2d8222134dc02a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb0ffca70a4645458b4650ff588f82cc","placeholder":"​","style":"IPY_MODEL_fec956e2f3ac4760a951569986ebb5c2","value":"Your token has been saved to /root/.cache/huggingface/token"}},"b289ce6929414af38bd4cd4ddf68bfe4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b292b711914d4f14abd2436aeb8050f8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3bfd48d65b748349afd7e3e5000baff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"b6eb7b2e427a4fb3b984a0346394555a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bad09d132dcc420fbad7ace8cc25aa06":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcab8a3e3c3f45d48890e88d50d8e982":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_b292b711914d4f14abd2436aeb8050f8","style":"IPY_MODEL_b3bfd48d65b748349afd7e3e5000baff","tooltip":""}},"c42b74a51b7843c7b8a9fca7d90bfd1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19649549a1ad47368ec9f6eeba1e80ff","placeholder":"​","style":"IPY_MODEL_3bd1b8a5cbdf4345b34a6042ad3c6383","value":"Connecting..."}},"d1a558c379ac48cc80c19ef9898d871d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_25bd97f157d8485fb15438d25d83421c","IPY_MODEL_7393008614c94b7f9aee294715d1f9c8","IPY_MODEL_a6333daeaf584192b2d8222134dc02a9","IPY_MODEL_3d0bb7ba88104e458caaaf9c72914b97"],"layout":"IPY_MODEL_7b5d107e75ec4226b2f951fa5eac32c7"}},"dbbfbb222a7d4ce18c1c7b655fc89ae1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"CheckboxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_5685a3fe6b084791b1c41bede0ee8429","style":"IPY_MODEL_6dcb4bd1b7424f698dcfe1586ecaaa87","value":true}},"f6f5badeb1f749d8a1a74c737ea45b81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb0ffca70a4645458b4650ff588f82cc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fec956e2f3ac4760a951569986ebb5c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Abstractive summaries - Train DistilBART on TWEETSUMM dataset","metadata":{"id":"AvCot6IFw3LG"}},{"cell_type":"code","source":"import json, re\nfrom huggingface_hub import notebook_login\nimport pandas as pd\nimport numpy as np\nimport os, time, datetime\n\ntry:\n    from datasets import load_dataset\nexcept:\n    !pip install datasets\n    from datasets import load_dataset\n\ntry:\n    import accelerate\nexcept:\n    !pip install -U 'accelerate==0.27.2'\n    import accelerate\n\n\nimport transformers\nfrom transformers import AutoTokenizer, DataCollatorForSeq2Seq, pipeline, set_seed\nfrom transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\nfrom transformers import GenerationConfig\n\ntry:\n    import wandb\nexcept:\n    !pip install wandb\n\nprint(transformers.__version__, accelerate.__version__)\n","metadata":{"id":"csIsnw2147iB","outputId":"b1168797-2e98-4a6a-81e1-9e079f98ab53","scrolled":true,"execution":{"iopub.status.busy":"2024-07-08T13:15:39.921121Z","iopub.execute_input":"2024-07-08T13:15:39.921479Z","iopub.status.idle":"2024-07-08T13:15:57.694563Z","shell.execute_reply.started":"2024-07-08T13:15:39.921451Z","shell.execute_reply":"2024-07-08T13:15:57.693581Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-07-08 13:15:48.336174: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-08 13:15:48.336271: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-08 13:15:48.473051: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"4.41.2 0.30.1\n","output_type":"stream"}]},{"cell_type":"code","source":"# try:\n#   import transformers\n# except:\n#   !pip install -U transformers[torch]\n#   import transformers","metadata":{"execution":{"iopub.status.busy":"2024-07-08T13:15:57.696393Z","iopub.execute_input":"2024-07-08T13:15:57.697003Z","iopub.status.idle":"2024-07-08T13:15:57.701041Z","shell.execute_reply.started":"2024-07-08T13:15:57.696975Z","shell.execute_reply":"2024-07-08T13:15:57.700001Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# for x in dir(transformers):\n#     if \"torch\" in x:\n#         print(x)\n        \n# print(transformers.is_tf_available())","metadata":{"execution":{"iopub.status.busy":"2024-07-08T13:15:57.702200Z","iopub.execute_input":"2024-07-08T13:15:57.702532Z","iopub.status.idle":"2024-07-08T13:15:57.726628Z","shell.execute_reply.started":"2024-07-08T13:15:57.702500Z","shell.execute_reply":"2024-07-08T13:15:57.725892Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"ds_dir = \"\"\ntry:\n    HF_TOKEN =  os.environ['HF_TOKEN']\nexcept:\n    HF_TOKEN = \"\"\n\nif 'google.colab' in str(get_ipython()):\n  print(\"Running on Colab\")\n  from google.colab import drive, userdata\n  drive.mount('/content/drive')\n  HF_TOKEN = userdata.get('HF_TOKEN')\nelif os.environ['KAGGLE_KERNEL_RUN_TYPE']:\n  from kaggle_secrets import UserSecretsClient\n  print(\"Running on Kaggle\")\n  ds_dir = \"/kaggle/input/tweet-data-2106-1512/\"\n  user_secrets = UserSecretsClient()\n  HF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")\n  WANDB_API_KEY = user_secrets.get_secret(\"WANDB_API_KEY\")\n  os.environ['WANDB_API_KEY'] = WANDB_API_KEY\n","metadata":{"id":"D7StYsAaxJLT","outputId":"3690cf47-554a-424d-b42e-e8f77bb4bbf5","execution":{"iopub.status.busy":"2024-07-08T13:15:57.729080Z","iopub.execute_input":"2024-07-08T13:15:57.729400Z","iopub.status.idle":"2024-07-08T13:15:57.932750Z","shell.execute_reply.started":"2024-07-08T13:15:57.729374Z","shell.execute_reply":"2024-07-08T13:15:57.932027Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Running on Kaggle\n","output_type":"stream"}]},{"cell_type":"code","source":"set_seed(17)\n\nos.environ[\"WANDB_PROJECT\"] = \"aiml-thesis-train\"\nos.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n\nwandb.init(settings=wandb.Settings(start_method=\"thread\"))","metadata":{"id":"XCVrFPA4GL-h","outputId":"228dbbaf-c276-495e-e759-0ecb0b4a1ebb","scrolled":true,"execution":{"iopub.status.busy":"2024-07-08T13:15:57.933814Z","iopub.execute_input":"2024-07-08T13:15:57.934131Z","iopub.status.idle":"2024-07-08T13:16:17.065893Z","shell.execute_reply.started":"2024-07-08T13:15:57.934106Z","shell.execute_reply":"2024-07-08T13:16:17.064905Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdawidk5\u001b[0m (\u001b[33mdawidk5ul\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240708_131600-ilmjvg66</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dawidk5ul/aiml-thesis-train/runs/ilmjvg66' target=\"_blank\">ancient-fog-15</a></strong> to <a href='https://wandb.ai/dawidk5ul/aiml-thesis-train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dawidk5ul/aiml-thesis-train' target=\"_blank\">https://wandb.ai/dawidk5ul/aiml-thesis-train</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dawidk5ul/aiml-thesis-train/runs/ilmjvg66' target=\"_blank\">https://wandb.ai/dawidk5ul/aiml-thesis-train/runs/ilmjvg66</a>"},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dawidk5ul/aiml-thesis-train/runs/ilmjvg66?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7a20128bd930>"},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token=HF_TOKEN)","metadata":{"id":"QoMm76b2i2NX","outputId":"f5df06b4-ac4d-4be9-8044-20010745149b","execution":{"iopub.status.busy":"2024-07-08T13:16:17.067206Z","iopub.execute_input":"2024-07-08T13:16:17.067583Z","iopub.status.idle":"2024-07-08T13:16:17.157083Z","shell.execute_reply.started":"2024-07-08T13:16:17.067545Z","shell.execute_reply":"2024-07-08T13:16:17.155933Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load data","metadata":{"id":"xP2HgEaKi2Nk"}},{"cell_type":"code","source":"train_df_temp = pd.read_feather(ds_dir + \"data/train_dial_abs_noex_noco_2006.feather\")\ntrain_df_temp.drop(columns=['index', 'company'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T13:16:17.158707Z","iopub.execute_input":"2024-07-08T13:16:17.159117Z","iopub.status.idle":"2024-07-08T13:16:17.223749Z","shell.execute_reply.started":"2024-07-08T13:16:17.159080Z","shell.execute_reply":"2024-07-08T13:16:17.222801Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# lengths_train_summaries = [len(row) for row in tokenized_tweetsumm_abs['train']['input_ids']]\n# print(\"Abstractive summaries training lengths[mean,max,min]:\", np.mean(lengths_train_summaries), np.max(lengths_train_summaries), np.min(lengths_train_summaries))","metadata":{"execution":{"iopub.status.busy":"2024-07-08T13:16:17.225064Z","iopub.execute_input":"2024-07-08T13:16:17.225889Z","iopub.status.idle":"2024-07-08T13:16:17.230163Z","shell.execute_reply.started":"2024-07-08T13:16:17.225835Z","shell.execute_reply":"2024-07-08T13:16:17.229222Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"val_df_temp = pd.read_feather(ds_dir + \"data/val_dial_abs_noex_noco_2006.feather\")\nval_df_temp.drop(columns=['index', 'company'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T13:16:17.231266Z","iopub.execute_input":"2024-07-08T13:16:17.231534Z","iopub.status.idle":"2024-07-08T13:16:17.249227Z","shell.execute_reply.started":"2024-07-08T13:16:17.231504Z","shell.execute_reply":"2024-07-08T13:16:17.248528Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Only for testing statistics display\n# train_df_temp[0:100]","metadata":{"execution":{"iopub.status.busy":"2024-07-08T13:16:17.253308Z","iopub.execute_input":"2024-07-08T13:16:17.253632Z","iopub.status.idle":"2024-07-08T13:16:17.257777Z","shell.execute_reply.started":"2024-07-08T13:16:17.253608Z","shell.execute_reply":"2024-07-08T13:16:17.256919Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset, DatasetDict\n\ntweetsum_train_val_abs = DatasetDict(\n {\n 'train': Dataset.from_pandas(train_df_temp),\n 'validation': Dataset.from_pandas(val_df_temp)\n }\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T13:16:17.259010Z","iopub.execute_input":"2024-07-08T13:16:17.259272Z","iopub.status.idle":"2024-07-08T13:16:17.293136Z","shell.execute_reply.started":"2024-07-08T13:16:17.259250Z","shell.execute_reply":"2024-07-08T13:16:17.292242Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"tweetsum_train_val_abs['train'][10]","metadata":{"execution":{"iopub.status.busy":"2024-07-08T13:16:17.294102Z","iopub.execute_input":"2024-07-08T13:16:17.294331Z","iopub.status.idle":"2024-07-08T13:16:17.302166Z","shell.execute_reply.started":"2024-07-08T13:16:17.294311Z","shell.execute_reply":"2024-07-08T13:16:17.301182Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'dialogue': \"<USER> Bought these biscuits a couple of weeks ago, only just opened and looked at the best before date... @49975 <SYSTEM> @393926 We can't see a picture of the best before date or biscuits attached to your tweets here. Please can you tweet or DM it to us again? Thanks. <URL> <USER> @marksandspencer  <URL> @marksandspencer  <URL> @marksandspencer  <URL> <SYSTEM> @393926 We'd certainly like to take a closer look into this. Please DM us a picture of your full receipt. <URL> <USER> @marksandspencer Don’t have a receipt as they were bought for my grandparents 3 weeks ago and have only just realised the date on them @marksandspencer The biscuits were purchased at the Marks and Spencer’s Store at the Ricoh Arena, Coventry <SYSTEM> @393926 Did yo use a sparks card on your transaction, Cian? <USER> @marksandspencer Yes <SYSTEM> @393926 Hi Cian. I'm really sorry to see this, especially when it was such a lovely gesture too! No worries though - we got your back ;) 1/3 @393926 Is there a barcode on the tin anywhere? If there is, could you take a pic and DM it to us please &amp; also  let us know how much they cost? 2/3 @393926 Once we have those, we'll explain what happens next. Cheers, Steve :) 3/3\",\n 'summary': \"Customer bought a tin of biscuits and the use by date was old. Wants a photo of the tin and date and how much they cost then they'll explain what happens next.\"}"},"metadata":{}}]},{"cell_type":"code","source":"# Source: https://huggingface.co/docs/transformers/en/tasks/summarization\n\ndef preprocess_function(examples):\n  prefix = \"summarize: \"\n  inputs = [prefix + dial for dial in examples[\"dialogue\"]]\n  model_inputs = tokenizer(inputs, max_length=512, truncation=True) # same params as tweetsumm paper\n  labels = tokenizer(text_target=examples[\"summary\"], max_length=80, truncation=True)\n  model_inputs[\"labels\"] = labels[\"input_ids\"]\n  return model_inputs","metadata":{"id":"vVQdGPfZw3Lb","execution":{"iopub.status.busy":"2024-07-08T13:16:17.303204Z","iopub.execute_input":"2024-07-08T13:16:17.303681Z","iopub.status.idle":"2024-07-08T13:16:17.310806Z","shell.execute_reply.started":"2024-07-08T13:16:17.303650Z","shell.execute_reply":"2024-07-08T13:16:17.310006Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"checkpoint_bart = \"sshleifer/distilbart-xsum-12-6\"","metadata":{"execution":{"iopub.status.busy":"2024-07-08T13:16:17.312057Z","iopub.execute_input":"2024-07-08T13:16:17.312365Z","iopub.status.idle":"2024-07-08T13:16:17.320482Z","shell.execute_reply.started":"2024-07-08T13:16:17.312341Z","shell.execute_reply":"2024-07-08T13:16:17.319281Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"bart_tokenizer = AutoTokenizer.from_pretrained(checkpoint_bart)\ntokenizer = bart_tokenizer\ntokenized_tweetsumm_abs = tweetsum_train_val_abs.map(preprocess_function, batched=True)","metadata":{"id":"F-hzIHQ9w3Lb","execution":{"iopub.status.busy":"2024-07-08T13:16:17.321646Z","iopub.execute_input":"2024-07-08T13:16:17.321932Z","iopub.status.idle":"2024-07-08T13:16:18.875785Z","shell.execute_reply.started":"2024-07-08T13:16:17.321910Z","shell.execute_reply":"2024-07-08T13:16:18.874665Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cca129da82c4002af5ba114b48e9779"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.59k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bda82aa54378438d82d742473053d4dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b90d688d25a342c7b27e8e9773b56b31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80e4b56b4e8a49259379781d079f2004"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/878 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2457eb0482a4d12824978c18eb40058"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/110 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b3b55c83f5d4a179906f071c8537e1a"}},"metadata":{}}]},{"cell_type":"code","source":"# min_ln = (9999, -1, 'train')\n# max_ln = (0, -1, 'train')\n# mean_ln = 0\n# for spl in ('validation','train'):\n#     summ_lengths = []\n#     for idx, summ in enumerate(tokenized_tweetsumm_abs[spl]['summary']):\n#         summ_length = len(str(summ).split())\n        \n#         min_ln = (min(min_ln[0], summ_length),idx, spl)\n#         max_ln = (max(max_ln[0], summ_length),idx, spl)\n#         mean_ln += summ_length\nall_summ_lengths = []\n\nfor spl in ('validation', 'train'):\n  summ_lengths = [len(str(summ).split()) for summ in tokenized_tweetsumm_abs[spl]['summary']]\n  all_summ_lengths = np.concatenate((all_summ_lengths, summ_lengths), axis=0, dtype=int, casting='unsafe')\n\nmin_length = min(all_summ_lengths)\nmax_length = max(all_summ_lengths)\nmin_summary = None\nmax_summary = None\n\nfor spl in ('validation', 'train'):\n  for idx, summ in enumerate(tokenized_tweetsumm_abs[spl]['summary']):\n    summ_length = len(str(summ).split())\n    if summ_length == min_length:\n      min_summary = summ\n    elif summ_length == max_length:\n      max_summary = summ\nprint(\"Min summary length:\", min_length, \"Summary:\", min_summary)\nprint(\"Max summary length:\", max_length, \"Summary:\", max_summary)\n# print(\"Avg summary length:\", mean_ln/ (len(tokenized_tweetsumm_abs['train'])+len(tokenized_tweetsumm_abs['validation'])))\n# print(\"Confirmed min summary length:\", len(tokenized_tweetsumm_abs[spl][int(np.argmin(summ_lengths))-1]['summary'].split()))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T13:16:18.877114Z","iopub.execute_input":"2024-07-08T13:16:18.877444Z","iopub.status.idle":"2024-07-08T13:16:18.901019Z","shell.execute_reply.started":"2024-07-08T13:16:18.877411Z","shell.execute_reply":"2024-07-08T13:16:18.899838Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Min summary length: 10 Summary: Customer is complaining about VirginTrains timings. Agent updated the timings.\nMax summary length: 96 Summary: The customer complains that it was a very short sale, he got a notification that he had a tech sale, the drone was included at $349, but by the next morning it's $499 and he could not purchase it since he left his wallet at office the previous day. The agent apologises since their prices are subject to change, as stated in their terms and conditions and requests to provide the catalogue number for the drone, so he can advise better and suggests that in future days the product can be reserved for the next days.\n","output_type":"stream"}]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint_bart)","metadata":{"id":"irJUvr6gi2No","execution":{"iopub.status.busy":"2024-07-08T13:16:18.902266Z","iopub.execute_input":"2024-07-08T13:16:18.902567Z","iopub.status.idle":"2024-07-08T13:16:18.912923Z","shell.execute_reply.started":"2024-07-08T13:16:18.902514Z","shell.execute_reply":"2024-07-08T13:16:18.911824Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print(json.dumps(tokenized_tweetsumm_abs['train'][5], indent=2))","metadata":{"id":"nDm22ccniBzX","outputId":"414453f7-b626-4bb3-970d-fa32e85cd29b","scrolled":true,"execution":{"iopub.status.busy":"2024-07-08T13:16:18.914513Z","iopub.execute_input":"2024-07-08T13:16:18.915369Z","iopub.status.idle":"2024-07-08T13:16:18.926810Z","shell.execute_reply.started":"2024-07-08T13:16:18.915334Z","shell.execute_reply":"2024-07-08T13:16:18.925912Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"{\n  \"dialogue\": \"<USER> @115802 @AirAsiaSupport doesn\\u2019t seem like a customer\\u2019s time/money is of value to you! just because you are a low-cost carrier!? Nvr again! ! <SYSTEM> @366867 Sorry for the delay, Saim. Flight Change is subject to Change Fee (per person/per flight) at <URL> plus &gt;&gt; @366867 &gt;&gt;Fare Difference, so you only have to pay for those. If you think it's cheaper to make a new booking, you may consider so.-Floi <USER> @AirAsiaSupport bt how can the rescheduling charges be more than the ticket charges. <SYSTEM> @366867 Really sorry as flight change is subject to change fee +  fare difference accordingly.Thanks - Ed <USER> @AirAsiaSupport i will go ahead with fresh booking bt will u move my baggage n food to the new pnr? <SYSTEM> @366867 Hi Saim , We are sorry as the add ons cannot be transferred to another booking. Thanks - Khairul <USER> @AirAsiaSupport @115802 @121276 never seen somebody sooo least bothered about customer... feel cheated.. and feel robbed... @AirAsiaSupport did nt expect this from such a reputed airlines... #cheated #robbed <SYSTEM> @366867 Terribly sorry for the inconvenience but if you make a flight change, the baggage will be transfered to your new flight. However, @366867 if you make a new booking, it can not be transferred since it is a totally different booking. -Yana <USER> @AirAsiaSupport as a basic courtesy and for customer satisfaction u can take so little of efforts... remember a satisfied customer is a best marketing @AirAsiaSupport its a request plz support <SYSTEM> @366867 Really sorry Saim, but they're non-transferable and non-refundable. We just have to be fair to all of our guests &gt;&gt; @366867 &gt;&gt;hence Ticket rules apply. However, you may opt for Tax refund in case of No Show. Thanks for your patience. -Floi\",\n  \"summary\": \"The client is visibly upset with the service. The agent cannot help the customer.\",\n  \"input_ids\": [\n    0,\n    18581,\n    3916,\n    2072,\n    35,\n    28696,\n    47955,\n    15698,\n    787,\n    15314,\n    37674,\n    787,\n    17906,\n    20892,\n    38873,\n    630,\n    17,\n    27,\n    90,\n    2045,\n    101,\n    10,\n    2111,\n    17,\n    27,\n    29,\n    86,\n    73,\n    17479,\n    16,\n    9,\n    923,\n    7,\n    47,\n    328,\n    95,\n    142,\n    47,\n    32,\n    10,\n    614,\n    12,\n    10111,\n    6994,\n    42648,\n    234,\n    37032,\n    456,\n    328,\n    27785,\n    28696,\n    21134,\n    43896,\n    15698,\n    787,\n    3367,\n    4671,\n    4111,\n    19719,\n    13,\n    5,\n    4646,\n    6,\n    208,\n    7146,\n    4,\n    13275,\n    7229,\n    16,\n    2087,\n    7,\n    7229,\n    30745,\n    36,\n    1741,\n    621,\n    73,\n    1741,\n    2524,\n    43,\n    23,\n    28696,\n    42703,\n    15698,\n    2704,\n    359,\n    19377,\n    131,\n    947,\n    19377,\n    131,\n    787,\n    3367,\n    4671,\n    4111,\n    359,\n    19377,\n    131,\n    947,\n    19377,\n    131,\n    597,\n    1322,\n    40905,\n    6,\n    98,\n    47,\n    129,\n    33,\n    7,\n    582,\n    13,\n    167,\n    4,\n    318,\n    47,\n    206,\n    24,\n    18,\n    7246,\n    7,\n    146,\n    10,\n    92,\n    12666,\n    6,\n    47,\n    189,\n    1701,\n    98,\n    3358,\n    45203,\n    118,\n    28696,\n    47955,\n    15698,\n    787,\n    17906,\n    20892,\n    38873,\n    741,\n    90,\n    141,\n    64,\n    5,\n    5032,\n    3804,\n    17556,\n    1103,\n    28,\n    55,\n    87,\n    5,\n    3682,\n    1103,\n    4,\n    28696,\n    21134,\n    43896,\n    15698,\n    787,\n    3367,\n    4671,\n    4111,\n    16923,\n    6661,\n    25,\n    2524,\n    464,\n    16,\n    2087,\n    7,\n    464,\n    4029,\n    2055,\n    1437,\n    11031,\n    2249,\n    14649,\n    4,\n    22086,\n    111,\n    2344,\n    28696,\n    47955,\n    15698,\n    787,\n    17906,\n    20892,\n    38873,\n    939,\n    40,\n    213,\n    789,\n    19,\n    2310,\n    12666,\n    741,\n    90,\n    40,\n    1717,\n    517,\n    127,\n    22235,\n    295,\n    689,\n    7,\n    5,\n    92,\n    181,\n    37643,\n    116,\n    28696,\n    21134,\n    43896,\n    15698,\n    787,\n    3367,\n    4671,\n    4111,\n    12289,\n    208,\n    7146,\n    2156,\n    166,\n    32,\n    6661,\n    25,\n    5,\n    1606,\n    15,\n    29,\n    1395,\n    28,\n    7225,\n    7,\n    277,\n    12666,\n    4,\n    4557,\n    111,\n    2218,\n    2456,\n    922,\n    28696,\n    47955,\n    15698,\n    787,\n    17906,\n    20892,\n    38873,\n    787,\n    15314,\n    37674,\n    787,\n    1092,\n    1092,\n    5067,\n    393,\n    450,\n    4909,\n    98,\n    3036,\n    513,\n    18523,\n    59,\n    2111,\n    734,\n    619,\n    25177,\n    7586,\n    8,\n    619,\n    13266,\n    734,\n    787,\n    17906,\n    20892,\n    38873,\n    222,\n    295,\n    90,\n    1057,\n    42,\n    31,\n    215,\n    10,\n    2851,\n    13735,\n    8537,\n    734,\n    849,\n    2871,\n    1070,\n    849,\n    17569,\n    5134,\n    28696,\n    21134,\n    43896,\n    15698,\n    787,\n    3367,\n    4671,\n    4111,\n    5094,\n    46529,\n    6661,\n    13,\n    5,\n    24109,\n    53,\n    114,\n    47,\n    146,\n    10,\n    2524,\n    464,\n    6,\n    5,\n    22235,\n    40,\n    28,\n    30387,\n    3215,\n    7,\n    110,\n    92,\n    2524,\n    4,\n    635,\n    6,\n    787,\n    3367,\n    4671,\n    4111,\n    114,\n    47,\n    146,\n    10,\n    92,\n    12666,\n    6,\n    24,\n    64,\n    45,\n    28,\n    7225,\n    187,\n    24,\n    16,\n    10,\n    4940,\n    430,\n    12666,\n    4,\n    111,\n    975,\n    1113,\n    28696,\n    47955,\n    15698,\n    787,\n    17906,\n    20892,\n    38873,\n    25,\n    10,\n    3280,\n    7676,\n    8,\n    13,\n    2111,\n    11658,\n    1717,\n    64,\n    185,\n    98,\n    410,\n    9,\n    1170,\n    734,\n    2145,\n    10,\n    10028,\n    2111,\n    16,\n    10,\n    275,\n    2474,\n    787,\n    17906,\n    20892,\n    38873,\n    63,\n    10,\n    2069,\n    2968,\n    329,\n    323,\n    28696,\n    21134,\n    43896,\n    15698,\n    787,\n    3367,\n    4671,\n    4111,\n    16923,\n    6661,\n    208,\n    7146,\n    6,\n    53,\n    51,\n    214,\n    786,\n    12,\n    40095,\n    868,\n    8,\n    786,\n    12,\n    13043,\n    3194,\n    868,\n    4,\n    166,\n    95,\n    33,\n    7,\n    28,\n    2105,\n    7,\n    70,\n    9,\n    84,\n    3958,\n    359,\n    19377,\n    131,\n    947,\n    19377,\n    131,\n    787,\n    3367,\n    4671,\n    4111,\n    359,\n    19377,\n    131,\n    947,\n    19377,\n    131,\n    2457,\n    1755,\n    17398,\n    1492,\n    3253,\n    4,\n    635,\n    6,\n    47,\n    189,\n    7996,\n    13,\n    6394,\n    12173,\n    11,\n    403,\n    9,\n    440,\n    2907,\n    4,\n    4557,\n    13,\n    110,\n    11383,\n    4,\n    111,\n    45203,\n    118,\n    2\n  ],\n  \"attention_mask\": [\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1,\n    1\n  ],\n  \"labels\": [\n    0,\n    133,\n    3653,\n    16,\n    23472,\n    4904,\n    19,\n    5,\n    544,\n    4,\n    20,\n    2936,\n    1395,\n    244,\n    5,\n    2111,\n    4,\n    2\n  ]\n}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Setup Training Evaluation","metadata":{"id":"97ha331Ii2Np"}},{"cell_type":"code","source":"try:\n  import evaluate\n  rouge = evaluate.load(\"rouge\")\n  meteor = evaluate.load(\"meteor\")\n  bertscore = evaluate.load(\"bertscore\")\nexcept:\n  !pip install evaluate nltk rouge_score bert_score\n  !pip install -U nltk\n  import evaluate\n  rouge = evaluate.load(\"rouge\")\n  meteor = evaluate.load(\"meteor\")\n  bertscore = evaluate.load(\"bertscore\")","metadata":{"id":"dHQv7Aeai2Nr","outputId":"6c4222bd-bf8f-4588-9871-716bd2cee0ca","execution":{"iopub.status.busy":"2024-07-08T13:16:18.928049Z","iopub.execute_input":"2024-07-08T13:16:18.928699Z","iopub.status.idle":"2024-07-08T13:16:51.054078Z","shell.execute_reply.started":"2024-07-08T13:16:18.928670Z","shell.execute_reply":"2024-07-08T13:16:51.052930Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting bert_score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.19.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.1)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.3.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.23.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.1.2)\nRequirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.41.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert_score) (3.7.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (2023.12.25)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.4.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (9.5.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\nDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=394a60388095d7806be846bdf50ca8ce62293bd427f006758f064790a7152b2f\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score, evaluate, bert_score\nSuccessfully installed bert_score-0.3.13 evaluate-0.4.2 rouge_score-0.1.2\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nCollecting nltk\n  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.12.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.66.4)\nDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nltk\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nltk-3.8.1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c44e35fae4f14963984020a74cfb9df5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.93k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c5f7cf80c824402b6410d397db13b90"}},"metadata":{}},{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e21c38480824575a22dc9ef129c2f72"}},"metadata":{}}]},{"cell_type":"code","source":"# import numpy as np\n\n\n# def compute_metrics(eval_pred):\n#     predictions, labels = eval_pred\n#     decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n#     labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n#     decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n#     # result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n#     result = {\n#       'rouge': rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True),\n#       'bertscore': bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\"),\n#       'meteor': meteor.compute(predictions=decoded_preds, references=decoded_labels),\n#     }\n#     prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n#     result[\"gen_len\"] = np.mean(prediction_lens)\n#     print(json.dumps(result, indent=2))\n#     return {k: round(v, 4) if type(v) != list else v for k, v in result.items()}","metadata":{"id":"DgrUqOlXi2Nt","execution":{"iopub.status.busy":"2024-07-08T13:16:51.055835Z","iopub.execute_input":"2024-07-08T13:16:51.056258Z","iopub.status.idle":"2024-07-08T13:16:51.062882Z","shell.execute_reply.started":"2024-07-08T13:16:51.056216Z","shell.execute_reply":"2024-07-08T13:16:51.061904Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# arrr = [0,1,2,3,4,5,6,7]\n# valsss = ['a','b','c','d','e','f','g','h']\n\n# kwkwk = {f\"id-{x}\": vall for x, vall in enumerate(valsss)}\n# origindict = {'alpha':5, **kwkwk}\n# print(origindict)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T13:16:51.063988Z","iopub.execute_input":"2024-07-08T13:16:51.064330Z","iopub.status.idle":"2024-07-08T13:16:51.084840Z","shell.execute_reply.started":"2024-07-08T13:16:51.064296Z","shell.execute_reply":"2024-07-08T13:16:51.083912Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def compute_metrics_abs(eval_pred):\n  predictions, labels = eval_pred\n  decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n  labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n  \n  # bertscores = bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")\n  # np.mean(bertscores)\n  # 'rouge': rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True,use_aggregator=False),\n  # wandb.log({f\"losses/loss-{ii}\": loss for ii, loss in enumerate(losses)})\n  # rouge_scores = {f\"rouge/rougerouge-id-{i}\": score for i, score in enumerate(rouge.compute(predictions=decoded_preds,\n  #                                                                                references=decoded_labels,\n  #                                                                                use_stemmer=True,\n  #                                                                                use_aggregator=True))}\n  # bert_scores = {f\"bertscore/bert-id-{i}\": score for i, score in enumerate(bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\"))},\n  rouge_scores = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n  bert_scores = bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")\n  bert_scores.pop('hashcode')\n  result = {\n      **{f\"rouge/{k}\": round(v, 4) for k,v in rouge_scores.items()},\n      **{f\"bertscore/bertscore-{k}\": round(np.mean(v), 4) for k,v in bert_scores.items()},\n      'meteor': round(meteor.compute(predictions=decoded_preds, references=decoded_labels)['meteor'], 4),\n  }\n  #   for k,v in result.items():\n  #     print(k, type(v), v)\n  # Bug fix source: https://discuss.huggingface.co/t/bug-in-summarization-tutorial/60566/2\n  predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n  prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n  result[\"gen_len\"] = np.mean(prediction_lens)\n  # print(json.dumps(bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\"), indent=2))\n  return result # {k: round(v, 4) if type(v) != list else v for k, v in result.items()}\n\n#       'rouge1': round(rouge_scores['rouge1'], 4),\n#       'rouge2': round(rouge_scores['rouge2'], 4),\n#       'rougeL': round(rouge_scores['rougeL'], 4),\n#       'rougeLsum': round(rouge_scores['rougeLsum'], 4),\n#       'bertscore/bertscore-precision': np.mean(bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")['precision']),\n#       'bertscore/bertscore-recall': np.mean(bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")['recall']),\n#       'bertscore/bertscore-f1': np.mean(bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")['f1']),","metadata":{"execution":{"iopub.status.busy":"2024-07-08T13:16:51.086348Z","iopub.execute_input":"2024-07-08T13:16:51.086709Z","iopub.status.idle":"2024-07-08T13:16:51.100065Z","shell.execute_reply.started":"2024-07-08T13:16:51.086675Z","shell.execute_reply":"2024-07-08T13:16:51.098786Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{"id":"4W_3h_eHi2Nu"}},{"cell_type":"code","source":"# print(json.dumps(), indent=2)\n# blah = bertscore.compute(predictions=['a', 'blue', 'car'], references=['a', 'black', 'car'], lang=\"en\")\n# for b,c in blah.items():\n#     print(c)\n#     print(np.round(sum(c)/len(c), 4))","metadata":{"execution":{"iopub.status.busy":"2024-07-08T13:16:51.101465Z","iopub.execute_input":"2024-07-08T13:16:51.102258Z","iopub.status.idle":"2024-07-08T13:16:51.112709Z","shell.execute_reply.started":"2024-07-08T13:16:51.102227Z","shell.execute_reply":"2024-07-08T13:16:51.111713Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoConfig\nconfig = AutoConfig.from_pretrained(checkpoint_bart)\nconfig.max_length = 80\nconfig.min_length = 10\nprint(config)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T13:16:51.113845Z","iopub.execute_input":"2024-07-08T13:16:51.114223Z","iopub.status.idle":"2024-07-08T13:16:51.166155Z","shell.execute_reply.started":"2024-07-08T13:16:51.114199Z","shell.execute_reply":"2024-07-08T13:16:51.165216Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"BartConfig {\n  \"_name_or_path\": \"sshleifer/distilbart-xsum-12-6\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"gelu\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"BartForConditionalGeneration\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 1024,\n  \"decoder_attention_heads\": 16,\n  \"decoder_ffn_dim\": 4096,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 2,\n  \"dropout\": 0.1,\n  \"early_stopping\": true,\n  \"encoder_attention_heads\": 16,\n  \"encoder_ffn_dim\": 4096,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 12,\n  \"eos_token_id\": 2,\n  \"eos_token_ids\": [\n    2\n  ],\n  \"extra_pos_embeddings\": 2,\n  \"forced_eos_token_id\": 2,\n  \"gradient_checkpointing\": false,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"length_penalty\": 0.5,\n  \"max_length\": 80,\n  \"max_position_embeddings\": 1024,\n  \"min_length\": 10,\n  \"model_type\": \"bart\",\n  \"no_repeat_ngram_size\": 3,\n  \"normalize_before\": false,\n  \"normalize_embedding\": true,\n  \"num_beams\": 6,\n  \"num_hidden_layers\": 12,\n  \"output_past\": true,\n  \"pad_token_id\": 1,\n  \"prefix\": \" \",\n  \"replacing_rate\": 0,\n  \"save_step\": 58,\n  \"scale_embedding\": false,\n  \"static_position_embeddings\": false,\n  \"student_decoder_layers\": null,\n  \"student_encoder_layers\": null,\n  \"task_specific_params\": {},\n  \"transformers_version\": \"4.41.2\",\n  \"use_cache\": true,\n  \"vocab_size\": 50264\n}\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint_bart, config=config)","metadata":{"id":"YMJSYk6gi2Nv","execution":{"iopub.status.busy":"2024-07-08T13:16:51.167529Z","iopub.execute_input":"2024-07-08T13:16:51.168515Z","iopub.status.idle":"2024-07-08T13:16:57.498216Z","shell.execute_reply.started":"2024-07-08T13:16:51.168476Z","shell.execute_reply":"2024-07-08T13:16:57.497140Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/611M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d653d4ce15a4c049d7804cac1ea5df1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"}]},{"cell_type":"code","source":"# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n# os.environ['TORCH_USE_CUDA_DSA'] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2024-07-08T13:16:57.501509Z","iopub.execute_input":"2024-07-08T13:16:57.501804Z","iopub.status.idle":"2024-07-08T13:16:57.507601Z","shell.execute_reply.started":"2024-07-08T13:16:57.501779Z","shell.execute_reply":"2024-07-08T13:16:57.505726Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# len(tokenized_tweetsumm_abs['train'])","metadata":{"execution":{"iopub.status.busy":"2024-07-08T13:16:57.508956Z","iopub.execute_input":"2024-07-08T13:16:57.509299Z","iopub.status.idle":"2024-07-08T13:16:57.522760Z","shell.execute_reply.started":"2024-07-08T13:16:57.509266Z","shell.execute_reply":"2024-07-08T13:16:57.521921Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Print config\nprint(\"Tokenizer config:\", tokenizer.init_kwargs)\nprint(\"Model config:\", str(model.config).replace('\\n',''))","metadata":{"execution":{"iopub.status.busy":"2024-07-08T13:16:57.528457Z","iopub.execute_input":"2024-07-08T13:16:57.528727Z","iopub.status.idle":"2024-07-08T13:16:57.537870Z","shell.execute_reply.started":"2024-07-08T13:16:57.528703Z","shell.execute_reply":"2024-07-08T13:16:57.536588Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Tokenizer config: {'errors': 'replace', 'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False), 'sep_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False), 'cls_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False), 'pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False), 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=False), 'add_prefix_space': False, 'trim_offsets': True, 'model_max_length': 1024, 'name_or_path': 'sshleifer/distilbart-xsum-12-6', 'tokenizer_file': None}\nModel config: BartConfig {  \"_name_or_path\": \"sshleifer/distilbart-xsum-12-6\",  \"_num_labels\": 3,  \"activation_dropout\": 0.0,  \"activation_function\": \"gelu\",  \"add_bias_logits\": false,  \"add_final_layer_norm\": false,  \"architectures\": [    \"BartForConditionalGeneration\"  ],  \"attention_dropout\": 0.0,  \"bos_token_id\": 0,  \"classif_dropout\": 0.0,  \"classifier_dropout\": 0.0,  \"d_model\": 1024,  \"decoder_attention_heads\": 16,  \"decoder_ffn_dim\": 4096,  \"decoder_layerdrop\": 0.0,  \"decoder_layers\": 6,  \"decoder_start_token_id\": 2,  \"dropout\": 0.1,  \"early_stopping\": true,  \"encoder_attention_heads\": 16,  \"encoder_ffn_dim\": 4096,  \"encoder_layerdrop\": 0.0,  \"encoder_layers\": 12,  \"eos_token_id\": 2,  \"eos_token_ids\": [    2  ],  \"extra_pos_embeddings\": 2,  \"forced_eos_token_id\": 2,  \"gradient_checkpointing\": false,  \"id2label\": {    \"0\": \"LABEL_0\",    \"1\": \"LABEL_1\",    \"2\": \"LABEL_2\"  },  \"init_std\": 0.02,  \"is_encoder_decoder\": true,  \"label2id\": {    \"LABEL_0\": 0,    \"LABEL_1\": 1,    \"LABEL_2\": 2  },  \"length_penalty\": 0.5,  \"max_length\": 80,  \"max_position_embeddings\": 1024,  \"min_length\": 10,  \"model_type\": \"bart\",  \"no_repeat_ngram_size\": 3,  \"normalize_before\": false,  \"normalize_embedding\": true,  \"num_beams\": 6,  \"num_hidden_layers\": 12,  \"output_past\": true,  \"pad_token_id\": 1,  \"prefix\": \" \",  \"replacing_rate\": 0,  \"save_step\": 58,  \"scale_embedding\": false,  \"static_position_embeddings\": false,  \"student_decoder_layers\": null,  \"student_encoder_layers\": null,  \"task_specific_params\": {},  \"transformers_version\": \"4.41.2\",  \"use_cache\": true,  \"vocab_size\": 50264}\n","output_type":"stream"}]},{"cell_type":"code","source":"current_time = datetime.datetime.now().strftime(\"%d%m-%H%M\")\nprint(current_time)\nrun_name_model = f\"distilbart-abs-{current_time}\"\nwandb.run.name = run_name_model\nwandb.run.save()\n\ngen_config = GenerationConfig(max_source_length=512,bos_token_id=0)\ngen_config.save_pretrained(\"roequitz/distilbart-abs-tweetsumm\", push_to_hub=True)\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=f\"trained-distilbart-abs-{current_time[0:4]}\",\n    eval_strategy=\"epoch\",\n    logging_strategy=\"steps\",\n    logging_steps=10,\n    learning_rate=3e-5,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    weight_decay=0.01,\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    num_train_epochs=6,\n    predict_with_generate=True,\n    fp16=True,\n    generation_max_length=80,\n    generation_config=gen_config,\n    push_to_hub=True,\n    report_to=\"wandb\",\n    run_name=run_name_model\n)\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_tweetsumm_abs[\"train\"],\n    eval_dataset=tokenized_tweetsumm_abs[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics_abs,\n)\n\ntraining_start = time.time()\ntrainer.train()\ntraining_end = time.time()\nprint(\"Time it took for training:\", str(datetime.timedelta(seconds=(training_end-training_start))))","metadata":{"id":"nj5v3nT9i2Nw","outputId":"512d759b-0343-4f83-e36c-cf15fec503a3","execution":{"iopub.status.busy":"2024-07-08T13:16:57.539312Z","iopub.execute_input":"2024-07-08T13:16:57.540302Z","iopub.status.idle":"2024-07-08T13:34:21.488409Z","shell.execute_reply.started":"2024-07-08T13:16:57.540269Z","shell.execute_reply":"2024-07-08T13:34:21.486837Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n","output_type":"stream"},{"name":"stdout","text":"0807-1316\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1320' max='1320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1320/1320 17:21, Epoch 6/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge/rouge1</th>\n      <th>Rouge/rouge2</th>\n      <th>Rouge/rougel</th>\n      <th>Rouge/rougelsum</th>\n      <th>Bertscore/bertscore-precision</th>\n      <th>Bertscore/bertscore-recall</th>\n      <th>Bertscore/bertscore-f1</th>\n      <th>Meteor</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.105000</td>\n      <td>2.088418</td>\n      <td>0.454500</td>\n      <td>0.204900</td>\n      <td>0.388100</td>\n      <td>0.390500</td>\n      <td>0.896900</td>\n      <td>0.880000</td>\n      <td>0.888200</td>\n      <td>0.392300</td>\n      <td>80.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.882300</td>\n      <td>2.006643</td>\n      <td>0.345300</td>\n      <td>0.157500</td>\n      <td>0.296500</td>\n      <td>0.298400</td>\n      <td>0.663200</td>\n      <td>0.654700</td>\n      <td>0.658700</td>\n      <td>0.294900</td>\n      <td>80.000000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.408900</td>\n      <td>2.071664</td>\n      <td>0.076800</td>\n      <td>0.033700</td>\n      <td>0.063700</td>\n      <td>0.063900</td>\n      <td>0.155900</td>\n      <td>0.153500</td>\n      <td>0.154700</td>\n      <td>0.066700</td>\n      <td>80.000000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.068700</td>\n      <td>2.162677</td>\n      <td>0.012500</td>\n      <td>0.004800</td>\n      <td>0.010400</td>\n      <td>0.011400</td>\n      <td>0.032200</td>\n      <td>0.031700</td>\n      <td>0.031900</td>\n      <td>0.011800</td>\n      <td>80.000000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.744500</td>\n      <td>2.292715</td>\n      <td>0.040200</td>\n      <td>0.017700</td>\n      <td>0.033200</td>\n      <td>0.033200</td>\n      <td>0.081500</td>\n      <td>0.080900</td>\n      <td>0.081200</td>\n      <td>0.037400</td>\n      <td>80.000000</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.761900</td>\n      <td>2.418395</td>\n      <td>0.018500</td>\n      <td>0.008800</td>\n      <td>0.015200</td>\n      <td>0.016000</td>\n      <td>0.040400</td>\n      <td>0.040000</td>\n      <td>0.040200</td>\n      <td>0.016300</td>\n      <td>80.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 80, 'min_length': 10, 'early_stopping': True, 'num_beams': 6, 'length_penalty': 0.5, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 2}\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./trained-distilbart-abs-0807/checkpoint-220)... Done. 20.7s\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 80, 'min_length': 10, 'early_stopping': True, 'num_beams': 6, 'length_penalty': 0.5, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 2}\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./trained-distilbart-abs-0807/checkpoint-440)... Done. 21.3s\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 80, 'min_length': 10, 'early_stopping': True, 'num_beams': 6, 'length_penalty': 0.5, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 2}\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./trained-distilbart-abs-0807/checkpoint-660)... Done. 18.0s\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 80, 'min_length': 10, 'early_stopping': True, 'num_beams': 6, 'length_penalty': 0.5, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 2}\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./trained-distilbart-abs-0807/checkpoint-880)... HTTP Error 500 thrown while requesting PUT https://hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com/repos/19/f0/19f0d168ba27956143e7f5ed83789a1e97835457a5c464af6b8fb120725d209f/574138dced4c1dd243a1e5365548883e1e5b7fa9a7e3e4f2d007f2ee30cb24e2?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20240708%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240708T132805Z&X-Amz-Expires=86400&X-Amz-Signature=0d40ed3112444f0d9198f2f17775da0532def10e70f22e2b35c4c07f899987da&X-Amz-SignedHeaders=host&partNumber=48&uploadId=aW.1hJs1BA4rWkMPm0CrBalWmg.tWk9Ilbqa74XPCjhq6iqnA10lObmDNi8lBJibWoDucn6u__0E3nG5AcKhRCoG27W..P2ooXWaNy8MtPyKA7OPVp.vTSni54u2wOww&x-id=UploadPart\nRetrying in 1s [Retry 1/5].\nDone. 25.3s\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 80, 'min_length': 10, 'early_stopping': True, 'num_beams': 6, 'length_penalty': 0.5, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 2}\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./trained-distilbart-abs-0807/checkpoint-1100)... Done. 28.6s\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 80, 'min_length': 10, 'early_stopping': True, 'num_beams': 6, 'length_penalty': 0.5, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 2}\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./trained-distilbart-abs-0807/checkpoint-1320)... Done. 26.6s\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 80, 'min_length': 10, 'early_stopping': True, 'num_beams': 6, 'length_penalty': 0.5, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 80, 'min_length': 10, 'early_stopping': True, 'num_beams': 6, 'length_penalty': 0.5, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 2}\n","output_type":"stream"},{"name":"stdout","text":"Time it took for training: 0:17:22.697266\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"id":"0z9pTauji2Nw","execution":{"iopub.status.busy":"2024-07-08T13:34:21.490382Z","iopub.execute_input":"2024-07-08T13:34:21.491725Z","iopub.status.idle":"2024-07-08T13:34:28.747431Z","shell.execute_reply.started":"2024-07-08T13:34:21.491678Z","shell.execute_reply":"2024-07-08T13:34:28.746268Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 80, 'min_length': 10, 'early_stopping': True, 'num_beams': 6, 'length_penalty': 0.5, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 2}\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/roequitz/trained-distilbart-abs-0807/commit/aa2cb5cc955d0613befd36be8dca6a2b5560d33a', commit_message='End of training', commit_description='', oid='aa2cb5cc955d0613befd36be8dca6a2b5560d33a', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"# tokenizer.decode(tokenized_tweetsumm_abs['train'][5]['input_ids'], skip_special_tokens=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T13:34:28.749255Z","iopub.execute_input":"2024-07-08T13:34:28.750027Z","iopub.status.idle":"2024-07-08T13:34:28.755240Z","shell.execute_reply.started":"2024-07-08T13:34:28.749988Z","shell.execute_reply":"2024-07-08T13:34:28.754294Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# eos_start_token_bart = tokenized_tweetsumm_abs['train'][5]['input_ids'][0]\n# print(\"End of sentence token for starting generating summaries with BART: \", eos_start_token_bart)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T13:34:28.756776Z","iopub.execute_input":"2024-07-08T13:34:28.757128Z","iopub.status.idle":"2024-07-08T13:34:31.190565Z","shell.execute_reply.started":"2024-07-08T13:34:28.757096Z","shell.execute_reply":"2024-07-08T13:34:31.189451Z"},"trusted":true},"execution_count":32,"outputs":[]}]}