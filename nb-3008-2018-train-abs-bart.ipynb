{"cells":[{"cell_type":"markdown","metadata":{"id":"AvCot6IFw3LG"},"source":["# Abstractive summaries - Train DistilBART on TWEETSUMM dataset"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T14:22:57.949573Z","iopub.status.busy":"2024-08-29T14:22:57.949031Z","iopub.status.idle":"2024-08-29T14:22:57.971025Z","shell.execute_reply":"2024-08-29T14:22:57.969853Z","shell.execute_reply.started":"2024-08-29T14:22:57.949527Z"},"id":"csIsnw2147iB","outputId":"b1168797-2e98-4a6a-81e1-9e079f98ab53","scrolled":true,"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\gracz\\OneDrive - University of Limerick\\University\\Masters\\Sem2\\Thesis\\notebooks\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from huggingface_hub import login\n","import pandas as pd\n","import numpy as np\n","import os, time, datetime\n","\n","from datasets import Dataset, DatasetDict\n","\n","from transformers import DataCollatorForSeq2Seq, AutoTokenizer, set_seed\n","from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","\n","import wandb"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["absl-py==2.1.0\n","aiohappyeyeballs==2.4.0\n","aiohttp==3.10.5\n","aiosignal==1.3.1\n","asttokens==2.4.1\n","attrs==24.2.0\n","certifi==2024.8.30\n","chardet==5.2.0\n","charset-normalizer==3.3.2\n","click==8.1.7\n","colorama==0.4.6\n","comm==0.2.2\n","contourpy==1.3.0\n","cycler==0.12.1\n","datasets==2.21.0\n","debugpy==1.8.5\n","decorator==5.1.1\n","dill==0.3.8\n","evaluate==0.4.2\n","executing==2.0.1\n","filelock==3.15.4\n","fonttools==4.53.1\n","frozenlist==1.4.1\n","fsspec==2024.6.1\n","huggingface-hub==0.24.6\n","idna==3.8\n","ipykernel==6.29.5\n","ipython==8.26.0\n","jedi==0.19.1\n","Jinja2==3.1.4\n","joblib==1.4.2\n","jupyter_client==8.6.2\n","jupyter_core==5.7.2\n","kiwisolver==1.4.5\n","MarkupSafe==2.1.5\n","matplotlib==3.9.2\n","matplotlib-inline==0.1.7\n","mpmath==1.3.0\n","multidict==6.0.5\n","multiprocess==0.70.16\n","nest-asyncio==1.6.0\n","networkx==3.3\n","nltk==3.9.1\n","numpy==1.26.4\n","packaging==24.1\n","pandas==2.2.2\n","parso==0.8.4\n","pillow==10.4.0\n","platformdirs==4.2.2\n","polars==1.2.1\n","prompt_toolkit==3.0.47\n","psutil==6.0.0\n","pure_eval==0.2.3\n","pyarrow==17.0.0\n","Pygments==2.18.0\n","pyparsing==3.1.4\n","python-dateutil==2.9.0.post0\n","pytz==2024.1\n","pywin32==306\n","PyYAML==6.0.2\n","pyzmq==26.1.0\n","regex==2024.7.24\n","requests==2.32.3\n","rouge_score==0.1.2\n","safetensors==0.4.4\n","seaborn==0.13.2\n","setuptools==74.0.0\n","six==1.16.0\n","stack-data==0.6.3\n","sympy==1.13.2\n","tokenizers==0.19.1\n","torch==2.4.0\n","tornado==6.4.1\n","tqdm==4.66.5\n","traitlets==5.14.3\n","transformers==4.44.2\n","typing_extensions==4.12.2\n","tzdata==2024.1\n","urllib3==2.2.2\n","wcwidth==0.2.13\n","xxhash==3.5.0\n","yarl==1.9.7\n"]}],"source":["!pip freeze"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T14:22:57.973732Z","iopub.status.busy":"2024-08-29T14:22:57.973370Z","iopub.status.idle":"2024-08-29T14:22:58.200549Z","shell.execute_reply":"2024-08-29T14:22:58.199294Z","shell.execute_reply.started":"2024-08-29T14:22:57.973694Z"},"id":"D7StYsAaxJLT","outputId":"3690cf47-554a-424d-b42e-e8f77bb4bbf5","trusted":true},"outputs":[],"source":["ds_dir = \"\"\n","try:\n","    HF_TOKEN =  os.environ['HF_TOKEN']\n","except:\n","    HF_TOKEN = \"\"\n","\n","if 'google.colab' in str(get_ipython()):\n","    print(\"Running on Colab\")\n","    from google.colab import drive, userdata\n","    drive.mount('/content/drive')\n","    HF_TOKEN = userdata.get('HF_TOKEN')\n","elif os.environ.get('KAGGLE_KERNEL_RUN_TYPE') != None:\n","    ds_dir=\"/kaggle/input/bertdata2207/\"\n","    from kaggle_secrets import UserSecretsClient\n","    print(\"Running on Kaggle\")\n","    ds_dir = \"/kaggle/input/tweet-data-2106-1512/\"\n","    user_secrets = UserSecretsClient()\n","    HF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")\n","    WANDB_API_KEY = user_secrets.get_secret(\"WANDB_API_KEY\")\n","    os.environ['WANDB_API_KEY'] = WANDB_API_KEY\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T14:22:58.202360Z","iopub.status.busy":"2024-08-29T14:22:58.201963Z","iopub.status.idle":"2024-08-29T14:23:18.570044Z","shell.execute_reply":"2024-08-29T14:23:18.568945Z","shell.execute_reply.started":"2024-08-29T14:22:58.202322Z"},"id":"XCVrFPA4GL-h","outputId":"228dbbaf-c276-495e-e759-0ecb0b4a1ebb","scrolled":true,"trusted":true},"outputs":[],"source":["set_seed(17)\n","os.environ[\"WANDB_PROJECT\"] = \"aiml-thesis-train\""]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# wandb.init(settings=wandb.Settings(start_method=\"thread\"))"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T14:23:18.572625Z","iopub.status.busy":"2024-08-29T14:23:18.572269Z","iopub.status.idle":"2024-08-29T14:23:18.694984Z","shell.execute_reply":"2024-08-29T14:23:18.693921Z","shell.execute_reply.started":"2024-08-29T14:23:18.572587Z"},"id":"QoMm76b2i2NX","outputId":"f5df06b4-ac4d-4be9-8044-20010745149b","trusted":true},"outputs":[],"source":["# login(token=HF_TOKEN)"]},{"cell_type":"markdown","metadata":{"id":"xP2HgEaKi2Nk"},"source":["## Load data"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[".\\data\\\n"]}],"source":["ds_dir = '.\\\\data\\\\'\n","print(ds_dir)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T14:23:18.697716Z","iopub.status.busy":"2024-08-29T14:23:18.696752Z","iopub.status.idle":"2024-08-29T14:23:18.702586Z","shell.execute_reply":"2024-08-29T14:23:18.701349Z","shell.execute_reply.started":"2024-08-29T14:23:18.697660Z"},"trusted":true},"outputs":[],"source":["checkpoint_bart = \"sshleifer/distilbart-xsum-12-6\""]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T14:23:18.704320Z","iopub.status.busy":"2024-08-29T14:23:18.703945Z","iopub.status.idle":"2024-08-29T14:23:18.766427Z","shell.execute_reply":"2024-08-29T14:23:18.765337Z","shell.execute_reply.started":"2024-08-29T14:23:18.704283Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["dialogue    string[python]\n","summary     string[python]\n","dtype: object\n","                                            dialogue  \\\n","0  Customer: So neither my iPhone nor my Apple Wa...   \n","1  Customer: @115850 hi team! i m planning to get...   \n","2  Customer: @AskAmex Where do I write to address...   \n","3  Customer: @AmazonHelp @115821 Wow, expected 4 ...   \n","4  Customer: @GWRHelp I'd rather you spent some t...   \n","\n","                                             summary  \n","0  Customer enquired about his Iphone and Apple w...  \n","1  Customer is eager to know about the replacemen...  \n","2  Signed up for an AmexCard with Delta but it di...  \n","3  The customer have a problem. The agent is very...  \n","4  Customer cannot purchase a train ticket on the...  \n"]}],"source":["train_df_temp = pd.read_csv(ds_dir + \"dials_abs_2607_1312_train_spc.csv\", names=['conv_id','dialogue','summary'], encoding='utf-8', dtype={'conv_id':'string', 'dialogue':'string', 'summary': 'string'})\n","train_df_temp.convert_dtypes()\n","train_df_temp.drop(columns=['conv_id'], inplace=True)\n","train_df_temp.reset_index(drop=True, inplace=True)\n","\n","val_df_temp = pd.read_csv(ds_dir + \"dials_abs_2607_1312_valid_spc.csv\", names=['conv_id','dialogue','summary'], encoding='utf-8', dtype={'conv_id':'string', 'dialogue':'string', 'summary': 'string'})\n","val_df_temp.convert_dtypes()\n","val_df_temp.drop(columns=['conv_id'], inplace=True)\n","val_df_temp.reset_index(drop=True, inplace=True)\n","\n","test_df_temp = pd.read_csv(ds_dir + \"dials_abs_2607_1312_test_spc.csv\", names=['conv_id','dialogue','summary'], encoding='utf-8', dtype={'conv_id':'string', 'dialogue':'string', 'summary': 'string'})\n","test_df_temp.convert_dtypes()\n","test_df_temp.reset_index(drop=True, inplace=True)\n","\n","print(train_df_temp.dtypes)\n","print(train_df_temp.head())"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T14:23:18.768471Z","iopub.status.busy":"2024-08-29T14:23:18.767965Z","iopub.status.idle":"2024-08-29T14:23:18.807467Z","shell.execute_reply":"2024-08-29T14:23:18.806249Z","shell.execute_reply.started":"2024-08-29T14:23:18.768418Z"},"trusted":true},"outputs":[],"source":["tweetsumm_abs = DatasetDict(\n","    {\n","        'train': Dataset.from_pandas(train_df_temp),\n","        'validation': Dataset.from_pandas(val_df_temp),\n","        'test': Dataset.from_pandas(test_df_temp)\n","    }\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T14:23:18.809221Z","iopub.status.busy":"2024-08-29T14:23:18.808807Z","iopub.status.idle":"2024-08-29T14:23:18.973871Z","shell.execute_reply":"2024-08-29T14:23:18.972875Z","shell.execute_reply.started":"2024-08-29T14:23:18.809164Z"},"id":"F-hzIHQ9w3Lb","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["BartTokenizerFast(name_or_path='sshleifer/distilbart-xsum-12-6', vocab_size=50265, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n","\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n","\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n","\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n","\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n","\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n","}\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\gracz\\OneDrive - University of Limerick\\University\\Masters\\Sem2\\Thesis\\notebooks\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}],"source":["bart_tokenizer = AutoTokenizer.from_pretrained(checkpoint_bart)\n","bart_tokenizer.max_source_length = 512\n","bart_tokenizer.max_target_length = 80\n","tokenizer = bart_tokenizer\n","print(tokenizer)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T14:23:18.988101Z","iopub.status.busy":"2024-08-29T14:23:18.987724Z","iopub.status.idle":"2024-08-29T14:23:18.995183Z","shell.execute_reply":"2024-08-29T14:23:18.994046Z","shell.execute_reply.started":"2024-08-29T14:23:18.988061Z"},"id":"vVQdGPfZw3Lb","trusted":true},"outputs":[],"source":["# Source: https://huggingface.co/docs/transformers/en/tasks/summarization\n","\n","def preprocess_function(examples):\n","    prefix = \"summarize: \"\n","    inputs = [str(prefix) + str(dial) for dial in examples[\"dialogue\"]]\n","    model_inputs = tokenizer(inputs, max_length=512, truncation=True) # same params as tweetsumm paper\n","    labels = tokenizer(text_target=examples[\"summary\"], max_length=80, truncation=True)\n","    # print(inputs, model_inputs['input_ids'])\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T14:23:19.007823Z","iopub.status.busy":"2024-08-29T14:23:19.007474Z","iopub.status.idle":"2024-08-29T14:23:32.197656Z","shell.execute_reply":"2024-08-29T14:23:32.196591Z","shell.execute_reply.started":"2024-08-29T14:23:19.007768Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Map: 100%|██████████| 867/867 [00:06<00:00, 144.32 examples/s]\n","Map: 100%|██████████| 110/110 [00:00<00:00, 1443.04 examples/s]\n","Map: 100%|██████████| 109/109 [00:00<00:00, 1338.42 examples/s]"]},{"name":"stdout","output_type":"stream","text":["{'dialogue': 'Customer: So neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesn’t recognise either source anymore for some reason. Any ideas? https://t.co/m9DPQbkftD\\r\\nCustomer: @AppleSupport please read the above.\\r\\nAgent: @135060 Let’s investigate this together. To start, can you tell us the software versions your iPhone and Apple Watch are running currently?\\r\\nCustomer: @AppleSupport My iPhone is on 11.1.2, and my watch is on 4.1.\\r\\nAgent: @135060 Thank you. Have you tried restarting both devices since this started happening?\\r\\nCustomer: @AppleSupport I’ve restarted both, also un-paired then re-paired the watch.\\r\\nAgent: @135060 Got it. When did you first notice that the two devices were not talking to each other. Do the two devices communicate through other apps such as Messages?\\r\\nCustomer: @AppleSupport Yes, everything seems fine, it’s just Health and activity.\\r\\nAgent: @135060 Let’s move to DM and look into this a bit more. When reaching out in DM, let us know when this first started happening please. For example, did it start after an update or after installing a certain app? https://t.co/GDrqU22YpT', 'summary': 'Customer enquired about his Iphone and Apple watch which is not showing his any steps/activity and health activities. Agent is asking to move to DM and look into it.', 'input_ids': [0, 18581, 3916, 2072, 35, 19458, 35, 407, 5063, 127, 2733, 3486, 127, 1257, 3075, 32, 5492, 127, 2402, 73, 30280, 6, 8, 1309, 630, 17, 27, 90, 11865, 1169, 1300, 5988, 13, 103, 1219, 4, 5053, 2956, 116, 1205, 640, 90, 4, 876, 73, 119, 466, 5174, 1864, 428, 330, 2543, 495, 50121, 50118, 44799, 35, 787, 20770, 38873, 2540, 1166, 5, 1065, 4, 50121, 50118, 45443, 35, 787, 1558, 1096, 2466, 2780, 17, 27, 29, 4830, 42, 561, 4, 598, 386, 6, 64, 47, 1137, 201, 5, 2257, 7952, 110, 2733, 8, 1257, 3075, 32, 878, 855, 116, 50121, 50118, 44799, 35, 787, 20770, 38873, 1308, 2733, 16, 15, 365, 4, 134, 4, 176, 6, 8, 127, 1183, 16, 15, 204, 4, 134, 4, 50121, 50118, 45443, 35, 787, 1558, 1096, 2466, 3837, 47, 4, 6319, 47, 1381, 12721, 154, 258, 2110, 187, 42, 554, 2909, 116, 50121, 50118, 44799, 35, 787, 20770, 38873, 38, 17, 27, 548, 12721, 196, 258, 6, 67, 542, 12, 6709, 7651, 172, 769, 12, 6709, 7651, 5, 1183, 4, 50121, 50118, 45443, 35, 787, 1558, 1096, 2466, 8432, 24, 4, 520, 222, 47, 78, 3120, 14, 5, 80, 2110, 58, 45, 1686, 7, 349, 97, 4, 1832, 5, 80, 2110, 8469, 149, 97, 3798, 215, 25, 34692, 116, 50121, 50118, 44799, 35, 787, 20770, 38873, 3216, 6, 960, 1302, 2051, 6, 24, 17, 27, 29, 95, 1309, 8, 1940, 4, 50121, 50118, 45443, 35, 787, 1558, 1096, 2466, 2780, 17, 27, 29, 517, 7, 18695, 8, 356, 88, 42, 10, 828, 55, 4, 520, 3970, 66, 11, 18695, 6, 905, 201, 216, 77, 42, 78, 554, 2909, 2540, 4, 286, 1246, 6, 222, 24, 386, 71, 41, 2935, 50, 71, 15602, 10, 1402, 1553, 116, 1205, 640, 90, 4, 876, 73, 534, 14043, 1343, 791, 2036, 975, 642, 565, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [0, 44799, 17730, 7651, 59, 39, 38, 17283, 8, 1257, 1183, 61, 16, 45, 2018, 39, 143, 2402, 73, 30280, 8, 474, 1713, 4, 18497, 16, 1996, 7, 517, 7, 18695, 8, 356, 88, 24, 4, 2]}\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["tokenized_tweetsumm_abs = tweetsumm_abs.map(preprocess_function, batched=True)\n","print(tokenized_tweetsumm_abs[\"train\"][0])"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T14:23:32.199372Z","iopub.status.busy":"2024-08-29T14:23:32.198983Z","iopub.status.idle":"2024-08-29T14:23:32.218598Z","shell.execute_reply":"2024-08-29T14:23:32.217466Z","shell.execute_reply.started":"2024-08-29T14:23:32.199333Z"},"id":"irJUvr6gi2No","trusted":true},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint_bart)"]},{"cell_type":"markdown","metadata":{"id":"97ha331Ii2Np"},"source":["## Setup Training Evaluation"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T14:23:32.220649Z","iopub.status.busy":"2024-08-29T14:23:32.220191Z","iopub.status.idle":"2024-08-29T14:23:33.262246Z","shell.execute_reply":"2024-08-29T14:23:33.261278Z","shell.execute_reply.started":"2024-08-29T14:23:32.220598Z"},"id":"dHQv7Aeai2Nr","outputId":"6c4222bd-bf8f-4588-9871-716bd2cee0ca","scrolled":true,"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\gracz\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\gracz\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to\n","[nltk_data]     C:\\Users\\gracz\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n","Using the latest cached version of the module from C:\\Users\\gracz\\.cache\\huggingface\\modules\\evaluate_modules\\metrics\\evaluate-metric--bertscore\\cf4907b18f8f741f202232c0f8009a3bd49ff98802c245abcb6ea51a37a8c05b (last modified on Mon Jul  8 15:40:51 2024) since it couldn't be found locally at evaluate-metric--bertscore, or remotely on the Hugging Face Hub.\n"]},{"ename":"ModuleNotFoundError","evalue":"No module named 'bert_score'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m rouge \u001b[38;5;241m=\u001b[39m evaluate\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrouge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m meteor \u001b[38;5;241m=\u001b[39m evaluate\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeteor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m bertscore \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbertscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpunkt_tab\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[1;32mc:\\Users\\gracz\\OneDrive - University of Limerick\\University\\Masters\\Sem2\\Thesis\\notebooks\\.venv\\Lib\\site-packages\\evaluate\\loading.py:751\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, config_name, module_type, process_id, num_process, cache_dir, experiment_id, keep_in_memory, download_config, download_mode, revision, **init_kwargs)\u001b[0m\n\u001b[0;32m    747\u001b[0m download_mode \u001b[38;5;241m=\u001b[39m DownloadMode(download_mode \u001b[38;5;129;01mor\u001b[39;00m DownloadMode\u001b[38;5;241m.\u001b[39mREUSE_DATASET_IF_EXISTS)\n\u001b[0;32m    748\u001b[0m evaluation_module \u001b[38;5;241m=\u001b[39m evaluation_module_factory(\n\u001b[0;32m    749\u001b[0m     path, module_type\u001b[38;5;241m=\u001b[39mmodule_type, revision\u001b[38;5;241m=\u001b[39mrevision, download_config\u001b[38;5;241m=\u001b[39mdownload_config, download_mode\u001b[38;5;241m=\u001b[39mdownload_mode\n\u001b[0;32m    750\u001b[0m )\n\u001b[1;32m--> 751\u001b[0m evaluation_cls \u001b[38;5;241m=\u001b[39m \u001b[43mimport_main_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluation_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m evaluation_instance \u001b[38;5;241m=\u001b[39m evaluation_cls(\n\u001b[0;32m    753\u001b[0m     config_name\u001b[38;5;241m=\u001b[39mconfig_name,\n\u001b[0;32m    754\u001b[0m     process_id\u001b[38;5;241m=\u001b[39mprocess_id,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minit_kwargs,\n\u001b[0;32m    761\u001b[0m )\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_type \u001b[38;5;129;01mand\u001b[39;00m module_type \u001b[38;5;241m!=\u001b[39m evaluation_instance\u001b[38;5;241m.\u001b[39mmodule_type:\n","File \u001b[1;32mc:\\Users\\gracz\\OneDrive - University of Limerick\\University\\Masters\\Sem2\\Thesis\\notebooks\\.venv\\Lib\\site-packages\\evaluate\\loading.py:76\u001b[0m, in \u001b[0;36mimport_main_class\u001b[1;34m(module_path)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimport_main_class\u001b[39m(module_path) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Union[Type[DatasetBuilder], Type[EvaluationModule]]]:\n\u001b[0;32m     75\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Import a module at module_path and return its main class, a Metric by default\"\"\"\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     main_cls_type \u001b[38;5;241m=\u001b[39m EvaluationModule\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;66;03m# Find the main class in our imported module\u001b[39;00m\n","File \u001b[1;32mC:\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n","File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n","File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n","File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n","File \u001b[1;32m<frozen importlib._bootstrap_external>:994\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n","File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n","File \u001b[1;32m~\\.cache\\huggingface\\modules\\evaluate_modules\\metrics\\evaluate-metric--bertscore\\cf4907b18f8f741f202232c0f8009a3bd49ff98802c245abcb6ea51a37a8c05b\\bertscore.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcontextlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m contextmanager\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbert_score\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bert_score'"]}],"source":["import evaluate, nltk\n","rouge = evaluate.load(\"rouge\")\n","meteor = evaluate.load(\"meteor\")\n","bertscore = evaluate.load(\"bertscore\")\n","\n","nltk.download('punkt_tab')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T14:23:33.271507Z","iopub.status.busy":"2024-08-29T14:23:33.271187Z","iopub.status.idle":"2024-08-29T14:23:33.282650Z","shell.execute_reply":"2024-08-29T14:23:33.281622Z","shell.execute_reply.started":"2024-08-29T14:23:33.271472Z"},"trusted":true},"outputs":[],"source":["def compute_metrics_abs(eval_pred):\n","    predictions, labels = eval_pred\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    rouge_scores = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n","    bert_scores = bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")\n","    bert_scores.pop('hashcode')\n","    result = {\n","      **{f\"rouge/{k}\": round(v, 4) for k,v in rouge_scores.items()},\n","      **{f\"bertscore/bertscore-{k}\": round(np.mean(v), 4) for k,v in bert_scores.items()},\n","      'meteor': round(meteor.compute(predictions=decoded_preds, references=decoded_labels)['meteor'], 4),\n","    }\n","    predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    return result\n"]},{"cell_type":"markdown","metadata":{"id":"4W_3h_eHi2Nu"},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" Volume in drive C has no label.\n"," Volume Serial Number is 2610-4815\n","\n"," Directory of c:\\Users\\gracz\\OneDrive - University of Limerick\\University\\Masters\\Sem2\\Thesis\\notebooks\n","\n","30/08/2024  20:52    <DIR>          .\n","24/07/2024  13:39    <DIR>          ..\n","27/08/2024  14:48                69 .gitignore\n","18/08/2024  13:24               107 .gitmodules\n","09/08/2024  15:45    <DIR>          .venv\n","27/08/2024  14:08            59,447 bert-input-cont-train-2508-1444.ipynb\n","27/08/2024  14:42            63,525 bert-input-cont-train-2708-1442.ipynb\n","16/08/2024  06:29           497,944 bert-plain-1308-1838.ipynb\n","16/08/2024  10:26            34,328 bert-plain-1608-1126.ipynb\n","18/08/2024  11:26           234,269 bert-plain-1808-1226.ipynb\n","28/08/2024  16:01           193,003 bertres_analyse_2808_1042.ipynb\n","16/08/2024  10:24            22,377 bert_plain_1608_1123.py\n","16/08/2024  10:26             3,567 bert_plain_script.py\n","09/08/2024  15:25           139,991 chatgpt-sum-0708-1154.ipynb\n","22/08/2024  16:44           139,961 chatgpt-sum-0908-1625.ipynb\n","06/08/2024  23:00            98,543 ChatGPTsumm_0308.ipynb\n","07/08/2024  10:51           104,521 ChatGPTsumm_0708.ipynb\n","16/08/2024  11:34    <DIR>          data\n","06/08/2024  23:00         4,296,547 data.zip\n","28/08/2024  17:48            24,614 eval-upload-res-bertsum-2708-2237.ipynb\n","06/08/2024  23:00            94,637 nb-0807-1417-train-abs-bart.ipynb\n","06/08/2024  23:00            71,845 nb-0807-1444-test-bart.ipynb\n","06/08/2024  23:00            39,325 nb-2607-1534-train-abs-bart.ipynb\n","29/08/2024  16:52           104,537 nb-2908-1652-train-abs-bart.ipynb\n","02/09/2024  14:24            77,690 nb-3008-2018-train-abs-bart.ipynb\n","09/08/2024  15:55             2,783 nb_result_analysis_0908.ipynb\n","06/08/2024  23:00            97,033 nb_train_bart_abs_2407_1745.ipynb\n","06/08/2024  23:00            50,404 notebook15893e28a9_train_kaggle_2106_1529.ipynb\n","06/08/2024  23:00            34,565 notebook15893e28a9_train_kaggle_2106_1755.ipynb\n","06/08/2024  23:00            93,801 notebook15893e28a9_train_kaggle_2206_0153.ipynb\n","06/08/2024  23:00                49 notebooks.code-workspace\n","06/08/2024  23:00            82,411 notebook_train_kaggle_0107_1941_abs_bart.ipynb\n","18/06/2024  00:21                13 README.md\n","28/08/2024  19:52    <DIR>          results\n","29/08/2024  18:26                 2 sigi.bin\n","18/08/2024  13:24    <DIR>          submods\n","06/08/2024  23:00           163,672 Summ_2805_1217_data.ipynb\n","06/08/2024  23:00           287,069 Summ_2805_1217_dbr.ipynb\n","06/08/2024  23:00           288,161 Summ_2805_1217_dbr_nb2.ipynb\n","06/08/2024  23:00           147,925 Summ_2805_1217_train_abs.ipynb\n","03/09/2024  17:17    <DIR>          temp\n","29/08/2024  14:26    <DIR>          util_scripts\n","22/07/2024  19:28    <DIR>          wandb\n","              34 File(s)      7,548,735 bytes\n","               9 Dir(s)  115,099,283,456 bytes free\n"]}],"source":["# Debug\n","!dir"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'os' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdebugtokens\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_tokenization_and_length, check_special_tokens_and_padding, check_dataset_and_collator\n\u001b[0;32m      3\u001b[0m SPLITS\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"]}],"source":["os.chdir('temp')\n","from debugtokens import check_tokenization_and_length, check_special_tokens_and_padding, check_dataset_and_collator\n","SPLITS= ('train', 'test', 'valid')\n","issues = []\n","for split in SPLITS:\n","    issues += check_tokenization_and_length(tokenizer, tweetsumm_abs['train']['dialogue'], tweetsumm_abs['train']['summary'])\n","    issues += check_special_tokens_and_padding(tokenizer, tweetsumm_abs[split])\n","    issues += check_dataset_and_collator(tweetsumm_abs[split], data_collator)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["LEARN_RATES = (3e-5, 3e-4, 3e-6)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T14:23:34.865482Z","iopub.status.busy":"2024-08-29T14:23:34.865075Z","iopub.status.idle":"2024-08-29T14:26:10.316633Z","shell.execute_reply":"2024-08-29T14:26:10.314372Z","shell.execute_reply.started":"2024-08-29T14:23:34.865434Z"},"id":"nj5v3nT9i2Nw","outputId":"512d759b-0343-4f83-e36c-cf15fec503a3","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"]},{"name":"stdout","output_type":"stream","text":["3008-2022\n"]},{"name":"stderr","output_type":"stream","text":["/home/dawidk/.conda/envs/dkbert/lib/python3.12/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","/home/dawidk/.conda/envs/dkbert/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/home/dawidk/.conda/envs/dkbert/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='328' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [328/654 05:19 < 05:19, 1.02 it/s, Epoch 3/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Rouge/rouge1</th>\n","      <th>Rouge/rouge2</th>\n","      <th>Rouge/rougel</th>\n","      <th>Rouge/rougelsum</th>\n","      <th>Bertscore/bertscore-precision</th>\n","      <th>Bertscore/bertscore-recall</th>\n","      <th>Bertscore/bertscore-f1</th>\n","      <th>Meteor</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.229200</td>\n","      <td>2.114038</td>\n","      <td>0.442600</td>\n","      <td>0.206700</td>\n","      <td>0.372100</td>\n","      <td>0.372800</td>\n","      <td>0.900700</td>\n","      <td>0.887800</td>\n","      <td>0.894000</td>\n","      <td>0.381000</td>\n","      <td>34.681818</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.713200</td>\n","      <td>2.017842</td>\n","      <td>0.459500</td>\n","      <td>0.215000</td>\n","      <td>0.395000</td>\n","      <td>0.395900</td>\n","      <td>0.904300</td>\n","      <td>0.891300</td>\n","      <td>0.897600</td>\n","      <td>0.393400</td>\n","      <td>33.300000</td>\n","    </tr>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [14/14 00:28]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/home/dawidk/.conda/envs/dkbert/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 62, 'min_length': 11, 'early_stopping': True, 'num_beams': 6, 'length_penalty': 0.5, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 2}\n","/home/dawidk/.conda/envs/dkbert/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/home/dawidk/.conda/envs/dkbert/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'max_length': 62, 'min_length': 11, 'early_stopping': True, 'num_beams': 6, 'length_penalty': 0.5, 'no_repeat_ngram_size': 3, 'forced_eos_token_id': 2}\n","/home/dawidk/.conda/envs/dkbert/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/home/dawidk/.conda/envs/dkbert/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"ename":"TypeError","evalue":"sequence item 35: expected str instance, NoneType found","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 41\u001b[0m\n\u001b[1;32m     30\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m     31\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     32\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics_abs,\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     40\u001b[0m training_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 41\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m training_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime it took for training:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mtimedelta(seconds\u001b[38;5;241m=\u001b[39m(training_end\u001b[38;5;241m-\u001b[39mtraining_start))))\n","File \u001b[0;32m~/.conda/envs/dkbert/lib/python3.12/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.conda/envs/dkbert/lib/python3.12/site-packages/transformers/trainer.py:2376\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2373\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2375\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2376\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   2379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[1;32m   2380\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n","File \u001b[0;32m~/.conda/envs/dkbert/lib/python3.12/site-packages/transformers/trainer.py:2804\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2802\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 2804\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m   2807\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_checkpoint(model, trial, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n","File \u001b[0;32m~/.conda/envs/dkbert/lib/python3.12/site-packages/transformers/trainer.py:2761\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   2760\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 2761\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2762\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2764\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n","File \u001b[0;32m~/.conda/envs/dkbert/lib/python3.12/site-packages/transformers/trainer_seq2seq.py:180\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_kwargs \u001b[38;5;241m=\u001b[39m gen_kwargs\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.conda/envs/dkbert/lib/python3.12/site-packages/transformers/trainer.py:3666\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3663\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3665\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3666\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3667\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3669\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3670\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3674\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3676\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n","File \u001b[0;32m~/.conda/envs/dkbert/lib/python3.12/site-packages/transformers/trainer.py:3956\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3952\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[1;32m   3953\u001b[0m             EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels, inputs\u001b[38;5;241m=\u001b[39mall_inputs)\n\u001b[1;32m   3954\u001b[0m         )\n\u001b[1;32m   3955\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3956\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvalPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3958\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n","Cell \u001b[0;32mIn[15], line 3\u001b[0m, in \u001b[0;36mcompute_metrics_abs\u001b[0;34m(eval_pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_metrics_abs\u001b[39m(eval_pred):\n\u001b[1;32m      2\u001b[0m     predictions, labels \u001b[38;5;241m=\u001b[39m eval_pred\n\u001b[0;32m----> 3\u001b[0m     decoded_preds \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(labels \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m, labels, tokenizer\u001b[38;5;241m.\u001b[39mpad_token_id)\n\u001b[1;32m      5\u001b[0m     decoded_labels \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(labels, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m~/.conda/envs/dkbert/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3977\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_decode\u001b[0;34m(self, sequences, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3952\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_decode\u001b[39m(\n\u001b[1;32m   3953\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3954\u001b[0m     sequences: Union[List[\u001b[38;5;28mint\u001b[39m], List[List[\u001b[38;5;28mint\u001b[39m]], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3957\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3958\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m   3959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3960\u001b[0m \u001b[38;5;124;03m    Convert a list of lists of token ids into a list of strings by calling decode.\u001b[39;00m\n\u001b[1;32m   3961\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3974\u001b[0m \u001b[38;5;124;03m        `List[str]`: The list of decoded sentences.\u001b[39;00m\n\u001b[1;32m   3975\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   3976\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m-> 3977\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m            \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3982\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3983\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences\n\u001b[1;32m   3984\u001b[0m     ]\n","File \u001b[0;32m~/.conda/envs/dkbert/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:4016\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   4013\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[1;32m   4014\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m to_py_obj(token_ids)\n\u001b[0;32m-> 4016\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4020\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4021\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.conda/envs/dkbert/lib/python3.12/site-packages/transformers/tokenization_utils.py:1104\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, spaces_between_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m         current_sub_text\u001b[38;5;241m.\u001b[39mappend(token)\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_sub_text:\n\u001b[0;32m-> 1104\u001b[0m     sub_texts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_tokens_to_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_sub_text\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spaces_between_special_tokens:\n\u001b[1;32m   1107\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(sub_texts)\n","File \u001b[0;32m~/.conda/envs/dkbert/lib/python3.12/site-packages/transformers/models/bart/tokenization_bart.py:278\u001b[0m, in \u001b[0;36mBartTokenizer.convert_tokens_to_string\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_tokens_to_string\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens):\n\u001b[1;32m    277\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Converts a sequence of tokens (string) in a single string.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbyte_decoder[c] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m text])\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n","\u001b[0;31mTypeError\u001b[0m: sequence item 35: expected str instance, NoneType found"]}],"source":["for exp_idx in range(0,4):\n","    \n","    model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint_bart)\n","    current_time = datetime.datetime.now().strftime(\"%d%m-%H%M\")\n","    print(current_time)\n","    run_name_model = f\"distilbart-abs-{current_time}-lr-{LEARN_RATES[exp_idx]}\"\n","    wandb.run.name = run_name_model\n","    wandb.run.save()\n","\n","    training_args = Seq2SeqTrainingArguments(\n","        output_dir=f\"trained-distilbart-abs-{current_time[0:4]}\",\n","        eval_strategy=\"epoch\",\n","        logging_strategy=\"steps\",\n","        logging_steps=10,\n","        learning_rate=LEARN_RATES[exp_idx],\n","        per_device_train_batch_size=4,\n","        per_device_eval_batch_size=4,\n","        weight_decay=0.01,\n","        save_strategy=\"epoch\",\n","        save_total_limit=6,\n","        num_train_epochs=6,\n","        predict_with_generate=True,\n","        fp16=True,\n","        generation_max_length=80,\n","        # generation_config=gen_config,\n","        push_to_hub=False,\n","        report_to=\"wandb\",\n","        run_name=run_name_model\n","    )\n","    trainer = Seq2SeqTrainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=tokenized_tweetsumm_abs[\"train\"],\n","        eval_dataset=tokenized_tweetsumm_abs[\"validation\"],\n","        tokenizer=tokenizer,\n","        data_collator=data_collator,\n","        compute_metrics=compute_metrics_abs,\n","    )\n","\n","    training_start = time.time()\n","    trainer.train()\n","    training_end = time.time()\n","    print(\"Time it took for training:\", str(datetime.timedelta(seconds=(training_end-training_start))))\n","    trainer.push_to_hub(run_name_model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wandb.finish()"]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5430249,"sourceId":9040667,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"},"widgets":{"application/vnd.jupyter.widget-state+json":{"09513166db494a318fe4bd2ff4fe8b73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bad09d132dcc420fbad7ace8cc25aa06","placeholder":"​","style":"IPY_MODEL_20787ae61e94452aae73869c5382ff1b","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"19649549a1ad47368ec9f6eeba1e80ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20787ae61e94452aae73869c5382ff1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25bd97f157d8485fb15438d25d83421c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c792771c4604d9b8f6bcda700f2ad74","placeholder":"​","style":"IPY_MODEL_36781c62f1164acabc7371ceb966e8cc","value":"Token is valid (permission: write)."}},"26b0af06bf1549bd8f16e297a3d5c4fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34efbeb9bdcf42b28bcfdf48289bb943":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36781c62f1164acabc7371ceb966e8cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3bd1b8a5cbdf4345b34a6042ad3c6383":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d0bb7ba88104e458caaaf9c72914b97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44d30b0ecad54f818f27bbd1858cdf3f","placeholder":"​","style":"IPY_MODEL_85e73a9905ba41c286b0645f0c667362","value":"Login successful"}},"44d30b0ecad54f818f27bbd1858cdf3f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5685a3fe6b084791b1c41bede0ee8429":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5764ccc3c9b943ac9031bb4fbf65ee84":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dcb4bd1b7424f698dcfe1586ecaaa87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7393008614c94b7f9aee294715d1f9c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6eb7b2e427a4fb3b984a0346394555a","placeholder":"​","style":"IPY_MODEL_34efbeb9bdcf42b28bcfdf48289bb943","value":"Your token has been saved in your configured git credential helpers (store)."}},"7b5d107e75ec4226b2f951fa5eac32c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"85e73a9905ba41c286b0645f0c667362":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c792771c4604d9b8f6bcda700f2ad74":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91cf6c949361472e8cdc02a27371892b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"PasswordModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_5764ccc3c9b943ac9031bb4fbf65ee84","placeholder":"​","style":"IPY_MODEL_f6f5badeb1f749d8a1a74c737ea45b81","value":""}},"9d286f232614404eac3e78415a823171":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26b0af06bf1549bd8f16e297a3d5c4fa","placeholder":"​","style":"IPY_MODEL_b289ce6929414af38bd4cd4ddf68bfe4","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"a6333daeaf584192b2d8222134dc02a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb0ffca70a4645458b4650ff588f82cc","placeholder":"​","style":"IPY_MODEL_fec956e2f3ac4760a951569986ebb5c2","value":"Your token has been saved to /root/.cache/huggingface/token"}},"b289ce6929414af38bd4cd4ddf68bfe4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b292b711914d4f14abd2436aeb8050f8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3bfd48d65b748349afd7e3e5000baff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"b6eb7b2e427a4fb3b984a0346394555a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bad09d132dcc420fbad7ace8cc25aa06":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcab8a3e3c3f45d48890e88d50d8e982":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_b292b711914d4f14abd2436aeb8050f8","style":"IPY_MODEL_b3bfd48d65b748349afd7e3e5000baff","tooltip":""}},"c42b74a51b7843c7b8a9fca7d90bfd1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19649549a1ad47368ec9f6eeba1e80ff","placeholder":"​","style":"IPY_MODEL_3bd1b8a5cbdf4345b34a6042ad3c6383","value":"Connecting..."}},"d1a558c379ac48cc80c19ef9898d871d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_25bd97f157d8485fb15438d25d83421c","IPY_MODEL_7393008614c94b7f9aee294715d1f9c8","IPY_MODEL_a6333daeaf584192b2d8222134dc02a9","IPY_MODEL_3d0bb7ba88104e458caaaf9c72914b97"],"layout":"IPY_MODEL_7b5d107e75ec4226b2f951fa5eac32c7"}},"dbbfbb222a7d4ce18c1c7b655fc89ae1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"CheckboxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_5685a3fe6b084791b1c41bede0ee8429","style":"IPY_MODEL_6dcb4bd1b7424f698dcfe1586ecaaa87","value":true}},"f6f5badeb1f749d8a1a74c737ea45b81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb0ffca70a4645458b4650ff588f82cc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fec956e2f3ac4760a951569986ebb5c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":4}
