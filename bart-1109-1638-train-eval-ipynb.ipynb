{"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9040667,"sourceType":"datasetVersion","datasetId":5430249},{"sourceId":9140997,"sourceType":"datasetVersion","datasetId":5507948}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"09513166db494a318fe4bd2ff4fe8b73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bad09d132dcc420fbad7ace8cc25aa06","placeholder":"​","style":"IPY_MODEL_20787ae61e94452aae73869c5382ff1b","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"19649549a1ad47368ec9f6eeba1e80ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20787ae61e94452aae73869c5382ff1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25bd97f157d8485fb15438d25d83421c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c792771c4604d9b8f6bcda700f2ad74","placeholder":"​","style":"IPY_MODEL_36781c62f1164acabc7371ceb966e8cc","value":"Token is valid (permission: write)."}},"26b0af06bf1549bd8f16e297a3d5c4fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34efbeb9bdcf42b28bcfdf48289bb943":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36781c62f1164acabc7371ceb966e8cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3bd1b8a5cbdf4345b34a6042ad3c6383":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d0bb7ba88104e458caaaf9c72914b97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44d30b0ecad54f818f27bbd1858cdf3f","placeholder":"​","style":"IPY_MODEL_85e73a9905ba41c286b0645f0c667362","value":"Login successful"}},"44d30b0ecad54f818f27bbd1858cdf3f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5685a3fe6b084791b1c41bede0ee8429":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5764ccc3c9b943ac9031bb4fbf65ee84":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dcb4bd1b7424f698dcfe1586ecaaa87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7393008614c94b7f9aee294715d1f9c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6eb7b2e427a4fb3b984a0346394555a","placeholder":"​","style":"IPY_MODEL_34efbeb9bdcf42b28bcfdf48289bb943","value":"Your token has been saved in your configured git credential helpers (store)."}},"7b5d107e75ec4226b2f951fa5eac32c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"85e73a9905ba41c286b0645f0c667362":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c792771c4604d9b8f6bcda700f2ad74":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91cf6c949361472e8cdc02a27371892b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"PasswordModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_5764ccc3c9b943ac9031bb4fbf65ee84","placeholder":"​","style":"IPY_MODEL_f6f5badeb1f749d8a1a74c737ea45b81","value":""}},"9d286f232614404eac3e78415a823171":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26b0af06bf1549bd8f16e297a3d5c4fa","placeholder":"​","style":"IPY_MODEL_b289ce6929414af38bd4cd4ddf68bfe4","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"a6333daeaf584192b2d8222134dc02a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb0ffca70a4645458b4650ff588f82cc","placeholder":"​","style":"IPY_MODEL_fec956e2f3ac4760a951569986ebb5c2","value":"Your token has been saved to /root/.cache/huggingface/token"}},"b289ce6929414af38bd4cd4ddf68bfe4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b292b711914d4f14abd2436aeb8050f8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3bfd48d65b748349afd7e3e5000baff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"b6eb7b2e427a4fb3b984a0346394555a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bad09d132dcc420fbad7ace8cc25aa06":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcab8a3e3c3f45d48890e88d50d8e982":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_b292b711914d4f14abd2436aeb8050f8","style":"IPY_MODEL_b3bfd48d65b748349afd7e3e5000baff","tooltip":""}},"c42b74a51b7843c7b8a9fca7d90bfd1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19649549a1ad47368ec9f6eeba1e80ff","placeholder":"​","style":"IPY_MODEL_3bd1b8a5cbdf4345b34a6042ad3c6383","value":"Connecting..."}},"d1a558c379ac48cc80c19ef9898d871d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_25bd97f157d8485fb15438d25d83421c","IPY_MODEL_7393008614c94b7f9aee294715d1f9c8","IPY_MODEL_a6333daeaf584192b2d8222134dc02a9","IPY_MODEL_3d0bb7ba88104e458caaaf9c72914b97"],"layout":"IPY_MODEL_7b5d107e75ec4226b2f951fa5eac32c7"}},"dbbfbb222a7d4ce18c1c7b655fc89ae1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"CheckboxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_5685a3fe6b084791b1c41bede0ee8429","style":"IPY_MODEL_6dcb4bd1b7424f698dcfe1586ecaaa87","value":true}},"f6f5badeb1f749d8a1a74c737ea45b81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb0ffca70a4645458b4650ff588f82cc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fec956e2f3ac4760a951569986ebb5c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Abstractive summaries - Train DistilBART on TWEETSUMM dataset","metadata":{"id":"AvCot6IFw3LG"}},{"cell_type":"code","source":"from huggingface_hub import login\nimport pandas as pd\nimport numpy as np\nimport os, time, datetime\n\nfrom datasets import Dataset, DatasetDict\n\nfrom transformers import DataCollatorForSeq2Seq, AutoTokenizer, set_seed\nfrom transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\nfrom transformers import TrainerCallback, TrainingArguments, TrainerState, TrainerControl\n\nimport wandb","metadata":{"id":"csIsnw2147iB","outputId":"b1168797-2e98-4a6a-81e1-9e079f98ab53","scrolled":true,"execution":{"iopub.status.busy":"2024-09-11T11:43:59.196899Z","iopub.execute_input":"2024-09-11T11:43:59.197215Z","iopub.status.idle":"2024-09-11T11:44:19.824056Z","shell.execute_reply.started":"2024-09-11T11:43:59.197174Z","shell.execute_reply":"2024-09-11T11:44:19.823271Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip freeze > requirements_bart.txt","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-09-11T11:44:19.825601Z","iopub.execute_input":"2024-09-11T11:44:19.825871Z","iopub.status.idle":"2024-09-11T11:44:23.177148Z","shell.execute_reply.started":"2024-09-11T11:44:19.825842Z","shell.execute_reply":"2024-09-11T11:44:23.175964Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"}]},{"cell_type":"code","source":"ds_dir = os.path.join(os.getcwd(), 'data')\ntry:\n    HF_TOKEN =  os.environ['HF_TOKEN']\nexcept:\n    HF_TOKEN = \"\"\n\nif 'google.colab' in str(get_ipython()):\n    print(\"Running on Colab\")\n    from google.colab import drive, userdata\n    drive.mount('/content/drive')\n    HF_TOKEN = userdata.get('HF_TOKEN')\nelif os.environ.get('KAGGLE_KERNEL_RUN_TYPE') != None:\n    ds_dir = '/kaggle/input/bertdata2207/'\n    # ds_dir=\"/kaggle/input/bertdata2207/\"\n    from kaggle_secrets import UserSecretsClient\n    print(\"Running on Kaggle\")\n    # ds_dir = \"/kaggle/input/tweet-data-2106-1512/\"\n    user_secrets = UserSecretsClient()\n    HF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")\n    WANDB_API_KEY = user_secrets.get_secret(\"WANDB_API_KEY\")\n    os.environ['WANDB_API_KEY'] = WANDB_API_KEY\n    os.makedirs(os.path.join(os.getcwd(), \"results\"), exist_ok=True)\n","metadata":{"id":"D7StYsAaxJLT","outputId":"3690cf47-554a-424d-b42e-e8f77bb4bbf5","execution":{"iopub.status.busy":"2024-09-11T11:44:23.178618Z","iopub.execute_input":"2024-09-11T11:44:23.178977Z","iopub.status.idle":"2024-09-11T11:44:24.911121Z","shell.execute_reply.started":"2024-09-11T11:44:23.178910Z","shell.execute_reply":"2024-09-11T11:44:24.910108Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Running on Kaggle\n","output_type":"stream"}]},{"cell_type":"code","source":"set_seed(17)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:44:24.913700Z","iopub.execute_input":"2024-09-11T11:44:24.914205Z","iopub.status.idle":"2024-09-11T11:44:24.926566Z","shell.execute_reply.started":"2024-09-11T11:44:24.914160Z","shell.execute_reply":"2024-09-11T11:44:24.925412Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def get_current_time():\n    return datetime.datetime.now().strftime(\"%d%m-%H%M\")","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:44:24.927677Z","iopub.execute_input":"2024-09-11T11:44:24.928000Z","iopub.status.idle":"2024-09-11T11:44:25.019776Z","shell.execute_reply.started":"2024-09-11T11:44:24.927964Z","shell.execute_reply":"2024-09-11T11:44:25.018792Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"run_name = f\"bart-abs-{get_current_time()}\"","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:44:25.020968Z","iopub.execute_input":"2024-09-11T11:44:25.021288Z","iopub.status.idle":"2024-09-11T11:44:25.029467Z","shell.execute_reply.started":"2024-09-11T11:44:25.021256Z","shell.execute_reply":"2024-09-11T11:44:25.028602Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"os.environ[\"WANDB_PROJECT\"] = \"aiml-thesis-train-test-temp\"\nos.environ[\"WANDB_WATCH\"] = \"all\"\nwandb.init(settings=wandb.Settings(start_method=\"thread\"), id=run_name)","metadata":{"id":"XCVrFPA4GL-h","outputId":"228dbbaf-c276-495e-e759-0ecb0b4a1ebb","scrolled":true,"execution":{"iopub.status.busy":"2024-09-11T11:44:25.030642Z","iopub.execute_input":"2024-09-11T11:44:25.031371Z","iopub.status.idle":"2024-09-11T11:44:45.154744Z","shell.execute_reply.started":"2024-09-11T11:44:25.031328Z","shell.execute_reply":"2024-09-11T11:44:45.153556Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdawidk5\u001b[0m (\u001b[33mdawidk5ul\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.9 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240911_114427-bart-abs-1109-1144</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dawidk5ul/aiml-thesis-train-test-temp/runs/bart-abs-1109-1144' target=\"_blank\">bart-abs-1109-1144</a></strong> to <a href='https://wandb.ai/dawidk5ul/aiml-thesis-train-test-temp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dawidk5ul/aiml-thesis-train-test-temp' target=\"_blank\">https://wandb.ai/dawidk5ul/aiml-thesis-train-test-temp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dawidk5ul/aiml-thesis-train-test-temp/runs/bart-abs-1109-1144' target=\"_blank\">https://wandb.ai/dawidk5ul/aiml-thesis-train-test-temp/runs/bart-abs-1109-1144</a>"},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dawidk5ul/aiml-thesis-train-test-temp/runs/bart-abs-1109-1144?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7cf71b73b5e0>"},"metadata":{}}]},{"cell_type":"code","source":"login(token=HF_TOKEN)","metadata":{"id":"QoMm76b2i2NX","outputId":"f5df06b4-ac4d-4be9-8044-20010745149b","execution":{"iopub.status.busy":"2024-09-11T11:44:45.156087Z","iopub.execute_input":"2024-09-11T11:44:45.156951Z","iopub.status.idle":"2024-09-11T11:44:45.385792Z","shell.execute_reply.started":"2024-09-11T11:44:45.156882Z","shell.execute_reply":"2024-09-11T11:44:45.384664Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load data","metadata":{"id":"xP2HgEaKi2Nk"}},{"cell_type":"code","source":"print(ds_dir)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:44:45.387102Z","iopub.execute_input":"2024-09-11T11:44:45.387407Z","iopub.status.idle":"2024-09-11T11:44:45.393732Z","shell.execute_reply.started":"2024-09-11T11:44:45.387374Z","shell.execute_reply":"2024-09-11T11:44:45.392607Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"/kaggle/input/bertdata2207/\n","output_type":"stream"}]},{"cell_type":"code","source":"checkpoint_bart = \"sshleifer/distilbart-xsum-12-6\"","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:44:45.398579Z","iopub.execute_input":"2024-09-11T11:44:45.398874Z","iopub.status.idle":"2024-09-11T11:44:45.404519Z","shell.execute_reply.started":"2024-09-11T11:44:45.398842Z","shell.execute_reply":"2024-09-11T11:44:45.403331Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_df_temp = pd.read_csv(os.path.join(ds_dir,\"dials_abs_2607_1312_train_spc.csv\"), names=['conv_id','dialogue','summary'], encoding='utf-8', dtype={'conv_id':'string', 'dialogue':'string', 'summary': 'string'})\ntrain_df_temp = train_df_temp.convert_dtypes()\ntrain_df_temp.drop(columns=['conv_id'], inplace=True)\ntrain_df_temp.reset_index(drop=True, inplace=True)\n\nval_df_temp = pd.read_csv(os.path.join(ds_dir,\"dials_abs_2607_1312_valid_spc.csv\"), names=['conv_id','dialogue','summary'], encoding='utf-8', dtype={'conv_id':'string', 'dialogue':'string', 'summary': 'string'})\nval_df_temp = val_df_temp.convert_dtypes()\nval_df_temp.drop(columns=['conv_id'], inplace=True)\nval_df_temp.reset_index(drop=True, inplace=True)\n\ntest_df_temp = pd.read_csv(os.path.join(ds_dir,\"dials_abs_2607_1312_test_spc.csv\"), names=['conv_id','dialogue','summary'], encoding='utf-8', dtype={'conv_id':'string', 'dialogue':'string', 'summary': 'string'})\ntest_df_temp = test_df_temp.convert_dtypes()\ntest_df_temp.reset_index(drop=True, inplace=True)\n\nprint(train_df_temp.dtypes)\nprint(train_df_temp.head())\n\nPD_DATASETS = {'train': train_df_temp, 'validation': val_df_temp, 'test': test_df_temp}","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-09-11T11:44:45.405873Z","iopub.execute_input":"2024-09-11T11:44:45.406402Z","iopub.status.idle":"2024-09-11T11:44:45.486786Z","shell.execute_reply.started":"2024-09-11T11:44:45.406359Z","shell.execute_reply":"2024-09-11T11:44:45.485713Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"dialogue    string[python]\nsummary     string[python]\ndtype: object\n                                            dialogue  \\\n0  Customer: So neither my iPhone nor my Apple Wa...   \n1  Customer: @115850 hi team! i m planning to get...   \n2  Customer: @AskAmex Where do I write to address...   \n3  Customer: @AmazonHelp @115821 Wow, expected 4 ...   \n4  Customer: @GWRHelp I'd rather you spent some t...   \n\n                                             summary  \n0  Customer enquired about his Iphone and Apple w...  \n1  Customer is eager to know about the replacemen...  \n2  Signed up for an AmexCard with Delta but it di...  \n3  The customer have a problem. The agent is very...  \n4  Customer cannot purchase a train ticket on the...  \n","output_type":"stream"}]},{"cell_type":"code","source":"tweetsumm_abs = DatasetDict(\n    {\n        'train': Dataset.from_pandas(train_df_temp),\n        'validation': Dataset.from_pandas(val_df_temp),\n        'test': Dataset.from_pandas(test_df_temp)\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:44:45.488139Z","iopub.execute_input":"2024-09-11T11:44:45.488550Z","iopub.status.idle":"2024-09-11T11:44:45.543896Z","shell.execute_reply.started":"2024-09-11T11:44:45.488503Z","shell.execute_reply":"2024-09-11T11:44:45.542876Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(checkpoint_bart)\nprint(tokenizer)","metadata":{"id":"F-hzIHQ9w3Lb","scrolled":true,"execution":{"iopub.status.busy":"2024-09-11T11:44:45.545420Z","iopub.execute_input":"2024-09-11T11:44:45.545838Z","iopub.status.idle":"2024-09-11T11:44:49.592053Z","shell.execute_reply.started":"2024-09-11T11:44:45.545788Z","shell.execute_reply":"2024-09-11T11:44:49.590880Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a950d4b6b6b44921857d63e51f902188"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.59k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdd7ba544ccc494f9de623b1cf244804"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad60d3af37dc4e459c12d265551d5c94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"127815f29585470a82c9d7715bf97bac"}},"metadata":{}},{"name":"stdout","text":"BartTokenizerFast(name_or_path='sshleifer/distilbart-xsum-12-6', vocab_size=50265, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Source: https://huggingface.co/docs/transformers/en/tasks/summarization\n\ndef preprocess_function(examples):\n    prefix = \"summarize: \"\n    inputs = [str(prefix) + str(dial) for dial in examples[\"dialogue\"]]\n    model_inputs = tokenizer(inputs, max_length=512, truncation=True) # same params as tweetsumm paper\n    labels = tokenizer(text_target=examples[\"summary\"], max_length=80, truncation=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"id":"vVQdGPfZw3Lb","execution":{"iopub.status.busy":"2024-09-11T11:44:49.593630Z","iopub.execute_input":"2024-09-11T11:44:49.594073Z","iopub.status.idle":"2024-09-11T11:44:49.603777Z","shell.execute_reply.started":"2024-09-11T11:44:49.594027Z","shell.execute_reply":"2024-09-11T11:44:49.602984Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"tokenized_tweetsumm_abs = tweetsumm_abs.map(preprocess_function, batched=True, remove_columns=['dialogue','summary'])\nprint(tokenized_tweetsumm_abs[\"train\"][1])","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:44:49.605071Z","iopub.execute_input":"2024-09-11T11:44:49.605364Z","iopub.status.idle":"2024-09-11T11:44:50.453038Z","shell.execute_reply.started":"2024-09-11T11:44:49.605333Z","shell.execute_reply":"2024-09-11T11:44:50.452173Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/867 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"082617a24c6b4cc78e3cb6b8f9b80a18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/110 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24dd7eb3ff454b58af2a1454d9f20ca3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/109 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c191bdb634514f329fca8972daf2dfb2"}},"metadata":{}},{"name":"stdout","text":"{'input_ids': [0, 18581, 3916, 2072, 35, 19458, 35, 787, 1225, 4432, 1096, 20280, 165, 328, 939, 475, 1884, 7, 120, 1257, 1754, 510, 20529, 27785, 24, 924, 15, 5, 998, 24, 34, 158, 360, 5010, 21784, 6, 64, 1717, 3922, 162, 99, 16, 24, 17487, 50118, 45443, 35, 787, 2481, 3897, 2036, 166, 348, 10, 158, 7033, 5010, 714, 114, 5, 6880, 47, 829, 16, 5009, 50, 31559, 4, 37249, 10237, 50118, 44799, 35, 787, 25146, 28780, 5148, 27785, 125, 99, 114, 939, 399, 17, 27, 90, 101, 5, 1152, 8, 236, 7, 671, 24, 50118, 45443, 35, 787, 2481, 3897, 2036, 166, 1979, 75, 28, 441, 7, 3264, 5, 23312, 2886, 4, 286, 55, 335, 15, 1830, 2886, 714, 4, 17161, 352, 3753, 15, 5, 3104, 1373, 259, 35, 1205, 640, 90, 4, 876, 73, 571, 40969, 9380, 530, 4154, 510, 975, 4, 3166, 19954, 877, 110, 2969, 4, 50118, 44799, 35, 787, 25146, 28780, 5148, 2446, 27785, 125, 209, 32, 5567, 15797, 98, 473, 24, 1266, 276, 714, 3253, 13, 209, 25, 157, 50118, 45443, 35, 787, 2481, 3897, 2036, 3216, 6, 30845, 73, 5567, 15797, 32, 45, 4973, 13, 23312, 2886, 4, 96, 403, 9, 143, 1880, 73, 17584, 47, 64, 1338, 66, 7, 201, 6, 52, 581, 1649, 8, 244, 47, 14649, 4, 37249, 846, 487, 50118, 44799, 35, 787, 25146, 28780, 5534, 15983, 27785, 4557, 13, 5, 244, 27785, 7840, 10874, 44660, 50118, 45443, 35, 787, 2481, 3897, 2036, 4557, 7, 47, 350, 13, 2969, 4, 1832, 489, 201, 1278, 13, 143, 617, 1379, 4, 166, 581, 28, 1372, 7, 244, 4, 17841, 27969, 37249, 846, 487, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [0, 44799, 16, 7921, 7, 216, 59, 5, 5010, 714, 15, 5, 5567, 15797, 37, 8605, 7, 907, 4, 18497, 2305, 14, 24, 129, 11459, 114, 5, 829, 6880, 16, 31559, 50, 5009, 4, 2]}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Setup Training Evaluation","metadata":{"id":"97ha331Ii2Np"}},{"cell_type":"code","source":"!pip install -U nltk","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:44:50.454333Z","iopub.execute_input":"2024-09-11T11:44:50.454627Z","iopub.status.idle":"2024-09-11T11:45:05.339555Z","shell.execute_reply.started":"2024-09-11T11:44:50.454595Z","shell.execute_reply":"2024-09-11T11:45:05.338395Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nCollecting nltk\n  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2024.5.15)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.66.4)\nDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nltk\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nltk-3.9.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install evaluate pyrouge rouge_score bert_score meteor","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-09-11T11:45:05.341555Z","iopub.execute_input":"2024-09-11T11:45:05.342065Z","iopub.status.idle":"2024-09-11T11:46:41.489930Z","shell.execute_reply.started":"2024-09-11T11:45:05.342000Z","shell.execute_reply":"2024-09-11T11:46:41.488725Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting pyrouge\n  Downloading pyrouge-0.1.3.tar.gz (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting bert_score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nCollecting meteor\n  Downloading meteor-2.0.16-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.21.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.24.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.9.1)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (2.4.0)\nRequirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert_score) (4.44.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert_score) (3.7.5)\nCollecting bgzip<0.6.0,>=0.5.0 (from meteor)\n  Downloading bgzip-0.5.0.tar.gz (100 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.2/100.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting biom-format<3.0.0,>=2.1.15 (from meteor)\n  Downloading biom-format-2.1.16.tar.gz (11.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting cogent3<2025.0.0,>=2024.2.5a1 (from meteor)\n  Downloading cogent3-2024.7.19a6-py3-none-any.whl.metadata (13 kB)\nCollecting ete3<4.0.0,>=3.1.3 (from meteor)\n  Downloading ete3-3.1.3.tar.gz (4.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting packaging (from evaluate)\n  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting pyarrow<16.0.0,>=15.0.0 (from meteor)\n  Downloading pyarrow-15.0.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\nCollecting pysam<0.23.0,>=0.22.0 (from meteor)\n  Downloading pysam-0.22.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from biom-format<3.0.0,>=2.1.15->meteor) (8.1.7)\nRequirement already satisfied: scipy>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from biom-format<3.0.0,>=2.1.15->meteor) (1.14.0)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from biom-format<3.0.0,>=2.1.15->meteor) (3.11.0)\nCollecting chardet (from cogent3<2025.0.0,>=2024.2.5a1->meteor)\n  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\nCollecting loky (from cogent3<2025.0.0,>=2024.2.5a1->meteor)\n  Downloading loky-3.4.1-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: numba>0.53 in /opt/conda/lib/python3.10/site-packages (from cogent3<2025.0.0,>=2024.2.5a1->meteor) (0.58.1)\nCollecting scitrack (from cogent3<2025.0.0,>=2024.2.5a1->meteor)\n  Downloading scitrack-2021.5.3-py3-none-any.whl.metadata (8.7 kB)\nCollecting stevedore (from cogent3<2025.0.0,>=2024.2.5a1->meteor)\n  Downloading stevedore-5.3.0-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from cogent3<2025.0.0,>=2024.2.5a1->meteor) (4.12.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.7.4)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert_score) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert_score) (0.19.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert_score) (3.1.2)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->rouge_score) (1.4.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>0.53->cogent3<2025.0.0,>=2024.2.5a1->meteor) (0.41.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.5)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from loky->cogent3<2025.0.0,>=2024.2.5a1->meteor) (3.0.0)\nCollecting pbr>=2.0.0 (from stevedore->cogent3<2025.0.0,>=2024.2.5a1->meteor)\n  Downloading pbr-6.1.0-py2.py3-none-any.whl.metadata (3.4 kB)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading meteor-2.0.16-py3-none-any.whl (61.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cogent3-2024.7.19a6-py3-none-any.whl (746 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m746.6/746.6 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow-15.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pysam-0.22.1-cp310-cp310-manylinux_2_28_x86_64.whl (22.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.0/22.0 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading loky-3.4.1-py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scitrack-2021.5.3-py3-none-any.whl (7.8 kB)\nDownloading stevedore-5.3.0-py3-none-any.whl (49 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pbr-6.1.0-py2.py3-none-any.whl (108 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pyrouge, rouge_score, bgzip, biom-format, ete3\n  Building wheel for pyrouge (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyrouge: filename=pyrouge-0.1.3-py3-none-any.whl size=191604 sha256=c72fcd783b70ae6cd7a9ce3e69bc2cbd6a62f932b9abf6a35a06127caaf564c7\n  Stored in directory: /root/.cache/pip/wheels/9a/67/12/c5dd8ef8b4152bb8789eafd2a74a734e2dc7bb9eae02b768e7\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=2deb6652bf3f928d7c0382700debf44cc83f2ec164956b63f5097c4782aca8df\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n  Building wheel for bgzip (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for bgzip: filename=bgzip-0.5.0-cp310-cp310-linux_x86_64.whl size=57885 sha256=9ae411a751c322421fb4a4181b0fb9cd28b0e39dbe6fe34b19cefc0a7ab231ea\n  Stored in directory: /root/.cache/pip/wheels/1c/b8/56/9367ade000d28a1a7f9439b7c040719e0d2c0152ddf216f5da\n  Building wheel for biom-format (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for biom-format: filename=biom_format-2.1.16-cp310-cp310-linux_x86_64.whl size=11803585 sha256=0cdee86bdfa341145ef3e071a2b08a8ebef31e10191d010ce9bbf208e77b6d4d\n  Stored in directory: /root/.cache/pip/wheels/8e/a9/f9/197fd5a0e5bbab5f2e03c89194f6c194bed7af5d7a8c8759f3\n  Building wheel for ete3 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ete3: filename=ete3-3.1.3-py3-none-any.whl size=2273786 sha256=928c7d9ce9de194a1f691e8757e8ac287ace074274b55a4da85c31b5448a8d1e\n  Stored in directory: /root/.cache/pip/wheels/a0/72/00/1982bd848e52b03079dbf800900120bc1c20e92e9a1216e525\nSuccessfully built pyrouge rouge_score bgzip biom-format ete3\nInstalling collected packages: pyrouge, ete3, bgzip, scitrack, pysam, pyarrow, pbr, packaging, loky, chardet, stevedore, rouge_score, cogent3, biom-format, meteor, evaluate, bert_score\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 16.1.0\n    Uninstalling pyarrow-16.1.0:\n      Successfully uninstalled pyarrow-16.1.0\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.8.2 requires cubinlinker, which is not installed.\ncudf 24.8.2 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.2 requires ptxcompiler, which is not installed.\ncuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.8.2 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\nbeatrix-jupyterlab 2024.66.154055 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.4 which is incompatible.\ncudf 24.8.2 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\ncudf 24.8.2 requires pyarrow<16.2.0a0,>=16.1.0, but you have pyarrow 15.0.2 which is incompatible.\ndistributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.8.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\nibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 15.0.2 which is incompatible.\njupyterlab 4.2.4 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.4 requires shapely<2.1,>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nrapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.8.1 which is incompatible.\nspaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.9.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bert_score-0.3.13 bgzip-0.5.0 biom-format-2.1.16 chardet-5.2.0 cogent3-2024.7.19a6 ete3-3.1.3 evaluate-0.4.3 loky-3.4.1 meteor-2.0.16 packaging-23.2 pbr-6.1.0 pyarrow-15.0.2 pyrouge-0.1.3 pysam-0.22.1 rouge_score-0.1.2 scitrack-2021.5.3 stevedore-5.3.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate, nltk, csv\nrouge = evaluate.load(\"rouge\")\nmeteor = evaluate.load(\"meteor\")\nbertscore = evaluate.load(\"bertscore\")\n\nnltk.download('punkt_tab')","metadata":{"id":"dHQv7Aeai2Nr","outputId":"6c4222bd-bf8f-4588-9871-716bd2cee0ca","scrolled":true,"execution":{"iopub.status.busy":"2024-09-11T11:46:41.491573Z","iopub.execute_input":"2024-09-11T11:46:41.491916Z","iopub.status.idle":"2024-09-11T11:46:49.333202Z","shell.execute_reply.started":"2024-09-11T11:46:41.491875Z","shell.execute_reply":"2024-09-11T11:46:49.332118Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64a7b45889ab484993175d26b35aa1af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.93k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4ce6a785b6e4b359b673feca8cf902a"}},"metadata":{}},{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6abcaf7f3a924bbf8edd1af285506e09"}},"metadata":{}},{"name":"stderr","text":"[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics_abs(eval_pred):\n    predictions, labels = eval_pred\n    # Extra line added to address an overflow: https://github.com/huggingface/transformers/issues/22634\n    predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n\n    rouge_scores = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n    bert_scores = bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")\n    bert_scores.pop('hashcode')\n    result = {\n      **{f\"rouge/{k}\": round(v, 4) for k,v in rouge_scores.items()},\n      **{f\"bertscore/bertscore-{k}\": round(np.mean(v), 4) for k,v in bert_scores.items()},\n      'meteor': round(meteor.compute(predictions=decoded_preds, references=decoded_labels)['meteor'], 4),\n    }\n   \n    result[\"gen_len\"] = np.mean(prediction_lens)\n    return result\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:46:49.335667Z","iopub.execute_input":"2024-09-11T11:46:49.336119Z","iopub.status.idle":"2024-09-11T11:46:49.348117Z","shell.execute_reply.started":"2024-09-11T11:46:49.336068Z","shell.execute_reply":"2024-09-11T11:46:49.347134Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Train and Evaluate","metadata":{"id":"4W_3h_eHi2Nu"}},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint_bart)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:46:49.349770Z","iopub.execute_input":"2024-09-11T11:46:49.350194Z","iopub.status.idle":"2024-09-11T11:47:31.927816Z","shell.execute_reply.started":"2024-09-11T11:46:49.350149Z","shell.execute_reply":"2024-09-11T11:47:31.926805Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/611M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd2f2f5054504ad0845da5c7c3d0e606"}},"metadata":{}}]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)","metadata":{"id":"irJUvr6gi2No","execution":{"iopub.status.busy":"2024-09-11T11:47:31.929215Z","iopub.execute_input":"2024-09-11T11:47:31.929606Z","iopub.status.idle":"2024-09-11T11:47:31.935573Z","shell.execute_reply.started":"2024-09-11T11:47:31.929558Z","shell.execute_reply":"2024-09-11T11:47:31.934736Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"my_batch = data_collator(tokenized_tweetsumm_abs['train'])\nassert len(my_batch) == 4 # default setting for the model","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:47:31.936717Z","iopub.execute_input":"2024-09-11T11:47:31.937035Z","iopub.status.idle":"2024-09-11T11:47:34.205429Z","shell.execute_reply.started":"2024-09-11T11:47:31.937003Z","shell.execute_reply":"2024-09-11T11:47:34.204271Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"EXPERIMENT_PARAMS = []\nBASE_PARAMS = {'lr':3e-5, 'batch_size':4, 'epochs': 6}\nEXPERIMENT_PARAMS.append(BASE_PARAMS)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:47:34.206892Z","iopub.execute_input":"2024-09-11T11:47:34.207349Z","iopub.status.idle":"2024-09-11T11:47:34.213244Z","shell.execute_reply.started":"2024-09-11T11:47:34.207298Z","shell.execute_reply":"2024-09-11T11:47:34.212269Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"LEARN_RATES = (3e-5, 3e-4, 3e-6)\nBATCH_SIZES = (4, 2, 8)\nEPOCHS = (6,10)\n\nfor lr in LEARN_RATES:\n    for batch_size in BATCH_SIZES:\n        for epoch in EPOCHS:\n            if lr == BASE_PARAMS['lr'] and batch_size == BASE_PARAMS['batch_size'] and epoch == BASE_PARAMS['epochs']:\n                continue\n            experiment = {'lr':lr, 'batch_size':batch_size, 'epochs': epoch}\n            EXPERIMENT_PARAMS.append(experiment)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-09-11T11:47:34.214496Z","iopub.execute_input":"2024-09-11T11:47:34.215098Z","iopub.status.idle":"2024-09-11T11:47:34.227957Z","shell.execute_reply.started":"2024-09-11T11:47:34.215065Z","shell.execute_reply":"2024-09-11T11:47:34.226873Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def run_post_training(split, test_details, test_df_temp: pd.DataFrame, tokenizer, experiment, run_name_model, epoch):\n    # First line added due to label error, see \n    predictions = np.where(test_details.predictions != -100, test_details.predictions, tokenizer.pad_token_id)\n    preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    test_df_temp['response'] = preds\n    exp_res = None\n    csv_items = {**experiment, **(test_details.metrics)}\n    if not exp_res:\n        exp_res = {k: list() for k in csv_items.keys()}\n    else:\n        for k, v in csv_items.items():\n            exp_res[k].append(v)\n\n    test_metrics_df = pd.DataFrame(exp_res)\n    test_df_temp.convert_dtypes()\n    test_metrics_df.convert_dtypes()\n    wandb.log({run_name_model: test_details.metrics})\n    preds_name = f\"{split}_preds_{run_name_model.replace('-','_')}_{epoch}_bart.csv\"\n    metrics_name =  f\"{split}_metrics_{run_name_model.replace('-','_')}_{epoch}_bart.csv\"\n    test_df_temp.to_csv(os.path.join(os.getcwd(), 'results', preds_name), index=False, header=False, encoding='utf-8', quoting=csv.QUOTE_ALL)\n    test_metrics_df.to_csv(os.path.join(os.getcwd(), 'results', metrics_name), index=False, header=True, encoding='utf-8', quoting=csv.QUOTE_ALL)\n    # Using wandb documentation: https://docs.wandb.ai/guides/artifacts\n    for root, dirs, files in os.walk(os.path.join(os.getcwd(), 'results')):\n        for file in files:\n            artifact = wandb.Artifact(name=run_name_model, type=\"predictions\")\n            artifact.add_file(local_path=os.path.join(root, file), name=file)\n            wandb.log_artifact(artifact)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:47:34.229068Z","iopub.execute_input":"2024-09-11T11:47:34.229370Z","iopub.status.idle":"2024-09-11T11:47:34.243347Z","shell.execute_reply.started":"2024-09-11T11:47:34.229335Z","shell.execute_reply":"2024-09-11T11:47:34.242267Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class ExtraCallback(TrainerCallback):\n    def __init__(self):\n        self.experiment_rows = []\n        \n#     def on_log(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):\n#         print(len(state.log_history), state.log_history)\n#         self.experiment_rows.append(state.log_history[-1])\n#         wandb.log({'run_name': args.run_name, **state.log_history[-1]})\n        \n    def on_epoch_end(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):\n        # Save loss from state, log current epoch to wandb\n        \n        # 'lr': args['learning_rate'], 'batch_size': args['per_device_train_batch_size'], 'max_epochs' args['num_train_epochs']\n        wandb.log({'run_name': args.run_name, **state.log_history[-1]})\n#         df = pd.DataFrame(self.experiment_rows)\n#         df = df.convert_dtypes()\n#         df.to_csv(os.path.join('.', 'results', args['run_name'] + \".csv\", header=True, index=False))\n    \n    def on_train_end(self, args, state, control, **kwargs):\n        # Save and upload CSVs\n        df = pd.DataFrame(state.log_history)\n        df = df.convert_dtypes()\n        df = df.groupby(['epoch'], as_index=False).mean()\n        df.to_csv(os.path.join('.', 'results', args.run_name + \".csv\"), header=True, index=False)\n        \n        \n#         for split in ('train', 'validation', 'test'):\n#             test_details = trainer.predict(tokenized_tweetsumm_abs[split], metric_key_prefix=split)\n#             run_post_training(split, test_details, PD_DATASETS[split], tokenizer, exp, run_name_model, state.epoch)\n#         if epoch in EPOCHS:\n#             trainer.push_to_hub()\n        ","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:47:34.244656Z","iopub.execute_input":"2024-09-11T11:47:34.244976Z","iopub.status.idle":"2024-09-11T11:47:34.258743Z","shell.execute_reply.started":"2024-09-11T11:47:34.244941Z","shell.execute_reply":"2024-09-11T11:47:34.257875Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"exp_res = None\nfor count, exp in enumerate(EXPERIMENT_PARAMS):\n    current_time = get_current_time()\n    run_name_model = f\"temp-bart-abs-{current_time}-lr-{exp['lr']}-bs-{exp['batch_size']}-maxep-{exp['epochs']}\"\n    print(\"Starting experiment\", count, run_name_model, \"training\")\n    wandb.run.name = run_name_model\n    wandb.run.save()\n\n    training_args = Seq2SeqTrainingArguments(\n        output_dir=os.path.join('.', run_model_name),\n        eval_strategy=\"epoch\",\n        logging_strategy=\"epoch\",\n        # logging_steps=100,\n        learning_rate=exp['lr'],\n        per_device_train_batch_size=exp['batch_size'],\n        per_device_eval_batch_size=exp['batch_size'],\n        weight_decay=0.01,\n        save_strategy=\"epoch\", # \"epoch\",\n        save_total_limit=1,\n        load_best_model_at_end=True,\n        metric_for_best_model=\"eval_loss\",\n        greater_is_better=False,\n        num_train_epochs=exp['epochs'],\n        predict_with_generate=True,\n        fp16=True,\n        generation_max_length=80,\n        push_to_hub=False,\n        report_to=\"none\",\n        run_name=run_name_model\n    )\n    trainer = Seq2SeqTrainer(\n        model=model,\n        args=training_args,\n        train_dataset=tokenized_tweetsumm_abs[\"train\"].select(range(0,50)),\n        eval_dataset=tokenized_tweetsumm_abs[\"validation\"].select(range(0,10)),\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics_abs,\n    )\n    trainer.add_callback(ExtraCallback)\n    training_start = time.time()\n    trainer.train()\n    training_end = time.time()\n    print(\"Finished\",  run_name_model, \"time it took for training:\", str(datetime.timedelta(seconds=(training_end-training_start))))","metadata":{"id":"nj5v3nT9i2Nw","outputId":"512d759b-0343-4f83-e36c-cf15fec503a3","execution":{"iopub.status.busy":"2024-09-11T11:47:34.262013Z","iopub.execute_input":"2024-09-11T11:47:34.262912Z","iopub.status.idle":"2024-09-11T11:50:58.941298Z","shell.execute_reply.started":"2024-09-11T11:47:34.262866Z","shell.execute_reply":"2024-09-11T11:50:58.940278Z"},"scrolled":true,"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n","output_type":"stream"},{"name":"stdout","text":"Starting experiment 0 bart-abs-1109-1147-lr-3e-05-bs-4-maxep-6 training\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [78/78 01:28, Epoch 6/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge/rouge1</th>\n      <th>Rouge/rouge2</th>\n      <th>Rouge/rougel</th>\n      <th>Rouge/rougelsum</th>\n      <th>Bertscore/bertscore-precision</th>\n      <th>Bertscore/bertscore-recall</th>\n      <th>Bertscore/bertscore-f1</th>\n      <th>Meteor</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>4.375500</td>\n      <td>3.195378</td>\n      <td>0.268600</td>\n      <td>0.105000</td>\n      <td>0.234000</td>\n      <td>0.233200</td>\n      <td>0.892000</td>\n      <td>0.844500</td>\n      <td>0.867500</td>\n      <td>0.155800</td>\n      <td>14.900000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2.938100</td>\n      <td>2.833267</td>\n      <td>0.326300</td>\n      <td>0.177000</td>\n      <td>0.273500</td>\n      <td>0.272400</td>\n      <td>0.925600</td>\n      <td>0.858800</td>\n      <td>0.890800</td>\n      <td>0.203800</td>\n      <td>16.500000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.126700</td>\n      <td>2.655557</td>\n      <td>0.298200</td>\n      <td>0.156300</td>\n      <td>0.250300</td>\n      <td>0.250100</td>\n      <td>0.911700</td>\n      <td>0.852000</td>\n      <td>0.880700</td>\n      <td>0.178800</td>\n      <td>16.100000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.639700</td>\n      <td>2.695941</td>\n      <td>0.359900</td>\n      <td>0.173100</td>\n      <td>0.306500</td>\n      <td>0.305300</td>\n      <td>0.909500</td>\n      <td>0.865400</td>\n      <td>0.886700</td>\n      <td>0.262400</td>\n      <td>21.200000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.333700</td>\n      <td>2.775159</td>\n      <td>0.354200</td>\n      <td>0.142300</td>\n      <td>0.299300</td>\n      <td>0.298700</td>\n      <td>0.908200</td>\n      <td>0.868100</td>\n      <td>0.887600</td>\n      <td>0.233900</td>\n      <td>23.700000</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.119600</td>\n      <td>2.827520</td>\n      <td>0.330500</td>\n      <td>0.130500</td>\n      <td>0.274000</td>\n      <td>0.274700</td>\n      <td>0.899600</td>\n      <td>0.860900</td>\n      <td>0.879700</td>\n      <td>0.216700</td>\n      <td>22.300000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"1 [{'loss': 4.3755, 'grad_norm': 14.370349884033203, 'learning_rate': 2.6153846153846157e-05, 'epoch': 1.0, 'step': 13}]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60bce94b603a4314a236adf9c98d916a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ae2e8e640e0459495601689b346029d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1ad18c5958248d88c2bb5cf81885a08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad7837da615d48b08f6ec532ba11adbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c64aa393693b414ea46b613e33f0fd81"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8825efd51bc4f2b898b20d743533c49"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"2 [{'loss': 4.3755, 'grad_norm': 14.370349884033203, 'learning_rate': 2.6153846153846157e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 3.195378303527832, 'eval_rouge/rouge1': 0.2686, 'eval_rouge/rouge2': 0.105, 'eval_rouge/rougeL': 0.234, 'eval_rouge/rougeLsum': 0.2332, 'eval_bertscore/bertscore-precision': 0.892, 'eval_bertscore/bertscore-recall': 0.8445, 'eval_bertscore/bertscore-f1': 0.8675, 'eval_meteor': 0.1558, 'eval_gen_len': 14.9, 'eval_runtime': 41.1023, 'eval_samples_per_second': 0.243, 'eval_steps_per_second': 0.073, 'epoch': 1.0, 'step': 13}]\n3 [{'loss': 4.3755, 'grad_norm': 14.370349884033203, 'learning_rate': 2.6153846153846157e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 3.195378303527832, 'eval_rouge/rouge1': 0.2686, 'eval_rouge/rouge2': 0.105, 'eval_rouge/rougeL': 0.234, 'eval_rouge/rougeLsum': 0.2332, 'eval_bertscore/bertscore-precision': 0.892, 'eval_bertscore/bertscore-recall': 0.8445, 'eval_bertscore/bertscore-f1': 0.8675, 'eval_meteor': 0.1558, 'eval_gen_len': 14.9, 'eval_runtime': 41.1023, 'eval_samples_per_second': 0.243, 'eval_steps_per_second': 0.073, 'epoch': 1.0, 'step': 13}, {'loss': 2.9381, 'grad_norm': 12.300722122192383, 'learning_rate': 2.1153846153846157e-05, 'epoch': 2.0, 'step': 26}]\n4 [{'loss': 4.3755, 'grad_norm': 14.370349884033203, 'learning_rate': 2.6153846153846157e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 3.195378303527832, 'eval_rouge/rouge1': 0.2686, 'eval_rouge/rouge2': 0.105, 'eval_rouge/rougeL': 0.234, 'eval_rouge/rougeLsum': 0.2332, 'eval_bertscore/bertscore-precision': 0.892, 'eval_bertscore/bertscore-recall': 0.8445, 'eval_bertscore/bertscore-f1': 0.8675, 'eval_meteor': 0.1558, 'eval_gen_len': 14.9, 'eval_runtime': 41.1023, 'eval_samples_per_second': 0.243, 'eval_steps_per_second': 0.073, 'epoch': 1.0, 'step': 13}, {'loss': 2.9381, 'grad_norm': 12.300722122192383, 'learning_rate': 2.1153846153846157e-05, 'epoch': 2.0, 'step': 26}, {'eval_loss': 2.8332674503326416, 'eval_rouge/rouge1': 0.3263, 'eval_rouge/rouge2': 0.177, 'eval_rouge/rougeL': 0.2735, 'eval_rouge/rougeLsum': 0.2724, 'eval_bertscore/bertscore-precision': 0.9256, 'eval_bertscore/bertscore-recall': 0.8588, 'eval_bertscore/bertscore-f1': 0.8908, 'eval_meteor': 0.2038, 'eval_gen_len': 16.5, 'eval_runtime': 2.6308, 'eval_samples_per_second': 3.801, 'eval_steps_per_second': 1.14, 'epoch': 2.0, 'step': 26}]\n5 [{'loss': 4.3755, 'grad_norm': 14.370349884033203, 'learning_rate': 2.6153846153846157e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 3.195378303527832, 'eval_rouge/rouge1': 0.2686, 'eval_rouge/rouge2': 0.105, 'eval_rouge/rougeL': 0.234, 'eval_rouge/rougeLsum': 0.2332, 'eval_bertscore/bertscore-precision': 0.892, 'eval_bertscore/bertscore-recall': 0.8445, 'eval_bertscore/bertscore-f1': 0.8675, 'eval_meteor': 0.1558, 'eval_gen_len': 14.9, 'eval_runtime': 41.1023, 'eval_samples_per_second': 0.243, 'eval_steps_per_second': 0.073, 'epoch': 1.0, 'step': 13}, {'loss': 2.9381, 'grad_norm': 12.300722122192383, 'learning_rate': 2.1153846153846157e-05, 'epoch': 2.0, 'step': 26}, {'eval_loss': 2.8332674503326416, 'eval_rouge/rouge1': 0.3263, 'eval_rouge/rouge2': 0.177, 'eval_rouge/rougeL': 0.2735, 'eval_rouge/rougeLsum': 0.2724, 'eval_bertscore/bertscore-precision': 0.9256, 'eval_bertscore/bertscore-recall': 0.8588, 'eval_bertscore/bertscore-f1': 0.8908, 'eval_meteor': 0.2038, 'eval_gen_len': 16.5, 'eval_runtime': 2.6308, 'eval_samples_per_second': 3.801, 'eval_steps_per_second': 1.14, 'epoch': 2.0, 'step': 26}, {'loss': 2.1267, 'grad_norm': 10.091501235961914, 'learning_rate': 1.6153846153846154e-05, 'epoch': 3.0, 'step': 39}]\n6 [{'loss': 4.3755, 'grad_norm': 14.370349884033203, 'learning_rate': 2.6153846153846157e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 3.195378303527832, 'eval_rouge/rouge1': 0.2686, 'eval_rouge/rouge2': 0.105, 'eval_rouge/rougeL': 0.234, 'eval_rouge/rougeLsum': 0.2332, 'eval_bertscore/bertscore-precision': 0.892, 'eval_bertscore/bertscore-recall': 0.8445, 'eval_bertscore/bertscore-f1': 0.8675, 'eval_meteor': 0.1558, 'eval_gen_len': 14.9, 'eval_runtime': 41.1023, 'eval_samples_per_second': 0.243, 'eval_steps_per_second': 0.073, 'epoch': 1.0, 'step': 13}, {'loss': 2.9381, 'grad_norm': 12.300722122192383, 'learning_rate': 2.1153846153846157e-05, 'epoch': 2.0, 'step': 26}, {'eval_loss': 2.8332674503326416, 'eval_rouge/rouge1': 0.3263, 'eval_rouge/rouge2': 0.177, 'eval_rouge/rougeL': 0.2735, 'eval_rouge/rougeLsum': 0.2724, 'eval_bertscore/bertscore-precision': 0.9256, 'eval_bertscore/bertscore-recall': 0.8588, 'eval_bertscore/bertscore-f1': 0.8908, 'eval_meteor': 0.2038, 'eval_gen_len': 16.5, 'eval_runtime': 2.6308, 'eval_samples_per_second': 3.801, 'eval_steps_per_second': 1.14, 'epoch': 2.0, 'step': 26}, {'loss': 2.1267, 'grad_norm': 10.091501235961914, 'learning_rate': 1.6153846153846154e-05, 'epoch': 3.0, 'step': 39}, {'eval_loss': 2.6555569171905518, 'eval_rouge/rouge1': 0.2982, 'eval_rouge/rouge2': 0.1563, 'eval_rouge/rougeL': 0.2503, 'eval_rouge/rougeLsum': 0.2501, 'eval_bertscore/bertscore-precision': 0.9117, 'eval_bertscore/bertscore-recall': 0.852, 'eval_bertscore/bertscore-f1': 0.8807, 'eval_meteor': 0.1788, 'eval_gen_len': 16.1, 'eval_runtime': 2.7388, 'eval_samples_per_second': 3.651, 'eval_steps_per_second': 1.095, 'epoch': 3.0, 'step': 39}]\n7 [{'loss': 4.3755, 'grad_norm': 14.370349884033203, 'learning_rate': 2.6153846153846157e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 3.195378303527832, 'eval_rouge/rouge1': 0.2686, 'eval_rouge/rouge2': 0.105, 'eval_rouge/rougeL': 0.234, 'eval_rouge/rougeLsum': 0.2332, 'eval_bertscore/bertscore-precision': 0.892, 'eval_bertscore/bertscore-recall': 0.8445, 'eval_bertscore/bertscore-f1': 0.8675, 'eval_meteor': 0.1558, 'eval_gen_len': 14.9, 'eval_runtime': 41.1023, 'eval_samples_per_second': 0.243, 'eval_steps_per_second': 0.073, 'epoch': 1.0, 'step': 13}, {'loss': 2.9381, 'grad_norm': 12.300722122192383, 'learning_rate': 2.1153846153846157e-05, 'epoch': 2.0, 'step': 26}, {'eval_loss': 2.8332674503326416, 'eval_rouge/rouge1': 0.3263, 'eval_rouge/rouge2': 0.177, 'eval_rouge/rougeL': 0.2735, 'eval_rouge/rougeLsum': 0.2724, 'eval_bertscore/bertscore-precision': 0.9256, 'eval_bertscore/bertscore-recall': 0.8588, 'eval_bertscore/bertscore-f1': 0.8908, 'eval_meteor': 0.2038, 'eval_gen_len': 16.5, 'eval_runtime': 2.6308, 'eval_samples_per_second': 3.801, 'eval_steps_per_second': 1.14, 'epoch': 2.0, 'step': 26}, {'loss': 2.1267, 'grad_norm': 10.091501235961914, 'learning_rate': 1.6153846153846154e-05, 'epoch': 3.0, 'step': 39}, {'eval_loss': 2.6555569171905518, 'eval_rouge/rouge1': 0.2982, 'eval_rouge/rouge2': 0.1563, 'eval_rouge/rougeL': 0.2503, 'eval_rouge/rougeLsum': 0.2501, 'eval_bertscore/bertscore-precision': 0.9117, 'eval_bertscore/bertscore-recall': 0.852, 'eval_bertscore/bertscore-f1': 0.8807, 'eval_meteor': 0.1788, 'eval_gen_len': 16.1, 'eval_runtime': 2.7388, 'eval_samples_per_second': 3.651, 'eval_steps_per_second': 1.095, 'epoch': 3.0, 'step': 39}, {'loss': 1.6397, 'grad_norm': 10.484790802001953, 'learning_rate': 1.1153846153846154e-05, 'epoch': 4.0, 'step': 52}]\n8 [{'loss': 4.3755, 'grad_norm': 14.370349884033203, 'learning_rate': 2.6153846153846157e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 3.195378303527832, 'eval_rouge/rouge1': 0.2686, 'eval_rouge/rouge2': 0.105, 'eval_rouge/rougeL': 0.234, 'eval_rouge/rougeLsum': 0.2332, 'eval_bertscore/bertscore-precision': 0.892, 'eval_bertscore/bertscore-recall': 0.8445, 'eval_bertscore/bertscore-f1': 0.8675, 'eval_meteor': 0.1558, 'eval_gen_len': 14.9, 'eval_runtime': 41.1023, 'eval_samples_per_second': 0.243, 'eval_steps_per_second': 0.073, 'epoch': 1.0, 'step': 13}, {'loss': 2.9381, 'grad_norm': 12.300722122192383, 'learning_rate': 2.1153846153846157e-05, 'epoch': 2.0, 'step': 26}, {'eval_loss': 2.8332674503326416, 'eval_rouge/rouge1': 0.3263, 'eval_rouge/rouge2': 0.177, 'eval_rouge/rougeL': 0.2735, 'eval_rouge/rougeLsum': 0.2724, 'eval_bertscore/bertscore-precision': 0.9256, 'eval_bertscore/bertscore-recall': 0.8588, 'eval_bertscore/bertscore-f1': 0.8908, 'eval_meteor': 0.2038, 'eval_gen_len': 16.5, 'eval_runtime': 2.6308, 'eval_samples_per_second': 3.801, 'eval_steps_per_second': 1.14, 'epoch': 2.0, 'step': 26}, {'loss': 2.1267, 'grad_norm': 10.091501235961914, 'learning_rate': 1.6153846153846154e-05, 'epoch': 3.0, 'step': 39}, {'eval_loss': 2.6555569171905518, 'eval_rouge/rouge1': 0.2982, 'eval_rouge/rouge2': 0.1563, 'eval_rouge/rougeL': 0.2503, 'eval_rouge/rougeLsum': 0.2501, 'eval_bertscore/bertscore-precision': 0.9117, 'eval_bertscore/bertscore-recall': 0.852, 'eval_bertscore/bertscore-f1': 0.8807, 'eval_meteor': 0.1788, 'eval_gen_len': 16.1, 'eval_runtime': 2.7388, 'eval_samples_per_second': 3.651, 'eval_steps_per_second': 1.095, 'epoch': 3.0, 'step': 39}, {'loss': 1.6397, 'grad_norm': 10.484790802001953, 'learning_rate': 1.1153846153846154e-05, 'epoch': 4.0, 'step': 52}, {'eval_loss': 2.695941209793091, 'eval_rouge/rouge1': 0.3599, 'eval_rouge/rouge2': 0.1731, 'eval_rouge/rougeL': 0.3065, 'eval_rouge/rougeLsum': 0.3053, 'eval_bertscore/bertscore-precision': 0.9095, 'eval_bertscore/bertscore-recall': 0.8654, 'eval_bertscore/bertscore-f1': 0.8867, 'eval_meteor': 0.2624, 'eval_gen_len': 21.2, 'eval_runtime': 2.8129, 'eval_samples_per_second': 3.555, 'eval_steps_per_second': 1.067, 'epoch': 4.0, 'step': 52}]\n9 [{'loss': 4.3755, 'grad_norm': 14.370349884033203, 'learning_rate': 2.6153846153846157e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 3.195378303527832, 'eval_rouge/rouge1': 0.2686, 'eval_rouge/rouge2': 0.105, 'eval_rouge/rougeL': 0.234, 'eval_rouge/rougeLsum': 0.2332, 'eval_bertscore/bertscore-precision': 0.892, 'eval_bertscore/bertscore-recall': 0.8445, 'eval_bertscore/bertscore-f1': 0.8675, 'eval_meteor': 0.1558, 'eval_gen_len': 14.9, 'eval_runtime': 41.1023, 'eval_samples_per_second': 0.243, 'eval_steps_per_second': 0.073, 'epoch': 1.0, 'step': 13}, {'loss': 2.9381, 'grad_norm': 12.300722122192383, 'learning_rate': 2.1153846153846157e-05, 'epoch': 2.0, 'step': 26}, {'eval_loss': 2.8332674503326416, 'eval_rouge/rouge1': 0.3263, 'eval_rouge/rouge2': 0.177, 'eval_rouge/rougeL': 0.2735, 'eval_rouge/rougeLsum': 0.2724, 'eval_bertscore/bertscore-precision': 0.9256, 'eval_bertscore/bertscore-recall': 0.8588, 'eval_bertscore/bertscore-f1': 0.8908, 'eval_meteor': 0.2038, 'eval_gen_len': 16.5, 'eval_runtime': 2.6308, 'eval_samples_per_second': 3.801, 'eval_steps_per_second': 1.14, 'epoch': 2.0, 'step': 26}, {'loss': 2.1267, 'grad_norm': 10.091501235961914, 'learning_rate': 1.6153846153846154e-05, 'epoch': 3.0, 'step': 39}, {'eval_loss': 2.6555569171905518, 'eval_rouge/rouge1': 0.2982, 'eval_rouge/rouge2': 0.1563, 'eval_rouge/rougeL': 0.2503, 'eval_rouge/rougeLsum': 0.2501, 'eval_bertscore/bertscore-precision': 0.9117, 'eval_bertscore/bertscore-recall': 0.852, 'eval_bertscore/bertscore-f1': 0.8807, 'eval_meteor': 0.1788, 'eval_gen_len': 16.1, 'eval_runtime': 2.7388, 'eval_samples_per_second': 3.651, 'eval_steps_per_second': 1.095, 'epoch': 3.0, 'step': 39}, {'loss': 1.6397, 'grad_norm': 10.484790802001953, 'learning_rate': 1.1153846153846154e-05, 'epoch': 4.0, 'step': 52}, {'eval_loss': 2.695941209793091, 'eval_rouge/rouge1': 0.3599, 'eval_rouge/rouge2': 0.1731, 'eval_rouge/rougeL': 0.3065, 'eval_rouge/rougeLsum': 0.3053, 'eval_bertscore/bertscore-precision': 0.9095, 'eval_bertscore/bertscore-recall': 0.8654, 'eval_bertscore/bertscore-f1': 0.8867, 'eval_meteor': 0.2624, 'eval_gen_len': 21.2, 'eval_runtime': 2.8129, 'eval_samples_per_second': 3.555, 'eval_steps_per_second': 1.067, 'epoch': 4.0, 'step': 52}, {'loss': 1.3337, 'grad_norm': 12.3429536819458, 'learning_rate': 6.153846153846154e-06, 'epoch': 5.0, 'step': 65}]\n10 [{'loss': 4.3755, 'grad_norm': 14.370349884033203, 'learning_rate': 2.6153846153846157e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 3.195378303527832, 'eval_rouge/rouge1': 0.2686, 'eval_rouge/rouge2': 0.105, 'eval_rouge/rougeL': 0.234, 'eval_rouge/rougeLsum': 0.2332, 'eval_bertscore/bertscore-precision': 0.892, 'eval_bertscore/bertscore-recall': 0.8445, 'eval_bertscore/bertscore-f1': 0.8675, 'eval_meteor': 0.1558, 'eval_gen_len': 14.9, 'eval_runtime': 41.1023, 'eval_samples_per_second': 0.243, 'eval_steps_per_second': 0.073, 'epoch': 1.0, 'step': 13}, {'loss': 2.9381, 'grad_norm': 12.300722122192383, 'learning_rate': 2.1153846153846157e-05, 'epoch': 2.0, 'step': 26}, {'eval_loss': 2.8332674503326416, 'eval_rouge/rouge1': 0.3263, 'eval_rouge/rouge2': 0.177, 'eval_rouge/rougeL': 0.2735, 'eval_rouge/rougeLsum': 0.2724, 'eval_bertscore/bertscore-precision': 0.9256, 'eval_bertscore/bertscore-recall': 0.8588, 'eval_bertscore/bertscore-f1': 0.8908, 'eval_meteor': 0.2038, 'eval_gen_len': 16.5, 'eval_runtime': 2.6308, 'eval_samples_per_second': 3.801, 'eval_steps_per_second': 1.14, 'epoch': 2.0, 'step': 26}, {'loss': 2.1267, 'grad_norm': 10.091501235961914, 'learning_rate': 1.6153846153846154e-05, 'epoch': 3.0, 'step': 39}, {'eval_loss': 2.6555569171905518, 'eval_rouge/rouge1': 0.2982, 'eval_rouge/rouge2': 0.1563, 'eval_rouge/rougeL': 0.2503, 'eval_rouge/rougeLsum': 0.2501, 'eval_bertscore/bertscore-precision': 0.9117, 'eval_bertscore/bertscore-recall': 0.852, 'eval_bertscore/bertscore-f1': 0.8807, 'eval_meteor': 0.1788, 'eval_gen_len': 16.1, 'eval_runtime': 2.7388, 'eval_samples_per_second': 3.651, 'eval_steps_per_second': 1.095, 'epoch': 3.0, 'step': 39}, {'loss': 1.6397, 'grad_norm': 10.484790802001953, 'learning_rate': 1.1153846153846154e-05, 'epoch': 4.0, 'step': 52}, {'eval_loss': 2.695941209793091, 'eval_rouge/rouge1': 0.3599, 'eval_rouge/rouge2': 0.1731, 'eval_rouge/rougeL': 0.3065, 'eval_rouge/rougeLsum': 0.3053, 'eval_bertscore/bertscore-precision': 0.9095, 'eval_bertscore/bertscore-recall': 0.8654, 'eval_bertscore/bertscore-f1': 0.8867, 'eval_meteor': 0.2624, 'eval_gen_len': 21.2, 'eval_runtime': 2.8129, 'eval_samples_per_second': 3.555, 'eval_steps_per_second': 1.067, 'epoch': 4.0, 'step': 52}, {'loss': 1.3337, 'grad_norm': 12.3429536819458, 'learning_rate': 6.153846153846154e-06, 'epoch': 5.0, 'step': 65}, {'eval_loss': 2.775158643722534, 'eval_rouge/rouge1': 0.3542, 'eval_rouge/rouge2': 0.1423, 'eval_rouge/rougeL': 0.2993, 'eval_rouge/rougeLsum': 0.2987, 'eval_bertscore/bertscore-precision': 0.9082, 'eval_bertscore/bertscore-recall': 0.8681, 'eval_bertscore/bertscore-f1': 0.8876, 'eval_meteor': 0.2339, 'eval_gen_len': 23.7, 'eval_runtime': 2.8986, 'eval_samples_per_second': 3.45, 'eval_steps_per_second': 1.035, 'epoch': 5.0, 'step': 65}]\n11 [{'loss': 4.3755, 'grad_norm': 14.370349884033203, 'learning_rate': 2.6153846153846157e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 3.195378303527832, 'eval_rouge/rouge1': 0.2686, 'eval_rouge/rouge2': 0.105, 'eval_rouge/rougeL': 0.234, 'eval_rouge/rougeLsum': 0.2332, 'eval_bertscore/bertscore-precision': 0.892, 'eval_bertscore/bertscore-recall': 0.8445, 'eval_bertscore/bertscore-f1': 0.8675, 'eval_meteor': 0.1558, 'eval_gen_len': 14.9, 'eval_runtime': 41.1023, 'eval_samples_per_second': 0.243, 'eval_steps_per_second': 0.073, 'epoch': 1.0, 'step': 13}, {'loss': 2.9381, 'grad_norm': 12.300722122192383, 'learning_rate': 2.1153846153846157e-05, 'epoch': 2.0, 'step': 26}, {'eval_loss': 2.8332674503326416, 'eval_rouge/rouge1': 0.3263, 'eval_rouge/rouge2': 0.177, 'eval_rouge/rougeL': 0.2735, 'eval_rouge/rougeLsum': 0.2724, 'eval_bertscore/bertscore-precision': 0.9256, 'eval_bertscore/bertscore-recall': 0.8588, 'eval_bertscore/bertscore-f1': 0.8908, 'eval_meteor': 0.2038, 'eval_gen_len': 16.5, 'eval_runtime': 2.6308, 'eval_samples_per_second': 3.801, 'eval_steps_per_second': 1.14, 'epoch': 2.0, 'step': 26}, {'loss': 2.1267, 'grad_norm': 10.091501235961914, 'learning_rate': 1.6153846153846154e-05, 'epoch': 3.0, 'step': 39}, {'eval_loss': 2.6555569171905518, 'eval_rouge/rouge1': 0.2982, 'eval_rouge/rouge2': 0.1563, 'eval_rouge/rougeL': 0.2503, 'eval_rouge/rougeLsum': 0.2501, 'eval_bertscore/bertscore-precision': 0.9117, 'eval_bertscore/bertscore-recall': 0.852, 'eval_bertscore/bertscore-f1': 0.8807, 'eval_meteor': 0.1788, 'eval_gen_len': 16.1, 'eval_runtime': 2.7388, 'eval_samples_per_second': 3.651, 'eval_steps_per_second': 1.095, 'epoch': 3.0, 'step': 39}, {'loss': 1.6397, 'grad_norm': 10.484790802001953, 'learning_rate': 1.1153846153846154e-05, 'epoch': 4.0, 'step': 52}, {'eval_loss': 2.695941209793091, 'eval_rouge/rouge1': 0.3599, 'eval_rouge/rouge2': 0.1731, 'eval_rouge/rougeL': 0.3065, 'eval_rouge/rougeLsum': 0.3053, 'eval_bertscore/bertscore-precision': 0.9095, 'eval_bertscore/bertscore-recall': 0.8654, 'eval_bertscore/bertscore-f1': 0.8867, 'eval_meteor': 0.2624, 'eval_gen_len': 21.2, 'eval_runtime': 2.8129, 'eval_samples_per_second': 3.555, 'eval_steps_per_second': 1.067, 'epoch': 4.0, 'step': 52}, {'loss': 1.3337, 'grad_norm': 12.3429536819458, 'learning_rate': 6.153846153846154e-06, 'epoch': 5.0, 'step': 65}, {'eval_loss': 2.775158643722534, 'eval_rouge/rouge1': 0.3542, 'eval_rouge/rouge2': 0.1423, 'eval_rouge/rougeL': 0.2993, 'eval_rouge/rougeLsum': 0.2987, 'eval_bertscore/bertscore-precision': 0.9082, 'eval_bertscore/bertscore-recall': 0.8681, 'eval_bertscore/bertscore-f1': 0.8876, 'eval_meteor': 0.2339, 'eval_gen_len': 23.7, 'eval_runtime': 2.8986, 'eval_samples_per_second': 3.45, 'eval_steps_per_second': 1.035, 'epoch': 5.0, 'step': 65}, {'loss': 1.1196, 'grad_norm': 9.597577095031738, 'learning_rate': 1.153846153846154e-06, 'epoch': 6.0, 'step': 78}]\n12 [{'loss': 4.3755, 'grad_norm': 14.370349884033203, 'learning_rate': 2.6153846153846157e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 3.195378303527832, 'eval_rouge/rouge1': 0.2686, 'eval_rouge/rouge2': 0.105, 'eval_rouge/rougeL': 0.234, 'eval_rouge/rougeLsum': 0.2332, 'eval_bertscore/bertscore-precision': 0.892, 'eval_bertscore/bertscore-recall': 0.8445, 'eval_bertscore/bertscore-f1': 0.8675, 'eval_meteor': 0.1558, 'eval_gen_len': 14.9, 'eval_runtime': 41.1023, 'eval_samples_per_second': 0.243, 'eval_steps_per_second': 0.073, 'epoch': 1.0, 'step': 13}, {'loss': 2.9381, 'grad_norm': 12.300722122192383, 'learning_rate': 2.1153846153846157e-05, 'epoch': 2.0, 'step': 26}, {'eval_loss': 2.8332674503326416, 'eval_rouge/rouge1': 0.3263, 'eval_rouge/rouge2': 0.177, 'eval_rouge/rougeL': 0.2735, 'eval_rouge/rougeLsum': 0.2724, 'eval_bertscore/bertscore-precision': 0.9256, 'eval_bertscore/bertscore-recall': 0.8588, 'eval_bertscore/bertscore-f1': 0.8908, 'eval_meteor': 0.2038, 'eval_gen_len': 16.5, 'eval_runtime': 2.6308, 'eval_samples_per_second': 3.801, 'eval_steps_per_second': 1.14, 'epoch': 2.0, 'step': 26}, {'loss': 2.1267, 'grad_norm': 10.091501235961914, 'learning_rate': 1.6153846153846154e-05, 'epoch': 3.0, 'step': 39}, {'eval_loss': 2.6555569171905518, 'eval_rouge/rouge1': 0.2982, 'eval_rouge/rouge2': 0.1563, 'eval_rouge/rougeL': 0.2503, 'eval_rouge/rougeLsum': 0.2501, 'eval_bertscore/bertscore-precision': 0.9117, 'eval_bertscore/bertscore-recall': 0.852, 'eval_bertscore/bertscore-f1': 0.8807, 'eval_meteor': 0.1788, 'eval_gen_len': 16.1, 'eval_runtime': 2.7388, 'eval_samples_per_second': 3.651, 'eval_steps_per_second': 1.095, 'epoch': 3.0, 'step': 39}, {'loss': 1.6397, 'grad_norm': 10.484790802001953, 'learning_rate': 1.1153846153846154e-05, 'epoch': 4.0, 'step': 52}, {'eval_loss': 2.695941209793091, 'eval_rouge/rouge1': 0.3599, 'eval_rouge/rouge2': 0.1731, 'eval_rouge/rougeL': 0.3065, 'eval_rouge/rougeLsum': 0.3053, 'eval_bertscore/bertscore-precision': 0.9095, 'eval_bertscore/bertscore-recall': 0.8654, 'eval_bertscore/bertscore-f1': 0.8867, 'eval_meteor': 0.2624, 'eval_gen_len': 21.2, 'eval_runtime': 2.8129, 'eval_samples_per_second': 3.555, 'eval_steps_per_second': 1.067, 'epoch': 4.0, 'step': 52}, {'loss': 1.3337, 'grad_norm': 12.3429536819458, 'learning_rate': 6.153846153846154e-06, 'epoch': 5.0, 'step': 65}, {'eval_loss': 2.775158643722534, 'eval_rouge/rouge1': 0.3542, 'eval_rouge/rouge2': 0.1423, 'eval_rouge/rougeL': 0.2993, 'eval_rouge/rougeLsum': 0.2987, 'eval_bertscore/bertscore-precision': 0.9082, 'eval_bertscore/bertscore-recall': 0.8681, 'eval_bertscore/bertscore-f1': 0.8876, 'eval_meteor': 0.2339, 'eval_gen_len': 23.7, 'eval_runtime': 2.8986, 'eval_samples_per_second': 3.45, 'eval_steps_per_second': 1.035, 'epoch': 5.0, 'step': 65}, {'loss': 1.1196, 'grad_norm': 9.597577095031738, 'learning_rate': 1.153846153846154e-06, 'epoch': 6.0, 'step': 78}, {'eval_loss': 2.827519655227661, 'eval_rouge/rouge1': 0.3305, 'eval_rouge/rouge2': 0.1305, 'eval_rouge/rougeL': 0.274, 'eval_rouge/rougeLsum': 0.2747, 'eval_bertscore/bertscore-precision': 0.8996, 'eval_bertscore/bertscore-recall': 0.8609, 'eval_bertscore/bertscore-f1': 0.8797, 'eval_meteor': 0.2167, 'eval_gen_len': 22.3, 'eval_runtime': 2.6957, 'eval_samples_per_second': 3.71, 'eval_steps_per_second': 1.113, 'epoch': 6.0, 'step': 78}]\n13 [{'loss': 4.3755, 'grad_norm': 14.370349884033203, 'learning_rate': 2.6153846153846157e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 3.195378303527832, 'eval_rouge/rouge1': 0.2686, 'eval_rouge/rouge2': 0.105, 'eval_rouge/rougeL': 0.234, 'eval_rouge/rougeLsum': 0.2332, 'eval_bertscore/bertscore-precision': 0.892, 'eval_bertscore/bertscore-recall': 0.8445, 'eval_bertscore/bertscore-f1': 0.8675, 'eval_meteor': 0.1558, 'eval_gen_len': 14.9, 'eval_runtime': 41.1023, 'eval_samples_per_second': 0.243, 'eval_steps_per_second': 0.073, 'epoch': 1.0, 'step': 13}, {'loss': 2.9381, 'grad_norm': 12.300722122192383, 'learning_rate': 2.1153846153846157e-05, 'epoch': 2.0, 'step': 26}, {'eval_loss': 2.8332674503326416, 'eval_rouge/rouge1': 0.3263, 'eval_rouge/rouge2': 0.177, 'eval_rouge/rougeL': 0.2735, 'eval_rouge/rougeLsum': 0.2724, 'eval_bertscore/bertscore-precision': 0.9256, 'eval_bertscore/bertscore-recall': 0.8588, 'eval_bertscore/bertscore-f1': 0.8908, 'eval_meteor': 0.2038, 'eval_gen_len': 16.5, 'eval_runtime': 2.6308, 'eval_samples_per_second': 3.801, 'eval_steps_per_second': 1.14, 'epoch': 2.0, 'step': 26}, {'loss': 2.1267, 'grad_norm': 10.091501235961914, 'learning_rate': 1.6153846153846154e-05, 'epoch': 3.0, 'step': 39}, {'eval_loss': 2.6555569171905518, 'eval_rouge/rouge1': 0.2982, 'eval_rouge/rouge2': 0.1563, 'eval_rouge/rougeL': 0.2503, 'eval_rouge/rougeLsum': 0.2501, 'eval_bertscore/bertscore-precision': 0.9117, 'eval_bertscore/bertscore-recall': 0.852, 'eval_bertscore/bertscore-f1': 0.8807, 'eval_meteor': 0.1788, 'eval_gen_len': 16.1, 'eval_runtime': 2.7388, 'eval_samples_per_second': 3.651, 'eval_steps_per_second': 1.095, 'epoch': 3.0, 'step': 39}, {'loss': 1.6397, 'grad_norm': 10.484790802001953, 'learning_rate': 1.1153846153846154e-05, 'epoch': 4.0, 'step': 52}, {'eval_loss': 2.695941209793091, 'eval_rouge/rouge1': 0.3599, 'eval_rouge/rouge2': 0.1731, 'eval_rouge/rougeL': 0.3065, 'eval_rouge/rougeLsum': 0.3053, 'eval_bertscore/bertscore-precision': 0.9095, 'eval_bertscore/bertscore-recall': 0.8654, 'eval_bertscore/bertscore-f1': 0.8867, 'eval_meteor': 0.2624, 'eval_gen_len': 21.2, 'eval_runtime': 2.8129, 'eval_samples_per_second': 3.555, 'eval_steps_per_second': 1.067, 'epoch': 4.0, 'step': 52}, {'loss': 1.3337, 'grad_norm': 12.3429536819458, 'learning_rate': 6.153846153846154e-06, 'epoch': 5.0, 'step': 65}, {'eval_loss': 2.775158643722534, 'eval_rouge/rouge1': 0.3542, 'eval_rouge/rouge2': 0.1423, 'eval_rouge/rougeL': 0.2993, 'eval_rouge/rougeLsum': 0.2987, 'eval_bertscore/bertscore-precision': 0.9082, 'eval_bertscore/bertscore-recall': 0.8681, 'eval_bertscore/bertscore-f1': 0.8876, 'eval_meteor': 0.2339, 'eval_gen_len': 23.7, 'eval_runtime': 2.8986, 'eval_samples_per_second': 3.45, 'eval_steps_per_second': 1.035, 'epoch': 5.0, 'step': 65}, {'loss': 1.1196, 'grad_norm': 9.597577095031738, 'learning_rate': 1.153846153846154e-06, 'epoch': 6.0, 'step': 78}, {'eval_loss': 2.827519655227661, 'eval_rouge/rouge1': 0.3305, 'eval_rouge/rouge2': 0.1305, 'eval_rouge/rougeL': 0.274, 'eval_rouge/rougeLsum': 0.2747, 'eval_bertscore/bertscore-precision': 0.8996, 'eval_bertscore/bertscore-recall': 0.8609, 'eval_bertscore/bertscore-f1': 0.8797, 'eval_meteor': 0.2167, 'eval_gen_len': 22.3, 'eval_runtime': 2.6957, 'eval_samples_per_second': 3.71, 'eval_steps_per_second': 1.113, 'epoch': 6.0, 'step': 78}, {'train_runtime': 89.1803, 'train_samples_per_second': 3.364, 'train_steps_per_second': 0.875, 'total_flos': 201491595239424.0, 'train_loss': 2.25553351182204, 'epoch': 6.0, 'step': 78}]\nFinished bart-abs-1109-1147-lr-3e-05-bs-4-maxep-6 time it took for training: 0:01:29.846218\nStarting experiment 1 bart-abs-1109-1149-lr-3e-05-bs-4-maxep-10 training\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [78/78 00:51, Epoch 6/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge/rouge1</th>\n      <th>Rouge/rouge2</th>\n      <th>Rouge/rougel</th>\n      <th>Rouge/rougelsum</th>\n      <th>Bertscore/bertscore-precision</th>\n      <th>Bertscore/bertscore-recall</th>\n      <th>Bertscore/bertscore-f1</th>\n      <th>Meteor</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.154600</td>\n      <td>2.958326</td>\n      <td>0.384000</td>\n      <td>0.170200</td>\n      <td>0.332900</td>\n      <td>0.334000</td>\n      <td>0.915600</td>\n      <td>0.872600</td>\n      <td>0.893500</td>\n      <td>0.271100</td>\n      <td>23.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.870400</td>\n      <td>3.037460</td>\n      <td>0.323300</td>\n      <td>0.127300</td>\n      <td>0.283600</td>\n      <td>0.283700</td>\n      <td>0.905300</td>\n      <td>0.862400</td>\n      <td>0.883200</td>\n      <td>0.227800</td>\n      <td>22.400000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.530400</td>\n      <td>3.362633</td>\n      <td>0.382900</td>\n      <td>0.156800</td>\n      <td>0.316500</td>\n      <td>0.314500</td>\n      <td>0.899400</td>\n      <td>0.868000</td>\n      <td>0.883300</td>\n      <td>0.291400</td>\n      <td>26.900000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.363600</td>\n      <td>3.577489</td>\n      <td>0.353200</td>\n      <td>0.127700</td>\n      <td>0.273900</td>\n      <td>0.275300</td>\n      <td>0.900500</td>\n      <td>0.867000</td>\n      <td>0.883300</td>\n      <td>0.266500</td>\n      <td>26.400000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.262100</td>\n      <td>3.700132</td>\n      <td>0.379300</td>\n      <td>0.127100</td>\n      <td>0.313200</td>\n      <td>0.312300</td>\n      <td>0.905800</td>\n      <td>0.871200</td>\n      <td>0.888000</td>\n      <td>0.280900</td>\n      <td>26.200000</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.226700</td>\n      <td>3.815955</td>\n      <td>0.367500</td>\n      <td>0.133300</td>\n      <td>0.309900</td>\n      <td>0.308700</td>\n      <td>0.905200</td>\n      <td>0.868600</td>\n      <td>0.886400</td>\n      <td>0.269000</td>\n      <td>24.400000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"1 [{'loss': 1.1546, 'grad_norm': 11.703929901123047, 'learning_rate': 2.5384615384615386e-05, 'epoch': 1.0, 'step': 13}]\n2 [{'loss': 1.1546, 'grad_norm': 11.703929901123047, 'learning_rate': 2.5384615384615386e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 2.9583256244659424, 'eval_rouge/rouge1': 0.384, 'eval_rouge/rouge2': 0.1702, 'eval_rouge/rougeL': 0.3329, 'eval_rouge/rougeLsum': 0.334, 'eval_bertscore/bertscore-precision': 0.9156, 'eval_bertscore/bertscore-recall': 0.8726, 'eval_bertscore/bertscore-f1': 0.8935, 'eval_meteor': 0.2711, 'eval_gen_len': 23.0, 'eval_runtime': 2.8473, 'eval_samples_per_second': 3.512, 'eval_steps_per_second': 1.054, 'epoch': 1.0, 'step': 13}]\n3 [{'loss': 1.1546, 'grad_norm': 11.703929901123047, 'learning_rate': 2.5384615384615386e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 2.9583256244659424, 'eval_rouge/rouge1': 0.384, 'eval_rouge/rouge2': 0.1702, 'eval_rouge/rougeL': 0.3329, 'eval_rouge/rougeLsum': 0.334, 'eval_bertscore/bertscore-precision': 0.9156, 'eval_bertscore/bertscore-recall': 0.8726, 'eval_bertscore/bertscore-f1': 0.8935, 'eval_meteor': 0.2711, 'eval_gen_len': 23.0, 'eval_runtime': 2.8473, 'eval_samples_per_second': 3.512, 'eval_steps_per_second': 1.054, 'epoch': 1.0, 'step': 13}, {'loss': 0.8704, 'grad_norm': 11.185465812683105, 'learning_rate': 2.0384615384615387e-05, 'epoch': 2.0, 'step': 26}]\n4 [{'loss': 1.1546, 'grad_norm': 11.703929901123047, 'learning_rate': 2.5384615384615386e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 2.9583256244659424, 'eval_rouge/rouge1': 0.384, 'eval_rouge/rouge2': 0.1702, 'eval_rouge/rougeL': 0.3329, 'eval_rouge/rougeLsum': 0.334, 'eval_bertscore/bertscore-precision': 0.9156, 'eval_bertscore/bertscore-recall': 0.8726, 'eval_bertscore/bertscore-f1': 0.8935, 'eval_meteor': 0.2711, 'eval_gen_len': 23.0, 'eval_runtime': 2.8473, 'eval_samples_per_second': 3.512, 'eval_steps_per_second': 1.054, 'epoch': 1.0, 'step': 13}, {'loss': 0.8704, 'grad_norm': 11.185465812683105, 'learning_rate': 2.0384615384615387e-05, 'epoch': 2.0, 'step': 26}, {'eval_loss': 3.0374596118927, 'eval_rouge/rouge1': 0.3233, 'eval_rouge/rouge2': 0.1273, 'eval_rouge/rougeL': 0.2836, 'eval_rouge/rougeLsum': 0.2837, 'eval_bertscore/bertscore-precision': 0.9053, 'eval_bertscore/bertscore-recall': 0.8624, 'eval_bertscore/bertscore-f1': 0.8832, 'eval_meteor': 0.2278, 'eval_gen_len': 22.4, 'eval_runtime': 2.8796, 'eval_samples_per_second': 3.473, 'eval_steps_per_second': 1.042, 'epoch': 2.0, 'step': 26}]\n5 [{'loss': 1.1546, 'grad_norm': 11.703929901123047, 'learning_rate': 2.5384615384615386e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 2.9583256244659424, 'eval_rouge/rouge1': 0.384, 'eval_rouge/rouge2': 0.1702, 'eval_rouge/rougeL': 0.3329, 'eval_rouge/rougeLsum': 0.334, 'eval_bertscore/bertscore-precision': 0.9156, 'eval_bertscore/bertscore-recall': 0.8726, 'eval_bertscore/bertscore-f1': 0.8935, 'eval_meteor': 0.2711, 'eval_gen_len': 23.0, 'eval_runtime': 2.8473, 'eval_samples_per_second': 3.512, 'eval_steps_per_second': 1.054, 'epoch': 1.0, 'step': 13}, {'loss': 0.8704, 'grad_norm': 11.185465812683105, 'learning_rate': 2.0384615384615387e-05, 'epoch': 2.0, 'step': 26}, {'eval_loss': 3.0374596118927, 'eval_rouge/rouge1': 0.3233, 'eval_rouge/rouge2': 0.1273, 'eval_rouge/rougeL': 0.2836, 'eval_rouge/rougeLsum': 0.2837, 'eval_bertscore/bertscore-precision': 0.9053, 'eval_bertscore/bertscore-recall': 0.8624, 'eval_bertscore/bertscore-f1': 0.8832, 'eval_meteor': 0.2278, 'eval_gen_len': 22.4, 'eval_runtime': 2.8796, 'eval_samples_per_second': 3.473, 'eval_steps_per_second': 1.042, 'epoch': 2.0, 'step': 26}, {'loss': 0.5304, 'grad_norm': 9.207221984863281, 'learning_rate': 1.5384615384615384e-05, 'epoch': 3.0, 'step': 39}]\n6 [{'loss': 1.1546, 'grad_norm': 11.703929901123047, 'learning_rate': 2.5384615384615386e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 2.9583256244659424, 'eval_rouge/rouge1': 0.384, 'eval_rouge/rouge2': 0.1702, 'eval_rouge/rougeL': 0.3329, 'eval_rouge/rougeLsum': 0.334, 'eval_bertscore/bertscore-precision': 0.9156, 'eval_bertscore/bertscore-recall': 0.8726, 'eval_bertscore/bertscore-f1': 0.8935, 'eval_meteor': 0.2711, 'eval_gen_len': 23.0, 'eval_runtime': 2.8473, 'eval_samples_per_second': 3.512, 'eval_steps_per_second': 1.054, 'epoch': 1.0, 'step': 13}, {'loss': 0.8704, 'grad_norm': 11.185465812683105, 'learning_rate': 2.0384615384615387e-05, 'epoch': 2.0, 'step': 26}, {'eval_loss': 3.0374596118927, 'eval_rouge/rouge1': 0.3233, 'eval_rouge/rouge2': 0.1273, 'eval_rouge/rougeL': 0.2836, 'eval_rouge/rougeLsum': 0.2837, 'eval_bertscore/bertscore-precision': 0.9053, 'eval_bertscore/bertscore-recall': 0.8624, 'eval_bertscore/bertscore-f1': 0.8832, 'eval_meteor': 0.2278, 'eval_gen_len': 22.4, 'eval_runtime': 2.8796, 'eval_samples_per_second': 3.473, 'eval_steps_per_second': 1.042, 'epoch': 2.0, 'step': 26}, {'loss': 0.5304, 'grad_norm': 9.207221984863281, 'learning_rate': 1.5384615384615384e-05, 'epoch': 3.0, 'step': 39}, {'eval_loss': 3.362632989883423, 'eval_rouge/rouge1': 0.3829, 'eval_rouge/rouge2': 0.1568, 'eval_rouge/rougeL': 0.3165, 'eval_rouge/rougeLsum': 0.3145, 'eval_bertscore/bertscore-precision': 0.8994, 'eval_bertscore/bertscore-recall': 0.868, 'eval_bertscore/bertscore-f1': 0.8833, 'eval_meteor': 0.2914, 'eval_gen_len': 26.9, 'eval_runtime': 3.3279, 'eval_samples_per_second': 3.005, 'eval_steps_per_second': 0.901, 'epoch': 3.0, 'step': 39}]\n7 [{'loss': 1.1546, 'grad_norm': 11.703929901123047, 'learning_rate': 2.5384615384615386e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 2.9583256244659424, 'eval_rouge/rouge1': 0.384, 'eval_rouge/rouge2': 0.1702, 'eval_rouge/rougeL': 0.3329, 'eval_rouge/rougeLsum': 0.334, 'eval_bertscore/bertscore-precision': 0.9156, 'eval_bertscore/bertscore-recall': 0.8726, 'eval_bertscore/bertscore-f1': 0.8935, 'eval_meteor': 0.2711, 'eval_gen_len': 23.0, 'eval_runtime': 2.8473, 'eval_samples_per_second': 3.512, 'eval_steps_per_second': 1.054, 'epoch': 1.0, 'step': 13}, {'loss': 0.8704, 'grad_norm': 11.185465812683105, 'learning_rate': 2.0384615384615387e-05, 'epoch': 2.0, 'step': 26}, {'eval_loss': 3.0374596118927, 'eval_rouge/rouge1': 0.3233, 'eval_rouge/rouge2': 0.1273, 'eval_rouge/rougeL': 0.2836, 'eval_rouge/rougeLsum': 0.2837, 'eval_bertscore/bertscore-precision': 0.9053, 'eval_bertscore/bertscore-recall': 0.8624, 'eval_bertscore/bertscore-f1': 0.8832, 'eval_meteor': 0.2278, 'eval_gen_len': 22.4, 'eval_runtime': 2.8796, 'eval_samples_per_second': 3.473, 'eval_steps_per_second': 1.042, 'epoch': 2.0, 'step': 26}, {'loss': 0.5304, 'grad_norm': 9.207221984863281, 'learning_rate': 1.5384615384615384e-05, 'epoch': 3.0, 'step': 39}, {'eval_loss': 3.362632989883423, 'eval_rouge/rouge1': 0.3829, 'eval_rouge/rouge2': 0.1568, 'eval_rouge/rougeL': 0.3165, 'eval_rouge/rougeLsum': 0.3145, 'eval_bertscore/bertscore-precision': 0.8994, 'eval_bertscore/bertscore-recall': 0.868, 'eval_bertscore/bertscore-f1': 0.8833, 'eval_meteor': 0.2914, 'eval_gen_len': 26.9, 'eval_runtime': 3.3279, 'eval_samples_per_second': 3.005, 'eval_steps_per_second': 0.901, 'epoch': 3.0, 'step': 39}, {'loss': 0.3636, 'grad_norm': 8.272068977355957, 'learning_rate': 1.0384615384615384e-05, 'epoch': 4.0, 'step': 52}]\n8 [{'loss': 1.1546, 'grad_norm': 11.703929901123047, 'learning_rate': 2.5384615384615386e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 2.9583256244659424, 'eval_rouge/rouge1': 0.384, 'eval_rouge/rouge2': 0.1702, 'eval_rouge/rougeL': 0.3329, 'eval_rouge/rougeLsum': 0.334, 'eval_bertscore/bertscore-precision': 0.9156, 'eval_bertscore/bertscore-recall': 0.8726, 'eval_bertscore/bertscore-f1': 0.8935, 'eval_meteor': 0.2711, 'eval_gen_len': 23.0, 'eval_runtime': 2.8473, 'eval_samples_per_second': 3.512, 'eval_steps_per_second': 1.054, 'epoch': 1.0, 'step': 13}, {'loss': 0.8704, 'grad_norm': 11.185465812683105, 'learning_rate': 2.0384615384615387e-05, 'epoch': 2.0, 'step': 26}, {'eval_loss': 3.0374596118927, 'eval_rouge/rouge1': 0.3233, 'eval_rouge/rouge2': 0.1273, 'eval_rouge/rougeL': 0.2836, 'eval_rouge/rougeLsum': 0.2837, 'eval_bertscore/bertscore-precision': 0.9053, 'eval_bertscore/bertscore-recall': 0.8624, 'eval_bertscore/bertscore-f1': 0.8832, 'eval_meteor': 0.2278, 'eval_gen_len': 22.4, 'eval_runtime': 2.8796, 'eval_samples_per_second': 3.473, 'eval_steps_per_second': 1.042, 'epoch': 2.0, 'step': 26}, {'loss': 0.5304, 'grad_norm': 9.207221984863281, 'learning_rate': 1.5384615384615384e-05, 'epoch': 3.0, 'step': 39}, {'eval_loss': 3.362632989883423, 'eval_rouge/rouge1': 0.3829, 'eval_rouge/rouge2': 0.1568, 'eval_rouge/rougeL': 0.3165, 'eval_rouge/rougeLsum': 0.3145, 'eval_bertscore/bertscore-precision': 0.8994, 'eval_bertscore/bertscore-recall': 0.868, 'eval_bertscore/bertscore-f1': 0.8833, 'eval_meteor': 0.2914, 'eval_gen_len': 26.9, 'eval_runtime': 3.3279, 'eval_samples_per_second': 3.005, 'eval_steps_per_second': 0.901, 'epoch': 3.0, 'step': 39}, {'loss': 0.3636, 'grad_norm': 8.272068977355957, 'learning_rate': 1.0384615384615384e-05, 'epoch': 4.0, 'step': 52}, {'eval_loss': 3.577488899230957, 'eval_rouge/rouge1': 0.3532, 'eval_rouge/rouge2': 0.1277, 'eval_rouge/rougeL': 0.2739, 'eval_rouge/rougeLsum': 0.2753, 'eval_bertscore/bertscore-precision': 0.9005, 'eval_bertscore/bertscore-recall': 0.867, 'eval_bertscore/bertscore-f1': 0.8833, 'eval_meteor': 0.2665, 'eval_gen_len': 26.4, 'eval_runtime': 3.0641, 'eval_samples_per_second': 3.264, 'eval_steps_per_second': 0.979, 'epoch': 4.0, 'step': 52}]\n9 [{'loss': 1.1546, 'grad_norm': 11.703929901123047, 'learning_rate': 2.5384615384615386e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 2.9583256244659424, 'eval_rouge/rouge1': 0.384, 'eval_rouge/rouge2': 0.1702, 'eval_rouge/rougeL': 0.3329, 'eval_rouge/rougeLsum': 0.334, 'eval_bertscore/bertscore-precision': 0.9156, 'eval_bertscore/bertscore-recall': 0.8726, 'eval_bertscore/bertscore-f1': 0.8935, 'eval_meteor': 0.2711, 'eval_gen_len': 23.0, 'eval_runtime': 2.8473, 'eval_samples_per_second': 3.512, 'eval_steps_per_second': 1.054, 'epoch': 1.0, 'step': 13}, {'loss': 0.8704, 'grad_norm': 11.185465812683105, 'learning_rate': 2.0384615384615387e-05, 'epoch': 2.0, 'step': 26}, {'eval_loss': 3.0374596118927, 'eval_rouge/rouge1': 0.3233, 'eval_rouge/rouge2': 0.1273, 'eval_rouge/rougeL': 0.2836, 'eval_rouge/rougeLsum': 0.2837, 'eval_bertscore/bertscore-precision': 0.9053, 'eval_bertscore/bertscore-recall': 0.8624, 'eval_bertscore/bertscore-f1': 0.8832, 'eval_meteor': 0.2278, 'eval_gen_len': 22.4, 'eval_runtime': 2.8796, 'eval_samples_per_second': 3.473, 'eval_steps_per_second': 1.042, 'epoch': 2.0, 'step': 26}, {'loss': 0.5304, 'grad_norm': 9.207221984863281, 'learning_rate': 1.5384615384615384e-05, 'epoch': 3.0, 'step': 39}, {'eval_loss': 3.362632989883423, 'eval_rouge/rouge1': 0.3829, 'eval_rouge/rouge2': 0.1568, 'eval_rouge/rougeL': 0.3165, 'eval_rouge/rougeLsum': 0.3145, 'eval_bertscore/bertscore-precision': 0.8994, 'eval_bertscore/bertscore-recall': 0.868, 'eval_bertscore/bertscore-f1': 0.8833, 'eval_meteor': 0.2914, 'eval_gen_len': 26.9, 'eval_runtime': 3.3279, 'eval_samples_per_second': 3.005, 'eval_steps_per_second': 0.901, 'epoch': 3.0, 'step': 39}, {'loss': 0.3636, 'grad_norm': 8.272068977355957, 'learning_rate': 1.0384615384615384e-05, 'epoch': 4.0, 'step': 52}, {'eval_loss': 3.577488899230957, 'eval_rouge/rouge1': 0.3532, 'eval_rouge/rouge2': 0.1277, 'eval_rouge/rougeL': 0.2739, 'eval_rouge/rougeLsum': 0.2753, 'eval_bertscore/bertscore-precision': 0.9005, 'eval_bertscore/bertscore-recall': 0.867, 'eval_bertscore/bertscore-f1': 0.8833, 'eval_meteor': 0.2665, 'eval_gen_len': 26.4, 'eval_runtime': 3.0641, 'eval_samples_per_second': 3.264, 'eval_steps_per_second': 0.979, 'epoch': 4.0, 'step': 52}, {'loss': 0.2621, 'grad_norm': 7.024145126342773, 'learning_rate': 5.384615384615385e-06, 'epoch': 5.0, 'step': 65}]\n10 [{'loss': 1.1546, 'grad_norm': 11.703929901123047, 'learning_rate': 2.5384615384615386e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 2.9583256244659424, 'eval_rouge/rouge1': 0.384, 'eval_rouge/rouge2': 0.1702, 'eval_rouge/rougeL': 0.3329, 'eval_rouge/rougeLsum': 0.334, 'eval_bertscore/bertscore-precision': 0.9156, 'eval_bertscore/bertscore-recall': 0.8726, 'eval_bertscore/bertscore-f1': 0.8935, 'eval_meteor': 0.2711, 'eval_gen_len': 23.0, 'eval_runtime': 2.8473, 'eval_samples_per_second': 3.512, 'eval_steps_per_second': 1.054, 'epoch': 1.0, 'step': 13}, {'loss': 0.8704, 'grad_norm': 11.185465812683105, 'learning_rate': 2.0384615384615387e-05, 'epoch': 2.0, 'step': 26}, {'eval_loss': 3.0374596118927, 'eval_rouge/rouge1': 0.3233, 'eval_rouge/rouge2': 0.1273, 'eval_rouge/rougeL': 0.2836, 'eval_rouge/rougeLsum': 0.2837, 'eval_bertscore/bertscore-precision': 0.9053, 'eval_bertscore/bertscore-recall': 0.8624, 'eval_bertscore/bertscore-f1': 0.8832, 'eval_meteor': 0.2278, 'eval_gen_len': 22.4, 'eval_runtime': 2.8796, 'eval_samples_per_second': 3.473, 'eval_steps_per_second': 1.042, 'epoch': 2.0, 'step': 26}, {'loss': 0.5304, 'grad_norm': 9.207221984863281, 'learning_rate': 1.5384615384615384e-05, 'epoch': 3.0, 'step': 39}, {'eval_loss': 3.362632989883423, 'eval_rouge/rouge1': 0.3829, 'eval_rouge/rouge2': 0.1568, 'eval_rouge/rougeL': 0.3165, 'eval_rouge/rougeLsum': 0.3145, 'eval_bertscore/bertscore-precision': 0.8994, 'eval_bertscore/bertscore-recall': 0.868, 'eval_bertscore/bertscore-f1': 0.8833, 'eval_meteor': 0.2914, 'eval_gen_len': 26.9, 'eval_runtime': 3.3279, 'eval_samples_per_second': 3.005, 'eval_steps_per_second': 0.901, 'epoch': 3.0, 'step': 39}, {'loss': 0.3636, 'grad_norm': 8.272068977355957, 'learning_rate': 1.0384615384615384e-05, 'epoch': 4.0, 'step': 52}, {'eval_loss': 3.577488899230957, 'eval_rouge/rouge1': 0.3532, 'eval_rouge/rouge2': 0.1277, 'eval_rouge/rougeL': 0.2739, 'eval_rouge/rougeLsum': 0.2753, 'eval_bertscore/bertscore-precision': 0.9005, 'eval_bertscore/bertscore-recall': 0.867, 'eval_bertscore/bertscore-f1': 0.8833, 'eval_meteor': 0.2665, 'eval_gen_len': 26.4, 'eval_runtime': 3.0641, 'eval_samples_per_second': 3.264, 'eval_steps_per_second': 0.979, 'epoch': 4.0, 'step': 52}, {'loss': 0.2621, 'grad_norm': 7.024145126342773, 'learning_rate': 5.384615384615385e-06, 'epoch': 5.0, 'step': 65}, {'eval_loss': 3.700132131576538, 'eval_rouge/rouge1': 0.3793, 'eval_rouge/rouge2': 0.1271, 'eval_rouge/rougeL': 0.3132, 'eval_rouge/rougeLsum': 0.3123, 'eval_bertscore/bertscore-precision': 0.9058, 'eval_bertscore/bertscore-recall': 0.8712, 'eval_bertscore/bertscore-f1': 0.888, 'eval_meteor': 0.2809, 'eval_gen_len': 26.2, 'eval_runtime': 2.93, 'eval_samples_per_second': 3.413, 'eval_steps_per_second': 1.024, 'epoch': 5.0, 'step': 65}]\n11 [{'loss': 1.1546, 'grad_norm': 11.703929901123047, 'learning_rate': 2.5384615384615386e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 2.9583256244659424, 'eval_rouge/rouge1': 0.384, 'eval_rouge/rouge2': 0.1702, 'eval_rouge/rougeL': 0.3329, 'eval_rouge/rougeLsum': 0.334, 'eval_bertscore/bertscore-precision': 0.9156, 'eval_bertscore/bertscore-recall': 0.8726, 'eval_bertscore/bertscore-f1': 0.8935, 'eval_meteor': 0.2711, 'eval_gen_len': 23.0, 'eval_runtime': 2.8473, 'eval_samples_per_second': 3.512, 'eval_steps_per_second': 1.054, 'epoch': 1.0, 'step': 13}, {'loss': 0.8704, 'grad_norm': 11.185465812683105, 'learning_rate': 2.0384615384615387e-05, 'epoch': 2.0, 'step': 26}, {'eval_loss': 3.0374596118927, 'eval_rouge/rouge1': 0.3233, 'eval_rouge/rouge2': 0.1273, 'eval_rouge/rougeL': 0.2836, 'eval_rouge/rougeLsum': 0.2837, 'eval_bertscore/bertscore-precision': 0.9053, 'eval_bertscore/bertscore-recall': 0.8624, 'eval_bertscore/bertscore-f1': 0.8832, 'eval_meteor': 0.2278, 'eval_gen_len': 22.4, 'eval_runtime': 2.8796, 'eval_samples_per_second': 3.473, 'eval_steps_per_second': 1.042, 'epoch': 2.0, 'step': 26}, {'loss': 0.5304, 'grad_norm': 9.207221984863281, 'learning_rate': 1.5384615384615384e-05, 'epoch': 3.0, 'step': 39}, {'eval_loss': 3.362632989883423, 'eval_rouge/rouge1': 0.3829, 'eval_rouge/rouge2': 0.1568, 'eval_rouge/rougeL': 0.3165, 'eval_rouge/rougeLsum': 0.3145, 'eval_bertscore/bertscore-precision': 0.8994, 'eval_bertscore/bertscore-recall': 0.868, 'eval_bertscore/bertscore-f1': 0.8833, 'eval_meteor': 0.2914, 'eval_gen_len': 26.9, 'eval_runtime': 3.3279, 'eval_samples_per_second': 3.005, 'eval_steps_per_second': 0.901, 'epoch': 3.0, 'step': 39}, {'loss': 0.3636, 'grad_norm': 8.272068977355957, 'learning_rate': 1.0384615384615384e-05, 'epoch': 4.0, 'step': 52}, {'eval_loss': 3.577488899230957, 'eval_rouge/rouge1': 0.3532, 'eval_rouge/rouge2': 0.1277, 'eval_rouge/rougeL': 0.2739, 'eval_rouge/rougeLsum': 0.2753, 'eval_bertscore/bertscore-precision': 0.9005, 'eval_bertscore/bertscore-recall': 0.867, 'eval_bertscore/bertscore-f1': 0.8833, 'eval_meteor': 0.2665, 'eval_gen_len': 26.4, 'eval_runtime': 3.0641, 'eval_samples_per_second': 3.264, 'eval_steps_per_second': 0.979, 'epoch': 4.0, 'step': 52}, {'loss': 0.2621, 'grad_norm': 7.024145126342773, 'learning_rate': 5.384615384615385e-06, 'epoch': 5.0, 'step': 65}, {'eval_loss': 3.700132131576538, 'eval_rouge/rouge1': 0.3793, 'eval_rouge/rouge2': 0.1271, 'eval_rouge/rougeL': 0.3132, 'eval_rouge/rougeLsum': 0.3123, 'eval_bertscore/bertscore-precision': 0.9058, 'eval_bertscore/bertscore-recall': 0.8712, 'eval_bertscore/bertscore-f1': 0.888, 'eval_meteor': 0.2809, 'eval_gen_len': 26.2, 'eval_runtime': 2.93, 'eval_samples_per_second': 3.413, 'eval_steps_per_second': 1.024, 'epoch': 5.0, 'step': 65}, {'loss': 0.2267, 'grad_norm': 7.981739521026611, 'learning_rate': 3.8461538461538463e-07, 'epoch': 6.0, 'step': 78}]\n12 [{'loss': 1.1546, 'grad_norm': 11.703929901123047, 'learning_rate': 2.5384615384615386e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 2.9583256244659424, 'eval_rouge/rouge1': 0.384, 'eval_rouge/rouge2': 0.1702, 'eval_rouge/rougeL': 0.3329, 'eval_rouge/rougeLsum': 0.334, 'eval_bertscore/bertscore-precision': 0.9156, 'eval_bertscore/bertscore-recall': 0.8726, 'eval_bertscore/bertscore-f1': 0.8935, 'eval_meteor': 0.2711, 'eval_gen_len': 23.0, 'eval_runtime': 2.8473, 'eval_samples_per_second': 3.512, 'eval_steps_per_second': 1.054, 'epoch': 1.0, 'step': 13}, {'loss': 0.8704, 'grad_norm': 11.185465812683105, 'learning_rate': 2.0384615384615387e-05, 'epoch': 2.0, 'step': 26}, {'eval_loss': 3.0374596118927, 'eval_rouge/rouge1': 0.3233, 'eval_rouge/rouge2': 0.1273, 'eval_rouge/rougeL': 0.2836, 'eval_rouge/rougeLsum': 0.2837, 'eval_bertscore/bertscore-precision': 0.9053, 'eval_bertscore/bertscore-recall': 0.8624, 'eval_bertscore/bertscore-f1': 0.8832, 'eval_meteor': 0.2278, 'eval_gen_len': 22.4, 'eval_runtime': 2.8796, 'eval_samples_per_second': 3.473, 'eval_steps_per_second': 1.042, 'epoch': 2.0, 'step': 26}, {'loss': 0.5304, 'grad_norm': 9.207221984863281, 'learning_rate': 1.5384615384615384e-05, 'epoch': 3.0, 'step': 39}, {'eval_loss': 3.362632989883423, 'eval_rouge/rouge1': 0.3829, 'eval_rouge/rouge2': 0.1568, 'eval_rouge/rougeL': 0.3165, 'eval_rouge/rougeLsum': 0.3145, 'eval_bertscore/bertscore-precision': 0.8994, 'eval_bertscore/bertscore-recall': 0.868, 'eval_bertscore/bertscore-f1': 0.8833, 'eval_meteor': 0.2914, 'eval_gen_len': 26.9, 'eval_runtime': 3.3279, 'eval_samples_per_second': 3.005, 'eval_steps_per_second': 0.901, 'epoch': 3.0, 'step': 39}, {'loss': 0.3636, 'grad_norm': 8.272068977355957, 'learning_rate': 1.0384615384615384e-05, 'epoch': 4.0, 'step': 52}, {'eval_loss': 3.577488899230957, 'eval_rouge/rouge1': 0.3532, 'eval_rouge/rouge2': 0.1277, 'eval_rouge/rougeL': 0.2739, 'eval_rouge/rougeLsum': 0.2753, 'eval_bertscore/bertscore-precision': 0.9005, 'eval_bertscore/bertscore-recall': 0.867, 'eval_bertscore/bertscore-f1': 0.8833, 'eval_meteor': 0.2665, 'eval_gen_len': 26.4, 'eval_runtime': 3.0641, 'eval_samples_per_second': 3.264, 'eval_steps_per_second': 0.979, 'epoch': 4.0, 'step': 52}, {'loss': 0.2621, 'grad_norm': 7.024145126342773, 'learning_rate': 5.384615384615385e-06, 'epoch': 5.0, 'step': 65}, {'eval_loss': 3.700132131576538, 'eval_rouge/rouge1': 0.3793, 'eval_rouge/rouge2': 0.1271, 'eval_rouge/rougeL': 0.3132, 'eval_rouge/rougeLsum': 0.3123, 'eval_bertscore/bertscore-precision': 0.9058, 'eval_bertscore/bertscore-recall': 0.8712, 'eval_bertscore/bertscore-f1': 0.888, 'eval_meteor': 0.2809, 'eval_gen_len': 26.2, 'eval_runtime': 2.93, 'eval_samples_per_second': 3.413, 'eval_steps_per_second': 1.024, 'epoch': 5.0, 'step': 65}, {'loss': 0.2267, 'grad_norm': 7.981739521026611, 'learning_rate': 3.8461538461538463e-07, 'epoch': 6.0, 'step': 78}, {'eval_loss': 3.81595516204834, 'eval_rouge/rouge1': 0.3675, 'eval_rouge/rouge2': 0.1333, 'eval_rouge/rougeL': 0.3099, 'eval_rouge/rougeLsum': 0.3087, 'eval_bertscore/bertscore-precision': 0.9052, 'eval_bertscore/bertscore-recall': 0.8686, 'eval_bertscore/bertscore-f1': 0.8864, 'eval_meteor': 0.269, 'eval_gen_len': 24.4, 'eval_runtime': 2.8679, 'eval_samples_per_second': 3.487, 'eval_steps_per_second': 1.046, 'epoch': 6.0, 'step': 78}]\n13 [{'loss': 1.1546, 'grad_norm': 11.703929901123047, 'learning_rate': 2.5384615384615386e-05, 'epoch': 1.0, 'step': 13}, {'eval_loss': 2.9583256244659424, 'eval_rouge/rouge1': 0.384, 'eval_rouge/rouge2': 0.1702, 'eval_rouge/rougeL': 0.3329, 'eval_rouge/rougeLsum': 0.334, 'eval_bertscore/bertscore-precision': 0.9156, 'eval_bertscore/bertscore-recall': 0.8726, 'eval_bertscore/bertscore-f1': 0.8935, 'eval_meteor': 0.2711, 'eval_gen_len': 23.0, 'eval_runtime': 2.8473, 'eval_samples_per_second': 3.512, 'eval_steps_per_second': 1.054, 'epoch': 1.0, 'step': 13}, {'loss': 0.8704, 'grad_norm': 11.185465812683105, 'learning_rate': 2.0384615384615387e-05, 'epoch': 2.0, 'step': 26}, {'eval_loss': 3.0374596118927, 'eval_rouge/rouge1': 0.3233, 'eval_rouge/rouge2': 0.1273, 'eval_rouge/rougeL': 0.2836, 'eval_rouge/rougeLsum': 0.2837, 'eval_bertscore/bertscore-precision': 0.9053, 'eval_bertscore/bertscore-recall': 0.8624, 'eval_bertscore/bertscore-f1': 0.8832, 'eval_meteor': 0.2278, 'eval_gen_len': 22.4, 'eval_runtime': 2.8796, 'eval_samples_per_second': 3.473, 'eval_steps_per_second': 1.042, 'epoch': 2.0, 'step': 26}, {'loss': 0.5304, 'grad_norm': 9.207221984863281, 'learning_rate': 1.5384615384615384e-05, 'epoch': 3.0, 'step': 39}, {'eval_loss': 3.362632989883423, 'eval_rouge/rouge1': 0.3829, 'eval_rouge/rouge2': 0.1568, 'eval_rouge/rougeL': 0.3165, 'eval_rouge/rougeLsum': 0.3145, 'eval_bertscore/bertscore-precision': 0.8994, 'eval_bertscore/bertscore-recall': 0.868, 'eval_bertscore/bertscore-f1': 0.8833, 'eval_meteor': 0.2914, 'eval_gen_len': 26.9, 'eval_runtime': 3.3279, 'eval_samples_per_second': 3.005, 'eval_steps_per_second': 0.901, 'epoch': 3.0, 'step': 39}, {'loss': 0.3636, 'grad_norm': 8.272068977355957, 'learning_rate': 1.0384615384615384e-05, 'epoch': 4.0, 'step': 52}, {'eval_loss': 3.577488899230957, 'eval_rouge/rouge1': 0.3532, 'eval_rouge/rouge2': 0.1277, 'eval_rouge/rougeL': 0.2739, 'eval_rouge/rougeLsum': 0.2753, 'eval_bertscore/bertscore-precision': 0.9005, 'eval_bertscore/bertscore-recall': 0.867, 'eval_bertscore/bertscore-f1': 0.8833, 'eval_meteor': 0.2665, 'eval_gen_len': 26.4, 'eval_runtime': 3.0641, 'eval_samples_per_second': 3.264, 'eval_steps_per_second': 0.979, 'epoch': 4.0, 'step': 52}, {'loss': 0.2621, 'grad_norm': 7.024145126342773, 'learning_rate': 5.384615384615385e-06, 'epoch': 5.0, 'step': 65}, {'eval_loss': 3.700132131576538, 'eval_rouge/rouge1': 0.3793, 'eval_rouge/rouge2': 0.1271, 'eval_rouge/rougeL': 0.3132, 'eval_rouge/rougeLsum': 0.3123, 'eval_bertscore/bertscore-precision': 0.9058, 'eval_bertscore/bertscore-recall': 0.8712, 'eval_bertscore/bertscore-f1': 0.888, 'eval_meteor': 0.2809, 'eval_gen_len': 26.2, 'eval_runtime': 2.93, 'eval_samples_per_second': 3.413, 'eval_steps_per_second': 1.024, 'epoch': 5.0, 'step': 65}, {'loss': 0.2267, 'grad_norm': 7.981739521026611, 'learning_rate': 3.8461538461538463e-07, 'epoch': 6.0, 'step': 78}, {'eval_loss': 3.81595516204834, 'eval_rouge/rouge1': 0.3675, 'eval_rouge/rouge2': 0.1333, 'eval_rouge/rougeL': 0.3099, 'eval_rouge/rougeLsum': 0.3087, 'eval_bertscore/bertscore-precision': 0.9052, 'eval_bertscore/bertscore-recall': 0.8686, 'eval_bertscore/bertscore-f1': 0.8864, 'eval_meteor': 0.269, 'eval_gen_len': 24.4, 'eval_runtime': 2.8679, 'eval_samples_per_second': 3.487, 'eval_steps_per_second': 1.046, 'epoch': 6.0, 'step': 78}, {'train_runtime': 51.6987, 'train_samples_per_second': 5.803, 'train_steps_per_second': 1.509, 'total_flos': 201491595239424.0, 'train_loss': 0.5679596662521362, 'epoch': 6.0, 'step': 78}]\nFinished bart-abs-1109-1149-lr-3e-05-bs-4-maxep-10 time it took for training: 0:00:52.345868\nStarting experiment 2 bart-abs-1109-1149-lr-3e-05-bs-2-maxep-6 training\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [150/150 01:00, Epoch 6/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge/rouge1</th>\n      <th>Rouge/rouge2</th>\n      <th>Rouge/rougel</th>\n      <th>Rouge/rougelsum</th>\n      <th>Bertscore/bertscore-precision</th>\n      <th>Bertscore/bertscore-recall</th>\n      <th>Bertscore/bertscore-f1</th>\n      <th>Meteor</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.458900</td>\n      <td>3.833492</td>\n      <td>0.393300</td>\n      <td>0.151300</td>\n      <td>0.324700</td>\n      <td>0.324200</td>\n      <td>0.904500</td>\n      <td>0.869900</td>\n      <td>0.886700</td>\n      <td>0.302900</td>\n      <td>24.700000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.414100</td>\n      <td>3.750737</td>\n      <td>0.375500</td>\n      <td>0.122300</td>\n      <td>0.310900</td>\n      <td>0.310300</td>\n      <td>0.895300</td>\n      <td>0.870100</td>\n      <td>0.882400</td>\n      <td>0.285200</td>\n      <td>30.500000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.289000</td>\n      <td>4.050595</td>\n      <td>0.323200</td>\n      <td>0.095300</td>\n      <td>0.239900</td>\n      <td>0.239400</td>\n      <td>0.889800</td>\n      <td>0.859500</td>\n      <td>0.874300</td>\n      <td>0.233900</td>\n      <td>24.900000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.185900</td>\n      <td>4.168713</td>\n      <td>0.431800</td>\n      <td>0.165200</td>\n      <td>0.355300</td>\n      <td>0.353500</td>\n      <td>0.904900</td>\n      <td>0.871400</td>\n      <td>0.887700</td>\n      <td>0.324600</td>\n      <td>26.100000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.120500</td>\n      <td>4.419093</td>\n      <td>0.410600</td>\n      <td>0.146300</td>\n      <td>0.336300</td>\n      <td>0.336500</td>\n      <td>0.899800</td>\n      <td>0.870900</td>\n      <td>0.885000</td>\n      <td>0.302700</td>\n      <td>27.700000</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.085500</td>\n      <td>4.402860</td>\n      <td>0.333000</td>\n      <td>0.095700</td>\n      <td>0.272500</td>\n      <td>0.272100</td>\n      <td>0.891200</td>\n      <td>0.862400</td>\n      <td>0.876300</td>\n      <td>0.252000</td>\n      <td>27.300000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"1 [{'loss': 0.4589, 'grad_norm': 11.128762245178223, 'learning_rate': 2.54e-05, 'epoch': 1.0, 'step': 25}]\n2 [{'loss': 0.4589, 'grad_norm': 11.128762245178223, 'learning_rate': 2.54e-05, 'epoch': 1.0, 'step': 25}, {'eval_loss': 3.833491802215576, 'eval_rouge/rouge1': 0.3933, 'eval_rouge/rouge2': 0.1513, 'eval_rouge/rougeL': 0.3247, 'eval_rouge/rougeLsum': 0.3242, 'eval_bertscore/bertscore-precision': 0.9045, 'eval_bertscore/bertscore-recall': 0.8699, 'eval_bertscore/bertscore-f1': 0.8867, 'eval_meteor': 0.3029, 'eval_gen_len': 24.7, 'eval_runtime': 3.2105, 'eval_samples_per_second': 3.115, 'eval_steps_per_second': 1.557, 'epoch': 1.0, 'step': 25}]\n3 [{'loss': 0.4589, 'grad_norm': 11.128762245178223, 'learning_rate': 2.54e-05, 'epoch': 1.0, 'step': 25}, {'eval_loss': 3.833491802215576, 'eval_rouge/rouge1': 0.3933, 'eval_rouge/rouge2': 0.1513, 'eval_rouge/rougeL': 0.3247, 'eval_rouge/rougeLsum': 0.3242, 'eval_bertscore/bertscore-precision': 0.9045, 'eval_bertscore/bertscore-recall': 0.8699, 'eval_bertscore/bertscore-f1': 0.8867, 'eval_meteor': 0.3029, 'eval_gen_len': 24.7, 'eval_runtime': 3.2105, 'eval_samples_per_second': 3.115, 'eval_steps_per_second': 1.557, 'epoch': 1.0, 'step': 25}, {'loss': 0.4141, 'grad_norm': 13.652347564697266, 'learning_rate': 2.04e-05, 'epoch': 2.0, 'step': 50}]\n4 [{'loss': 0.4589, 'grad_norm': 11.128762245178223, 'learning_rate': 2.54e-05, 'epoch': 1.0, 'step': 25}, {'eval_loss': 3.833491802215576, 'eval_rouge/rouge1': 0.3933, 'eval_rouge/rouge2': 0.1513, 'eval_rouge/rougeL': 0.3247, 'eval_rouge/rougeLsum': 0.3242, 'eval_bertscore/bertscore-precision': 0.9045, 'eval_bertscore/bertscore-recall': 0.8699, 'eval_bertscore/bertscore-f1': 0.8867, 'eval_meteor': 0.3029, 'eval_gen_len': 24.7, 'eval_runtime': 3.2105, 'eval_samples_per_second': 3.115, 'eval_steps_per_second': 1.557, 'epoch': 1.0, 'step': 25}, {'loss': 0.4141, 'grad_norm': 13.652347564697266, 'learning_rate': 2.04e-05, 'epoch': 2.0, 'step': 50}, {'eval_loss': 3.750737428665161, 'eval_rouge/rouge1': 0.3755, 'eval_rouge/rouge2': 0.1223, 'eval_rouge/rougeL': 0.3109, 'eval_rouge/rougeLsum': 0.3103, 'eval_bertscore/bertscore-precision': 0.8953, 'eval_bertscore/bertscore-recall': 0.8701, 'eval_bertscore/bertscore-f1': 0.8824, 'eval_meteor': 0.2852, 'eval_gen_len': 30.5, 'eval_runtime': 3.917, 'eval_samples_per_second': 2.553, 'eval_steps_per_second': 1.276, 'epoch': 2.0, 'step': 50}]\n5 [{'loss': 0.4589, 'grad_norm': 11.128762245178223, 'learning_rate': 2.54e-05, 'epoch': 1.0, 'step': 25}, {'eval_loss': 3.833491802215576, 'eval_rouge/rouge1': 0.3933, 'eval_rouge/rouge2': 0.1513, 'eval_rouge/rougeL': 0.3247, 'eval_rouge/rougeLsum': 0.3242, 'eval_bertscore/bertscore-precision': 0.9045, 'eval_bertscore/bertscore-recall': 0.8699, 'eval_bertscore/bertscore-f1': 0.8867, 'eval_meteor': 0.3029, 'eval_gen_len': 24.7, 'eval_runtime': 3.2105, 'eval_samples_per_second': 3.115, 'eval_steps_per_second': 1.557, 'epoch': 1.0, 'step': 25}, {'loss': 0.4141, 'grad_norm': 13.652347564697266, 'learning_rate': 2.04e-05, 'epoch': 2.0, 'step': 50}, {'eval_loss': 3.750737428665161, 'eval_rouge/rouge1': 0.3755, 'eval_rouge/rouge2': 0.1223, 'eval_rouge/rougeL': 0.3109, 'eval_rouge/rougeLsum': 0.3103, 'eval_bertscore/bertscore-precision': 0.8953, 'eval_bertscore/bertscore-recall': 0.8701, 'eval_bertscore/bertscore-f1': 0.8824, 'eval_meteor': 0.2852, 'eval_gen_len': 30.5, 'eval_runtime': 3.917, 'eval_samples_per_second': 2.553, 'eval_steps_per_second': 1.276, 'epoch': 2.0, 'step': 50}, {'loss': 0.289, 'grad_norm': 12.835441589355469, 'learning_rate': 1.5399999999999998e-05, 'epoch': 3.0, 'step': 75}]\n6 [{'loss': 0.4589, 'grad_norm': 11.128762245178223, 'learning_rate': 2.54e-05, 'epoch': 1.0, 'step': 25}, {'eval_loss': 3.833491802215576, 'eval_rouge/rouge1': 0.3933, 'eval_rouge/rouge2': 0.1513, 'eval_rouge/rougeL': 0.3247, 'eval_rouge/rougeLsum': 0.3242, 'eval_bertscore/bertscore-precision': 0.9045, 'eval_bertscore/bertscore-recall': 0.8699, 'eval_bertscore/bertscore-f1': 0.8867, 'eval_meteor': 0.3029, 'eval_gen_len': 24.7, 'eval_runtime': 3.2105, 'eval_samples_per_second': 3.115, 'eval_steps_per_second': 1.557, 'epoch': 1.0, 'step': 25}, {'loss': 0.4141, 'grad_norm': 13.652347564697266, 'learning_rate': 2.04e-05, 'epoch': 2.0, 'step': 50}, {'eval_loss': 3.750737428665161, 'eval_rouge/rouge1': 0.3755, 'eval_rouge/rouge2': 0.1223, 'eval_rouge/rougeL': 0.3109, 'eval_rouge/rougeLsum': 0.3103, 'eval_bertscore/bertscore-precision': 0.8953, 'eval_bertscore/bertscore-recall': 0.8701, 'eval_bertscore/bertscore-f1': 0.8824, 'eval_meteor': 0.2852, 'eval_gen_len': 30.5, 'eval_runtime': 3.917, 'eval_samples_per_second': 2.553, 'eval_steps_per_second': 1.276, 'epoch': 2.0, 'step': 50}, {'loss': 0.289, 'grad_norm': 12.835441589355469, 'learning_rate': 1.5399999999999998e-05, 'epoch': 3.0, 'step': 75}, {'eval_loss': 4.050595283508301, 'eval_rouge/rouge1': 0.3232, 'eval_rouge/rouge2': 0.0953, 'eval_rouge/rougeL': 0.2399, 'eval_rouge/rougeLsum': 0.2394, 'eval_bertscore/bertscore-precision': 0.8898, 'eval_bertscore/bertscore-recall': 0.8595, 'eval_bertscore/bertscore-f1': 0.8743, 'eval_meteor': 0.2339, 'eval_gen_len': 24.9, 'eval_runtime': 3.743, 'eval_samples_per_second': 2.672, 'eval_steps_per_second': 1.336, 'epoch': 3.0, 'step': 75}]\n7 [{'loss': 0.4589, 'grad_norm': 11.128762245178223, 'learning_rate': 2.54e-05, 'epoch': 1.0, 'step': 25}, {'eval_loss': 3.833491802215576, 'eval_rouge/rouge1': 0.3933, 'eval_rouge/rouge2': 0.1513, 'eval_rouge/rougeL': 0.3247, 'eval_rouge/rougeLsum': 0.3242, 'eval_bertscore/bertscore-precision': 0.9045, 'eval_bertscore/bertscore-recall': 0.8699, 'eval_bertscore/bertscore-f1': 0.8867, 'eval_meteor': 0.3029, 'eval_gen_len': 24.7, 'eval_runtime': 3.2105, 'eval_samples_per_second': 3.115, 'eval_steps_per_second': 1.557, 'epoch': 1.0, 'step': 25}, {'loss': 0.4141, 'grad_norm': 13.652347564697266, 'learning_rate': 2.04e-05, 'epoch': 2.0, 'step': 50}, {'eval_loss': 3.750737428665161, 'eval_rouge/rouge1': 0.3755, 'eval_rouge/rouge2': 0.1223, 'eval_rouge/rougeL': 0.3109, 'eval_rouge/rougeLsum': 0.3103, 'eval_bertscore/bertscore-precision': 0.8953, 'eval_bertscore/bertscore-recall': 0.8701, 'eval_bertscore/bertscore-f1': 0.8824, 'eval_meteor': 0.2852, 'eval_gen_len': 30.5, 'eval_runtime': 3.917, 'eval_samples_per_second': 2.553, 'eval_steps_per_second': 1.276, 'epoch': 2.0, 'step': 50}, {'loss': 0.289, 'grad_norm': 12.835441589355469, 'learning_rate': 1.5399999999999998e-05, 'epoch': 3.0, 'step': 75}, {'eval_loss': 4.050595283508301, 'eval_rouge/rouge1': 0.3232, 'eval_rouge/rouge2': 0.0953, 'eval_rouge/rougeL': 0.2399, 'eval_rouge/rougeLsum': 0.2394, 'eval_bertscore/bertscore-precision': 0.8898, 'eval_bertscore/bertscore-recall': 0.8595, 'eval_bertscore/bertscore-f1': 0.8743, 'eval_meteor': 0.2339, 'eval_gen_len': 24.9, 'eval_runtime': 3.743, 'eval_samples_per_second': 2.672, 'eval_steps_per_second': 1.336, 'epoch': 3.0, 'step': 75}, {'loss': 0.1859, 'grad_norm': 5.502574443817139, 'learning_rate': 1.04e-05, 'epoch': 4.0, 'step': 100}]\n8 [{'loss': 0.4589, 'grad_norm': 11.128762245178223, 'learning_rate': 2.54e-05, 'epoch': 1.0, 'step': 25}, {'eval_loss': 3.833491802215576, 'eval_rouge/rouge1': 0.3933, 'eval_rouge/rouge2': 0.1513, 'eval_rouge/rougeL': 0.3247, 'eval_rouge/rougeLsum': 0.3242, 'eval_bertscore/bertscore-precision': 0.9045, 'eval_bertscore/bertscore-recall': 0.8699, 'eval_bertscore/bertscore-f1': 0.8867, 'eval_meteor': 0.3029, 'eval_gen_len': 24.7, 'eval_runtime': 3.2105, 'eval_samples_per_second': 3.115, 'eval_steps_per_second': 1.557, 'epoch': 1.0, 'step': 25}, {'loss': 0.4141, 'grad_norm': 13.652347564697266, 'learning_rate': 2.04e-05, 'epoch': 2.0, 'step': 50}, {'eval_loss': 3.750737428665161, 'eval_rouge/rouge1': 0.3755, 'eval_rouge/rouge2': 0.1223, 'eval_rouge/rougeL': 0.3109, 'eval_rouge/rougeLsum': 0.3103, 'eval_bertscore/bertscore-precision': 0.8953, 'eval_bertscore/bertscore-recall': 0.8701, 'eval_bertscore/bertscore-f1': 0.8824, 'eval_meteor': 0.2852, 'eval_gen_len': 30.5, 'eval_runtime': 3.917, 'eval_samples_per_second': 2.553, 'eval_steps_per_second': 1.276, 'epoch': 2.0, 'step': 50}, {'loss': 0.289, 'grad_norm': 12.835441589355469, 'learning_rate': 1.5399999999999998e-05, 'epoch': 3.0, 'step': 75}, {'eval_loss': 4.050595283508301, 'eval_rouge/rouge1': 0.3232, 'eval_rouge/rouge2': 0.0953, 'eval_rouge/rougeL': 0.2399, 'eval_rouge/rougeLsum': 0.2394, 'eval_bertscore/bertscore-precision': 0.8898, 'eval_bertscore/bertscore-recall': 0.8595, 'eval_bertscore/bertscore-f1': 0.8743, 'eval_meteor': 0.2339, 'eval_gen_len': 24.9, 'eval_runtime': 3.743, 'eval_samples_per_second': 2.672, 'eval_steps_per_second': 1.336, 'epoch': 3.0, 'step': 75}, {'loss': 0.1859, 'grad_norm': 5.502574443817139, 'learning_rate': 1.04e-05, 'epoch': 4.0, 'step': 100}, {'eval_loss': 4.168712615966797, 'eval_rouge/rouge1': 0.4318, 'eval_rouge/rouge2': 0.1652, 'eval_rouge/rougeL': 0.3553, 'eval_rouge/rougeLsum': 0.3535, 'eval_bertscore/bertscore-precision': 0.9049, 'eval_bertscore/bertscore-recall': 0.8714, 'eval_bertscore/bertscore-f1': 0.8877, 'eval_meteor': 0.3246, 'eval_gen_len': 26.1, 'eval_runtime': 3.3791, 'eval_samples_per_second': 2.959, 'eval_steps_per_second': 1.48, 'epoch': 4.0, 'step': 100}]\n9 [{'loss': 0.4589, 'grad_norm': 11.128762245178223, 'learning_rate': 2.54e-05, 'epoch': 1.0, 'step': 25}, {'eval_loss': 3.833491802215576, 'eval_rouge/rouge1': 0.3933, 'eval_rouge/rouge2': 0.1513, 'eval_rouge/rougeL': 0.3247, 'eval_rouge/rougeLsum': 0.3242, 'eval_bertscore/bertscore-precision': 0.9045, 'eval_bertscore/bertscore-recall': 0.8699, 'eval_bertscore/bertscore-f1': 0.8867, 'eval_meteor': 0.3029, 'eval_gen_len': 24.7, 'eval_runtime': 3.2105, 'eval_samples_per_second': 3.115, 'eval_steps_per_second': 1.557, 'epoch': 1.0, 'step': 25}, {'loss': 0.4141, 'grad_norm': 13.652347564697266, 'learning_rate': 2.04e-05, 'epoch': 2.0, 'step': 50}, {'eval_loss': 3.750737428665161, 'eval_rouge/rouge1': 0.3755, 'eval_rouge/rouge2': 0.1223, 'eval_rouge/rougeL': 0.3109, 'eval_rouge/rougeLsum': 0.3103, 'eval_bertscore/bertscore-precision': 0.8953, 'eval_bertscore/bertscore-recall': 0.8701, 'eval_bertscore/bertscore-f1': 0.8824, 'eval_meteor': 0.2852, 'eval_gen_len': 30.5, 'eval_runtime': 3.917, 'eval_samples_per_second': 2.553, 'eval_steps_per_second': 1.276, 'epoch': 2.0, 'step': 50}, {'loss': 0.289, 'grad_norm': 12.835441589355469, 'learning_rate': 1.5399999999999998e-05, 'epoch': 3.0, 'step': 75}, {'eval_loss': 4.050595283508301, 'eval_rouge/rouge1': 0.3232, 'eval_rouge/rouge2': 0.0953, 'eval_rouge/rougeL': 0.2399, 'eval_rouge/rougeLsum': 0.2394, 'eval_bertscore/bertscore-precision': 0.8898, 'eval_bertscore/bertscore-recall': 0.8595, 'eval_bertscore/bertscore-f1': 0.8743, 'eval_meteor': 0.2339, 'eval_gen_len': 24.9, 'eval_runtime': 3.743, 'eval_samples_per_second': 2.672, 'eval_steps_per_second': 1.336, 'epoch': 3.0, 'step': 75}, {'loss': 0.1859, 'grad_norm': 5.502574443817139, 'learning_rate': 1.04e-05, 'epoch': 4.0, 'step': 100}, {'eval_loss': 4.168712615966797, 'eval_rouge/rouge1': 0.4318, 'eval_rouge/rouge2': 0.1652, 'eval_rouge/rougeL': 0.3553, 'eval_rouge/rougeLsum': 0.3535, 'eval_bertscore/bertscore-precision': 0.9049, 'eval_bertscore/bertscore-recall': 0.8714, 'eval_bertscore/bertscore-f1': 0.8877, 'eval_meteor': 0.3246, 'eval_gen_len': 26.1, 'eval_runtime': 3.3791, 'eval_samples_per_second': 2.959, 'eval_steps_per_second': 1.48, 'epoch': 4.0, 'step': 100}, {'loss': 0.1205, 'grad_norm': 5.309665203094482, 'learning_rate': 5.4e-06, 'epoch': 5.0, 'step': 125}]\n10 [{'loss': 0.4589, 'grad_norm': 11.128762245178223, 'learning_rate': 2.54e-05, 'epoch': 1.0, 'step': 25}, {'eval_loss': 3.833491802215576, 'eval_rouge/rouge1': 0.3933, 'eval_rouge/rouge2': 0.1513, 'eval_rouge/rougeL': 0.3247, 'eval_rouge/rougeLsum': 0.3242, 'eval_bertscore/bertscore-precision': 0.9045, 'eval_bertscore/bertscore-recall': 0.8699, 'eval_bertscore/bertscore-f1': 0.8867, 'eval_meteor': 0.3029, 'eval_gen_len': 24.7, 'eval_runtime': 3.2105, 'eval_samples_per_second': 3.115, 'eval_steps_per_second': 1.557, 'epoch': 1.0, 'step': 25}, {'loss': 0.4141, 'grad_norm': 13.652347564697266, 'learning_rate': 2.04e-05, 'epoch': 2.0, 'step': 50}, {'eval_loss': 3.750737428665161, 'eval_rouge/rouge1': 0.3755, 'eval_rouge/rouge2': 0.1223, 'eval_rouge/rougeL': 0.3109, 'eval_rouge/rougeLsum': 0.3103, 'eval_bertscore/bertscore-precision': 0.8953, 'eval_bertscore/bertscore-recall': 0.8701, 'eval_bertscore/bertscore-f1': 0.8824, 'eval_meteor': 0.2852, 'eval_gen_len': 30.5, 'eval_runtime': 3.917, 'eval_samples_per_second': 2.553, 'eval_steps_per_second': 1.276, 'epoch': 2.0, 'step': 50}, {'loss': 0.289, 'grad_norm': 12.835441589355469, 'learning_rate': 1.5399999999999998e-05, 'epoch': 3.0, 'step': 75}, {'eval_loss': 4.050595283508301, 'eval_rouge/rouge1': 0.3232, 'eval_rouge/rouge2': 0.0953, 'eval_rouge/rougeL': 0.2399, 'eval_rouge/rougeLsum': 0.2394, 'eval_bertscore/bertscore-precision': 0.8898, 'eval_bertscore/bertscore-recall': 0.8595, 'eval_bertscore/bertscore-f1': 0.8743, 'eval_meteor': 0.2339, 'eval_gen_len': 24.9, 'eval_runtime': 3.743, 'eval_samples_per_second': 2.672, 'eval_steps_per_second': 1.336, 'epoch': 3.0, 'step': 75}, {'loss': 0.1859, 'grad_norm': 5.502574443817139, 'learning_rate': 1.04e-05, 'epoch': 4.0, 'step': 100}, {'eval_loss': 4.168712615966797, 'eval_rouge/rouge1': 0.4318, 'eval_rouge/rouge2': 0.1652, 'eval_rouge/rougeL': 0.3553, 'eval_rouge/rougeLsum': 0.3535, 'eval_bertscore/bertscore-precision': 0.9049, 'eval_bertscore/bertscore-recall': 0.8714, 'eval_bertscore/bertscore-f1': 0.8877, 'eval_meteor': 0.3246, 'eval_gen_len': 26.1, 'eval_runtime': 3.3791, 'eval_samples_per_second': 2.959, 'eval_steps_per_second': 1.48, 'epoch': 4.0, 'step': 100}, {'loss': 0.1205, 'grad_norm': 5.309665203094482, 'learning_rate': 5.4e-06, 'epoch': 5.0, 'step': 125}, {'eval_loss': 4.419092655181885, 'eval_rouge/rouge1': 0.4106, 'eval_rouge/rouge2': 0.1463, 'eval_rouge/rougeL': 0.3363, 'eval_rouge/rougeLsum': 0.3365, 'eval_bertscore/bertscore-precision': 0.8998, 'eval_bertscore/bertscore-recall': 0.8709, 'eval_bertscore/bertscore-f1': 0.885, 'eval_meteor': 0.3027, 'eval_gen_len': 27.7, 'eval_runtime': 3.708, 'eval_samples_per_second': 2.697, 'eval_steps_per_second': 1.348, 'epoch': 5.0, 'step': 125}]\n11 [{'loss': 0.4589, 'grad_norm': 11.128762245178223, 'learning_rate': 2.54e-05, 'epoch': 1.0, 'step': 25}, {'eval_loss': 3.833491802215576, 'eval_rouge/rouge1': 0.3933, 'eval_rouge/rouge2': 0.1513, 'eval_rouge/rougeL': 0.3247, 'eval_rouge/rougeLsum': 0.3242, 'eval_bertscore/bertscore-precision': 0.9045, 'eval_bertscore/bertscore-recall': 0.8699, 'eval_bertscore/bertscore-f1': 0.8867, 'eval_meteor': 0.3029, 'eval_gen_len': 24.7, 'eval_runtime': 3.2105, 'eval_samples_per_second': 3.115, 'eval_steps_per_second': 1.557, 'epoch': 1.0, 'step': 25}, {'loss': 0.4141, 'grad_norm': 13.652347564697266, 'learning_rate': 2.04e-05, 'epoch': 2.0, 'step': 50}, {'eval_loss': 3.750737428665161, 'eval_rouge/rouge1': 0.3755, 'eval_rouge/rouge2': 0.1223, 'eval_rouge/rougeL': 0.3109, 'eval_rouge/rougeLsum': 0.3103, 'eval_bertscore/bertscore-precision': 0.8953, 'eval_bertscore/bertscore-recall': 0.8701, 'eval_bertscore/bertscore-f1': 0.8824, 'eval_meteor': 0.2852, 'eval_gen_len': 30.5, 'eval_runtime': 3.917, 'eval_samples_per_second': 2.553, 'eval_steps_per_second': 1.276, 'epoch': 2.0, 'step': 50}, {'loss': 0.289, 'grad_norm': 12.835441589355469, 'learning_rate': 1.5399999999999998e-05, 'epoch': 3.0, 'step': 75}, {'eval_loss': 4.050595283508301, 'eval_rouge/rouge1': 0.3232, 'eval_rouge/rouge2': 0.0953, 'eval_rouge/rougeL': 0.2399, 'eval_rouge/rougeLsum': 0.2394, 'eval_bertscore/bertscore-precision': 0.8898, 'eval_bertscore/bertscore-recall': 0.8595, 'eval_bertscore/bertscore-f1': 0.8743, 'eval_meteor': 0.2339, 'eval_gen_len': 24.9, 'eval_runtime': 3.743, 'eval_samples_per_second': 2.672, 'eval_steps_per_second': 1.336, 'epoch': 3.0, 'step': 75}, {'loss': 0.1859, 'grad_norm': 5.502574443817139, 'learning_rate': 1.04e-05, 'epoch': 4.0, 'step': 100}, {'eval_loss': 4.168712615966797, 'eval_rouge/rouge1': 0.4318, 'eval_rouge/rouge2': 0.1652, 'eval_rouge/rougeL': 0.3553, 'eval_rouge/rougeLsum': 0.3535, 'eval_bertscore/bertscore-precision': 0.9049, 'eval_bertscore/bertscore-recall': 0.8714, 'eval_bertscore/bertscore-f1': 0.8877, 'eval_meteor': 0.3246, 'eval_gen_len': 26.1, 'eval_runtime': 3.3791, 'eval_samples_per_second': 2.959, 'eval_steps_per_second': 1.48, 'epoch': 4.0, 'step': 100}, {'loss': 0.1205, 'grad_norm': 5.309665203094482, 'learning_rate': 5.4e-06, 'epoch': 5.0, 'step': 125}, {'eval_loss': 4.419092655181885, 'eval_rouge/rouge1': 0.4106, 'eval_rouge/rouge2': 0.1463, 'eval_rouge/rougeL': 0.3363, 'eval_rouge/rougeLsum': 0.3365, 'eval_bertscore/bertscore-precision': 0.8998, 'eval_bertscore/bertscore-recall': 0.8709, 'eval_bertscore/bertscore-f1': 0.885, 'eval_meteor': 0.3027, 'eval_gen_len': 27.7, 'eval_runtime': 3.708, 'eval_samples_per_second': 2.697, 'eval_steps_per_second': 1.348, 'epoch': 5.0, 'step': 125}, {'loss': 0.0855, 'grad_norm': 7.5415568351745605, 'learning_rate': 4.0000000000000003e-07, 'epoch': 6.0, 'step': 150}]\n12 [{'loss': 0.4589, 'grad_norm': 11.128762245178223, 'learning_rate': 2.54e-05, 'epoch': 1.0, 'step': 25}, {'eval_loss': 3.833491802215576, 'eval_rouge/rouge1': 0.3933, 'eval_rouge/rouge2': 0.1513, 'eval_rouge/rougeL': 0.3247, 'eval_rouge/rougeLsum': 0.3242, 'eval_bertscore/bertscore-precision': 0.9045, 'eval_bertscore/bertscore-recall': 0.8699, 'eval_bertscore/bertscore-f1': 0.8867, 'eval_meteor': 0.3029, 'eval_gen_len': 24.7, 'eval_runtime': 3.2105, 'eval_samples_per_second': 3.115, 'eval_steps_per_second': 1.557, 'epoch': 1.0, 'step': 25}, {'loss': 0.4141, 'grad_norm': 13.652347564697266, 'learning_rate': 2.04e-05, 'epoch': 2.0, 'step': 50}, {'eval_loss': 3.750737428665161, 'eval_rouge/rouge1': 0.3755, 'eval_rouge/rouge2': 0.1223, 'eval_rouge/rougeL': 0.3109, 'eval_rouge/rougeLsum': 0.3103, 'eval_bertscore/bertscore-precision': 0.8953, 'eval_bertscore/bertscore-recall': 0.8701, 'eval_bertscore/bertscore-f1': 0.8824, 'eval_meteor': 0.2852, 'eval_gen_len': 30.5, 'eval_runtime': 3.917, 'eval_samples_per_second': 2.553, 'eval_steps_per_second': 1.276, 'epoch': 2.0, 'step': 50}, {'loss': 0.289, 'grad_norm': 12.835441589355469, 'learning_rate': 1.5399999999999998e-05, 'epoch': 3.0, 'step': 75}, {'eval_loss': 4.050595283508301, 'eval_rouge/rouge1': 0.3232, 'eval_rouge/rouge2': 0.0953, 'eval_rouge/rougeL': 0.2399, 'eval_rouge/rougeLsum': 0.2394, 'eval_bertscore/bertscore-precision': 0.8898, 'eval_bertscore/bertscore-recall': 0.8595, 'eval_bertscore/bertscore-f1': 0.8743, 'eval_meteor': 0.2339, 'eval_gen_len': 24.9, 'eval_runtime': 3.743, 'eval_samples_per_second': 2.672, 'eval_steps_per_second': 1.336, 'epoch': 3.0, 'step': 75}, {'loss': 0.1859, 'grad_norm': 5.502574443817139, 'learning_rate': 1.04e-05, 'epoch': 4.0, 'step': 100}, {'eval_loss': 4.168712615966797, 'eval_rouge/rouge1': 0.4318, 'eval_rouge/rouge2': 0.1652, 'eval_rouge/rougeL': 0.3553, 'eval_rouge/rougeLsum': 0.3535, 'eval_bertscore/bertscore-precision': 0.9049, 'eval_bertscore/bertscore-recall': 0.8714, 'eval_bertscore/bertscore-f1': 0.8877, 'eval_meteor': 0.3246, 'eval_gen_len': 26.1, 'eval_runtime': 3.3791, 'eval_samples_per_second': 2.959, 'eval_steps_per_second': 1.48, 'epoch': 4.0, 'step': 100}, {'loss': 0.1205, 'grad_norm': 5.309665203094482, 'learning_rate': 5.4e-06, 'epoch': 5.0, 'step': 125}, {'eval_loss': 4.419092655181885, 'eval_rouge/rouge1': 0.4106, 'eval_rouge/rouge2': 0.1463, 'eval_rouge/rougeL': 0.3363, 'eval_rouge/rougeLsum': 0.3365, 'eval_bertscore/bertscore-precision': 0.8998, 'eval_bertscore/bertscore-recall': 0.8709, 'eval_bertscore/bertscore-f1': 0.885, 'eval_meteor': 0.3027, 'eval_gen_len': 27.7, 'eval_runtime': 3.708, 'eval_samples_per_second': 2.697, 'eval_steps_per_second': 1.348, 'epoch': 5.0, 'step': 125}, {'loss': 0.0855, 'grad_norm': 7.5415568351745605, 'learning_rate': 4.0000000000000003e-07, 'epoch': 6.0, 'step': 150}, {'eval_loss': 4.402859687805176, 'eval_rouge/rouge1': 0.333, 'eval_rouge/rouge2': 0.0957, 'eval_rouge/rougeL': 0.2725, 'eval_rouge/rougeLsum': 0.2721, 'eval_bertscore/bertscore-precision': 0.8912, 'eval_bertscore/bertscore-recall': 0.8624, 'eval_bertscore/bertscore-f1': 0.8763, 'eval_meteor': 0.252, 'eval_gen_len': 27.3, 'eval_runtime': 3.7231, 'eval_samples_per_second': 2.686, 'eval_steps_per_second': 1.343, 'epoch': 6.0, 'step': 150}]\n13 [{'loss': 0.4589, 'grad_norm': 11.128762245178223, 'learning_rate': 2.54e-05, 'epoch': 1.0, 'step': 25}, {'eval_loss': 3.833491802215576, 'eval_rouge/rouge1': 0.3933, 'eval_rouge/rouge2': 0.1513, 'eval_rouge/rougeL': 0.3247, 'eval_rouge/rougeLsum': 0.3242, 'eval_bertscore/bertscore-precision': 0.9045, 'eval_bertscore/bertscore-recall': 0.8699, 'eval_bertscore/bertscore-f1': 0.8867, 'eval_meteor': 0.3029, 'eval_gen_len': 24.7, 'eval_runtime': 3.2105, 'eval_samples_per_second': 3.115, 'eval_steps_per_second': 1.557, 'epoch': 1.0, 'step': 25}, {'loss': 0.4141, 'grad_norm': 13.652347564697266, 'learning_rate': 2.04e-05, 'epoch': 2.0, 'step': 50}, {'eval_loss': 3.750737428665161, 'eval_rouge/rouge1': 0.3755, 'eval_rouge/rouge2': 0.1223, 'eval_rouge/rougeL': 0.3109, 'eval_rouge/rougeLsum': 0.3103, 'eval_bertscore/bertscore-precision': 0.8953, 'eval_bertscore/bertscore-recall': 0.8701, 'eval_bertscore/bertscore-f1': 0.8824, 'eval_meteor': 0.2852, 'eval_gen_len': 30.5, 'eval_runtime': 3.917, 'eval_samples_per_second': 2.553, 'eval_steps_per_second': 1.276, 'epoch': 2.0, 'step': 50}, {'loss': 0.289, 'grad_norm': 12.835441589355469, 'learning_rate': 1.5399999999999998e-05, 'epoch': 3.0, 'step': 75}, {'eval_loss': 4.050595283508301, 'eval_rouge/rouge1': 0.3232, 'eval_rouge/rouge2': 0.0953, 'eval_rouge/rougeL': 0.2399, 'eval_rouge/rougeLsum': 0.2394, 'eval_bertscore/bertscore-precision': 0.8898, 'eval_bertscore/bertscore-recall': 0.8595, 'eval_bertscore/bertscore-f1': 0.8743, 'eval_meteor': 0.2339, 'eval_gen_len': 24.9, 'eval_runtime': 3.743, 'eval_samples_per_second': 2.672, 'eval_steps_per_second': 1.336, 'epoch': 3.0, 'step': 75}, {'loss': 0.1859, 'grad_norm': 5.502574443817139, 'learning_rate': 1.04e-05, 'epoch': 4.0, 'step': 100}, {'eval_loss': 4.168712615966797, 'eval_rouge/rouge1': 0.4318, 'eval_rouge/rouge2': 0.1652, 'eval_rouge/rougeL': 0.3553, 'eval_rouge/rougeLsum': 0.3535, 'eval_bertscore/bertscore-precision': 0.9049, 'eval_bertscore/bertscore-recall': 0.8714, 'eval_bertscore/bertscore-f1': 0.8877, 'eval_meteor': 0.3246, 'eval_gen_len': 26.1, 'eval_runtime': 3.3791, 'eval_samples_per_second': 2.959, 'eval_steps_per_second': 1.48, 'epoch': 4.0, 'step': 100}, {'loss': 0.1205, 'grad_norm': 5.309665203094482, 'learning_rate': 5.4e-06, 'epoch': 5.0, 'step': 125}, {'eval_loss': 4.419092655181885, 'eval_rouge/rouge1': 0.4106, 'eval_rouge/rouge2': 0.1463, 'eval_rouge/rougeL': 0.3363, 'eval_rouge/rougeLsum': 0.3365, 'eval_bertscore/bertscore-precision': 0.8998, 'eval_bertscore/bertscore-recall': 0.8709, 'eval_bertscore/bertscore-f1': 0.885, 'eval_meteor': 0.3027, 'eval_gen_len': 27.7, 'eval_runtime': 3.708, 'eval_samples_per_second': 2.697, 'eval_steps_per_second': 1.348, 'epoch': 5.0, 'step': 125}, {'loss': 0.0855, 'grad_norm': 7.5415568351745605, 'learning_rate': 4.0000000000000003e-07, 'epoch': 6.0, 'step': 150}, {'eval_loss': 4.402859687805176, 'eval_rouge/rouge1': 0.333, 'eval_rouge/rouge2': 0.0957, 'eval_rouge/rougeL': 0.2725, 'eval_rouge/rougeLsum': 0.2721, 'eval_bertscore/bertscore-precision': 0.8912, 'eval_bertscore/bertscore-recall': 0.8624, 'eval_bertscore/bertscore-f1': 0.8763, 'eval_meteor': 0.252, 'eval_gen_len': 27.3, 'eval_runtime': 3.7231, 'eval_samples_per_second': 2.686, 'eval_steps_per_second': 1.343, 'epoch': 6.0, 'step': 150}, {'train_runtime': 61.1554, 'train_samples_per_second': 4.906, 'train_steps_per_second': 2.453, 'total_flos': 182674788950016.0, 'train_loss': 0.2590131648381551, 'epoch': 6.0, 'step': 150}]\nFinished bart-abs-1109-1149-lr-3e-05-bs-2-maxep-6 time it took for training: 0:01:01.806880\n","output_type":"stream"}]},{"cell_type":"code","source":"def log_csv_wandb(results_path, run_name_model):\n    for root, dirs, files in os.walk(results_path):\n        for file in files:\n            artifact = wandb.Artifact(name=run_name_model, type=\"predictions\")\n            artifact.add_file(local_path=os.path.join(root, file), name=file)\n            wandb.log_artifact(artifact)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:50:58.946350Z","iopub.execute_input":"2024-09-11T11:50:58.946679Z","iopub.status.idle":"2024-09-11T11:50:58.953351Z","shell.execute_reply.started":"2024-09-11T11:50:58.946643Z","shell.execute_reply":"2024-09-11T11:50:58.952203Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"!ls results","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:50:58.955768Z","iopub.execute_input":"2024-09-11T11:50:58.956218Z","iopub.status.idle":"2024-09-11T11:51:00.031373Z","shell.execute_reply.started":"2024-09-11T11:50:58.956170Z","shell.execute_reply":"2024-09-11T11:51:00.030175Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"bart-abs-1109-1147-lr-3e-05-bs-4-maxep-6.csv\nbart-abs-1109-1149-lr-3e-05-bs-2-maxep-6.csv\nbart-abs-1109-1149-lr-3e-05-bs-4-maxep-10.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"log_csv_wandb(os.path.join(os.getcwd(), 'results'), run_name_model)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:51:00.033490Z","iopub.execute_input":"2024-09-11T11:51:00.033945Z","iopub.status.idle":"2024-09-11T11:51:00.726196Z","shell.execute_reply.started":"2024-09-11T11:51:00.033876Z","shell.execute_reply":"2024-09-11T11:51:00.725227Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"print(\"Finished all training and evaluation for\", run_name)\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:51:00.727432Z","iopub.execute_input":"2024-09-11T11:51:00.727805Z","iopub.status.idle":"2024-09-11T11:51:13.379401Z","shell.execute_reply.started":"2024-09-11T11:51:00.727762Z","shell.execute_reply":"2024-09-11T11:51:13.378591Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Finished all training and evaluation for bart-abs-1109-1144\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▄▄▅▅▇▇███▁▁▂▂▄▄▅▅▇▇███▁▁▂▂▄▄▅▅▇▇███</td></tr><tr><td>eval_bertscore/bertscore-f1</td><td>▁▇▅▆▆▄█▅▅▅▇▆▆▅▃▆▆▃</td></tr><tr><td>eval_bertscore/bertscore-precision</td><td>▁█▅▅▅▃▆▄▃▃▄▄▄▂▁▄▃▁</td></tr><tr><td>eval_bertscore/bertscore-recall</td><td>▁▅▃▆▇▅█▅▇▇█▇▇▇▅██▅</td></tr><tr><td>eval_gen_len</td><td>▁▂▂▄▅▄▅▄▆▆▆▅▅█▅▆▇▇</td></tr><tr><td>eval_loss</td><td>▃▂▁▁▁▂▂▃▄▅▅▆▆▅▇▇██</td></tr><tr><td>eval_meteor</td><td>▁▃▂▅▄▄▆▄▇▆▆▆▇▆▄█▇▅</td></tr><tr><td>eval_rouge/rouge1</td><td>▁▃▂▅▅▄▆▃▆▅▆▅▆▆▃█▇▄</td></tr><tr><td>eval_rouge/rouge2</td><td>▂█▆█▅▄▇▄▆▄▄▄▆▃▁▇▅▁</td></tr><tr><td>eval_rouge/rougeL</td><td>▁▃▂▅▅▃▇▄▆▃▆▅▆▅▁█▇▃</td></tr><tr><td>eval_rouge/rougeLsum</td><td>▁▃▂▅▅▃▇▄▆▃▆▅▆▅▁█▇▃</td></tr><tr><td>eval_runtime</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval_samples_per_second</td><td>▁███▇█▇▇▆▇▇▇▇▆▆▆▆▆</td></tr><tr><td>eval_steps_per_second</td><td>▁▆▆▆▆▆▆▆▅▅▅▆█▇▇█▇▇</td></tr><tr><td>grad_norm</td><td>█▆▅▅▆▄▆▆▄▃▂▃▅▇▇▁▁▃</td></tr><tr><td>learning_rate</td><td>█▇▅▄▃▁█▆▅▄▂▁█▆▅▄▂▁</td></tr><tr><td>loss</td><td>█▆▄▄▃▃▃▂▂▁▁▁▂▂▁▁▁▁</td></tr><tr><td>step</td><td>▁▁▂▂▂▂▃▃▄▄▄▄▄▁▁▂▂▂▂▃▃▄▄▄▄▄▂▂▃▃▄▄▅▅▇▇███</td></tr><tr><td>total_flos</td><td>██▁</td></tr><tr><td>train_loss</td><td>█▂▁</td></tr><tr><td>train_runtime</td><td>█▁▃</td></tr><tr><td>train_samples_per_second</td><td>▁█▅</td></tr><tr><td>train_steps_per_second</td><td>▁▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>6.0</td></tr><tr><td>eval_bertscore/bertscore-f1</td><td>0.8763</td></tr><tr><td>eval_bertscore/bertscore-precision</td><td>0.8912</td></tr><tr><td>eval_bertscore/bertscore-recall</td><td>0.8624</td></tr><tr><td>eval_gen_len</td><td>27.3</td></tr><tr><td>eval_loss</td><td>4.40286</td></tr><tr><td>eval_meteor</td><td>0.252</td></tr><tr><td>eval_rouge/rouge1</td><td>0.333</td></tr><tr><td>eval_rouge/rouge2</td><td>0.0957</td></tr><tr><td>eval_rouge/rougeL</td><td>0.2725</td></tr><tr><td>eval_rouge/rougeLsum</td><td>0.2721</td></tr><tr><td>eval_runtime</td><td>3.7231</td></tr><tr><td>eval_samples_per_second</td><td>2.686</td></tr><tr><td>eval_steps_per_second</td><td>1.343</td></tr><tr><td>grad_norm</td><td>7.54156</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>loss</td><td>0.0855</td></tr><tr><td>run_name</td><td>bart-abs-1109-1149-l...</td></tr><tr><td>step</td><td>150</td></tr><tr><td>total_flos</td><td>182674788950016.0</td></tr><tr><td>train_loss</td><td>0.25901</td></tr><tr><td>train_runtime</td><td>61.1554</td></tr><tr><td>train_samples_per_second</td><td>4.906</td></tr><tr><td>train_steps_per_second</td><td>2.453</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">bart-abs-1109-1144</strong> at: <a href='https://wandb.ai/dawidk5ul/aiml-thesis-train-test-temp/runs/bart-abs-1109-1144' target=\"_blank\">https://wandb.ai/dawidk5ul/aiml-thesis-train-test-temp/runs/bart-abs-1109-1144</a><br/> View project at: <a href='https://wandb.ai/dawidk5ul/aiml-thesis-train-test-temp' target=\"_blank\">https://wandb.ai/dawidk5ul/aiml-thesis-train-test-temp</a><br/>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240911_114427-bart-abs-1109-1144/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."},"metadata":{}}]},{"cell_type":"code","source":"print(\"Results uploaded\")","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:51:13.380706Z","iopub.execute_input":"2024-09-11T11:51:13.381195Z","iopub.status.idle":"2024-09-11T11:51:13.386200Z","shell.execute_reply.started":"2024-09-11T11:51:13.381149Z","shell.execute_reply":"2024-09-11T11:51:13.385322Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Results uploaded\n","output_type":"stream"}]}]}