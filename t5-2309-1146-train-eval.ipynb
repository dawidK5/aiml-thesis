{"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9040667,"sourceType":"datasetVersion","datasetId":5430249},{"sourceId":9140997,"sourceType":"datasetVersion","datasetId":5507948}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"09513166db494a318fe4bd2ff4fe8b73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bad09d132dcc420fbad7ace8cc25aa06","placeholder":"​","style":"IPY_MODEL_20787ae61e94452aae73869c5382ff1b","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"19649549a1ad47368ec9f6eeba1e80ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20787ae61e94452aae73869c5382ff1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25bd97f157d8485fb15438d25d83421c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c792771c4604d9b8f6bcda700f2ad74","placeholder":"​","style":"IPY_MODEL_36781c62f1164acabc7371ceb966e8cc","value":"Token is valid (permission: write)."}},"26b0af06bf1549bd8f16e297a3d5c4fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34efbeb9bdcf42b28bcfdf48289bb943":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36781c62f1164acabc7371ceb966e8cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3bd1b8a5cbdf4345b34a6042ad3c6383":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d0bb7ba88104e458caaaf9c72914b97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44d30b0ecad54f818f27bbd1858cdf3f","placeholder":"​","style":"IPY_MODEL_85e73a9905ba41c286b0645f0c667362","value":"Login successful"}},"44d30b0ecad54f818f27bbd1858cdf3f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5685a3fe6b084791b1c41bede0ee8429":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5764ccc3c9b943ac9031bb4fbf65ee84":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dcb4bd1b7424f698dcfe1586ecaaa87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7393008614c94b7f9aee294715d1f9c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6eb7b2e427a4fb3b984a0346394555a","placeholder":"​","style":"IPY_MODEL_34efbeb9bdcf42b28bcfdf48289bb943","value":"Your token has been saved in your configured git credential helpers (store)."}},"7b5d107e75ec4226b2f951fa5eac32c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"85e73a9905ba41c286b0645f0c667362":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c792771c4604d9b8f6bcda700f2ad74":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91cf6c949361472e8cdc02a27371892b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"PasswordModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_5764ccc3c9b943ac9031bb4fbf65ee84","placeholder":"​","style":"IPY_MODEL_f6f5badeb1f749d8a1a74c737ea45b81","value":""}},"9d286f232614404eac3e78415a823171":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26b0af06bf1549bd8f16e297a3d5c4fa","placeholder":"​","style":"IPY_MODEL_b289ce6929414af38bd4cd4ddf68bfe4","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"a6333daeaf584192b2d8222134dc02a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb0ffca70a4645458b4650ff588f82cc","placeholder":"​","style":"IPY_MODEL_fec956e2f3ac4760a951569986ebb5c2","value":"Your token has been saved to /root/.cache/huggingface/token"}},"b289ce6929414af38bd4cd4ddf68bfe4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b292b711914d4f14abd2436aeb8050f8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3bfd48d65b748349afd7e3e5000baff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"b6eb7b2e427a4fb3b984a0346394555a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bad09d132dcc420fbad7ace8cc25aa06":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcab8a3e3c3f45d48890e88d50d8e982":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_b292b711914d4f14abd2436aeb8050f8","style":"IPY_MODEL_b3bfd48d65b748349afd7e3e5000baff","tooltip":""}},"c42b74a51b7843c7b8a9fca7d90bfd1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19649549a1ad47368ec9f6eeba1e80ff","placeholder":"​","style":"IPY_MODEL_3bd1b8a5cbdf4345b34a6042ad3c6383","value":"Connecting..."}},"d1a558c379ac48cc80c19ef9898d871d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_25bd97f157d8485fb15438d25d83421c","IPY_MODEL_7393008614c94b7f9aee294715d1f9c8","IPY_MODEL_a6333daeaf584192b2d8222134dc02a9","IPY_MODEL_3d0bb7ba88104e458caaaf9c72914b97"],"layout":"IPY_MODEL_7b5d107e75ec4226b2f951fa5eac32c7"}},"dbbfbb222a7d4ce18c1c7b655fc89ae1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"CheckboxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_5685a3fe6b084791b1c41bede0ee8429","style":"IPY_MODEL_6dcb4bd1b7424f698dcfe1586ecaaa87","value":true}},"f6f5badeb1f749d8a1a74c737ea45b81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb0ffca70a4645458b4650ff588f82cc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fec956e2f3ac4760a951569986ebb5c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Abstractive summaries - Train Distilt5 on TWEETSUMM dataset","metadata":{"id":"AvCot6IFw3LG"}},{"cell_type":"code","source":"from huggingface_hub import login\nimport pandas as pd\nimport numpy as np\nimport os, time, datetime, shutil\n\nfrom datasets import Dataset, DatasetDict\n\nfrom transformers import DataCollatorForSeq2Seq, AutoTokenizer, set_seed\nfrom transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\nfrom transformers import TrainerCallback, TrainingArguments, TrainerState, TrainerControl\n\nimport wandb","metadata":{"id":"csIsnw2147iB","outputId":"b1168797-2e98-4a6a-81e1-9e079f98ab53","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip freeze > requirements_t5.txt","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_current_time(underscore=False):\n    return datetime.datetime.now().strftime(\"%d%m-%H%M\" if not underscore else \"%d%m_%H%M\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_name = f\"t5-abs-{get_current_time()}\"\nmodels_dir = os.path.join(os.getcwd(), 'models')\nos.makedirs(models_dir, exist_ok=True)\nresults_dir = os.path.join(os.getcwd(), 'results', 't5')\nos.makedirs(results_dir, exist_ok=True)\nds_dir = os.path.join(os.getcwd(), 'data')\nprint(run_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    HF_TOKEN =  os.environ['HF_TOKEN']\nexcept:\n    HF_TOKEN = \"\"\n\nif 'google.colab' in str(get_ipython()):\n    print(\"Running on Colab\")\n    from google.colab import drive, userdata\n    drive.mount('/content/drive')\n    HF_TOKEN = userdata.get('HF_TOKEN')\nelif os.environ.get('KAGGLE_KERNEL_RUN_TYPE') != None:\n    ds_dir = '/kaggle/input/bertdata2207/'\n    from kaggle_secrets import UserSecretsClient\n    print(\"Running on Kaggle\")\n    user_secrets = UserSecretsClient()\n    HF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")\n    WANDB_API_KEY = user_secrets.get_secret(\"WANDB_API_KEY\")\n    os.environ['WANDB_API_KEY'] = WANDB_API_KEY\n    os.makedirs(os.path.join(os.getcwd(), \"results\"), exist_ok=True)\n    os.makedirs(os.path.join(os.getcwd(), 'results', 't5'), exist_ok=True)\n","metadata":{"id":"D7StYsAaxJLT","outputId":"3690cf47-554a-424d-b42e-e8f77bb4bbf5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seed(17)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ[\"WANDB_PROJECT\"] = f\"aiml-thesis-train-{run_name}\"\nos.environ[\"WANDB_WATCH\"] = \"false\"\nwandb.init(settings=wandb.Settings(start_method=\"thread\"), id=run_name)","metadata":{"id":"XCVrFPA4GL-h","outputId":"228dbbaf-c276-495e-e759-0ecb0b4a1ebb","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"login(token=HF_TOKEN)","metadata":{"id":"QoMm76b2i2NX","outputId":"f5df06b4-ac4d-4be9-8044-20010745149b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load data","metadata":{"id":"xP2HgEaKi2Nk"}},{"cell_type":"code","source":"print(ds_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_t5 = \"google-t5/t5-base\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def csv_to_pandas(file_name, ds_dir, drop_conv_id=True):\n    df = pd.read_csv(os.path.join(ds_dir, file_name), names=['conv_id', 'dialogue', 'summary'], encoding='utf-8', dtype={'conv_id': 'string', 'dialogue': 'string', 'summary': 'string'})\n    df = df.convert_dtypes()\n    if drop_conv_id:\n        df.drop(columns=['conv_id'], inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_temp = csv_to_pandas(\"dials_abs_2607_1312_train_spc.csv\", ds_dir)\nval_df_temp = csv_to_pandas(\"dials_abs_2607_1312_valid_spc.csv\", ds_dir)\ntest_df = csv_to_pandas(\"dials_abs_2607_1312_test_spc.csv\", ds_dir, drop_conv_id=False)\n\nprint(train_df_temp.dtypes)\nprint(train_df_temp.head(), len(train_df_temp))","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweetsumm_abs = DatasetDict(\n    {\n        'train': Dataset.from_pandas(train_df_temp),\n        'validation': Dataset.from_pandas(val_df_temp),\n        'test': Dataset.from_pandas(test_df)\n    }\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(checkpoint_t5)\nprint(tokenizer)","metadata":{"id":"F-hzIHQ9w3Lb","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Source: https://huggingface.co/docs/transformers/en/tasks/summarization\n\ndef preprocess_function(examples):\n    prefix = \"summarize: \"\n    inputs = [str(prefix) + str(dial) for dial in examples[\"dialogue\"]]\n    model_inputs = tokenizer(inputs, max_length=512, truncation=True) # same params as tweetsumm paper\n    labels = tokenizer(text_target=examples[\"summary\"], max_length=80, truncation=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"id":"vVQdGPfZw3Lb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_tweetsumm_abs = tweetsumm_abs.map(preprocess_function, batched=True, remove_columns=['dialogue','summary'])\nprint(tokenized_tweetsumm_abs[\"train\"][1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setup Training Evaluation","metadata":{"id":"97ha331Ii2Np"}},{"cell_type":"code","source":"!pip install -U nltk","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install evaluate pyrouge rouge_score bert_score meteor","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import evaluate, nltk, csv\nrouge = evaluate.load(\"rouge\")\nmeteor = evaluate.load(\"meteor\")\nbertscore = evaluate.load(\"bertscore\")\n\nnltk.download('punkt_tab')","metadata":{"id":"dHQv7Aeai2Nr","outputId":"6c4222bd-bf8f-4588-9871-716bd2cee0ca","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_metrics_abs(eval_pred):\n    predictions, labels = eval_pred\n    # Extra line added to address an overflow: https://github.com/huggingface/transformers/issues/22634\n    predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n\n    rouge_scores = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n    bert_scores = bertscore.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")\n    bert_scores.pop('hashcode')\n    result = {\n      **{f\"rouge/{k}\": round(v, 4) for k,v in rouge_scores.items()},\n      **{f\"bertscore/bertscore-{k}\": round(np.mean(v), 4) for k,v in bert_scores.items()},\n      'meteor': round(meteor.compute(predictions=decoded_preds, references=decoded_labels)['meteor'], 4),\n    }\n   \n    result[\"gen_len\"] = np.mean(prediction_lens)\n    return result\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train and Evaluate","metadata":{"id":"4W_3h_eHi2Nu"}},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint_t5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)","metadata":{"id":"irJUvr6gi2No","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EXPERIMENT_PARAMS = []\nBASE_PARAMS = {'lr':1e-4, 'batch_size':10, 'epochs': 20}\nEXPERIMENT_PARAMS.append(BASE_PARAMS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LEARN_RATES = (1e-3, 1e-4, 1e-5)\nBATCH_SIZES = (2,5,10)\nEPOCHS = (20,)\n\nfor lr in LEARN_RATES:\n    for batch_size in BATCH_SIZES:\n        for epoch in EPOCHS:\n            if lr == BASE_PARAMS['lr'] and batch_size == BASE_PARAMS['batch_size'] and epoch == BASE_PARAMS['epochs']:\n                continue\n            experiment = {'lr':lr, 'batch_size':batch_size, 'epochs': epoch}\n            EXPERIMENT_PARAMS.append(experiment)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_post_training(split, test_details, test_df_temp: pd.DataFrame, tokenizer, experiment, run_name_model, epoch, results_dir):\n    # First line added due to label error, see \n    predictions = np.where(test_details.predictions != -100, test_details.predictions, tokenizer.pad_token_id)\n    preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    test_df_temp['response'] = preds\n    exp_res = {**experiment, **(test_details.metrics)}\n    test_metrics_df = pd.DataFrame([exp_res])\n    test_df_temp = test_df_temp.convert_dtypes()\n    test_metrics_df = test_metrics_df.convert_dtypes()\n    wandb.log({run_name_model: test_details.metrics})\n    preds_name = f\"{split}_preds_{run_name_model.replace('-','_')}_s{epoch}_t5.csv\"\n    metrics_name =  f\"{split}_metrics_{run_name_model.replace('-','_')}_s{epoch}_t5.csv\"\n    test_df_temp.to_csv(os.path.join(results_dir, preds_name), index=False, header=False, encoding='utf-8', quoting=csv.QUOTE_ALL)\n    test_metrics_df.to_csv(os.path.join(results_dir, metrics_name), index=False, header=True, encoding='utf-8', quoting=csv.QUOTE_ALL)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ExtraCallback(TrainerCallback):        \n    def on_train_end(self, args, state, control, **kwargs):\n        # Save and upload CSVs\n        super().on_train_end(args, state, control, **kwargs)\n        df = pd.DataFrame(state.log_history)\n        df = df.convert_dtypes()\n        df = df.groupby(['epoch'], as_index=False).sum()\n        df.to_csv(os.path.join(results_dir, \"log_\" + args.run_name.replace('-','_') + \".csv\"), header=True, index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for count, exp in enumerate(EXPERIMENT_PARAMS):\n    run_name_model = f\"{run_name}-lr-{exp['lr']}-bs-{exp['batch_size']}-maxep-{exp['epochs']}\"\n    print(\"=== Starting experiment\", count, f\"on {get_current_time()}:\", run_name_model, \"training\")\n    wandb.run.name = run_name_model\n    wandb.run.save()\n\n    training_args = Seq2SeqTrainingArguments(\n        output_dir=os.path.join(models_dir, run_name_model),\n        eval_strategy=\"epoch\",\n        logging_strategy=\"epoch\",\n        save_only_model=True,\n        learning_rate=exp['lr'],\n        per_device_train_batch_size=exp['batch_size'],\n        per_device_eval_batch_size=exp['batch_size'],\n        weight_decay=0.0,\n        lr_scheduler_type='linear',\n        warmup_ratio=0.1,\n        gradient_accumulation_steps=2,\n        save_strategy=\"epoch\",\n        save_total_limit=1,\n        load_best_model_at_end=True,\n        metric_for_best_model=\"eval_rouge/rougeL\",\n        greater_is_better=True,\n        num_train_epochs=exp['epochs'],\n        predict_with_generate=True,\n        fp16=True,\n        generation_max_length=80,\n        push_to_hub=False,\n        report_to=\"wandb\",\n        run_name=run_name_model,\n    )\n    trainer = Seq2SeqTrainer(\n        model=model,\n        args=training_args,\n        train_dataset=tokenized_tweetsumm_abs[\"train\"], # .select(range(0,50)),\n        eval_dataset=tokenized_tweetsumm_abs[\"validation\"], # .select(range(0,10)),\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics_abs,\n    )\n    trainer.add_callback(ExtraCallback)\n    training_start = time.time()\n    trainer.train()\n    training_end = time.time()\n    print(f\"Finished experiment {count}: {run_name_model} - time it took for training:\", str(datetime.timedelta(seconds=(training_end-training_start))))\n    test_details = trainer.predict(tokenized_tweetsumm_abs['test'], metric_key_prefix='test')\n    run_post_training('test', test_details, test_df, tokenizer, exp, run_name_model, trainer.state.best_model_checkpoint.split('-')[-1], results_dir)\n    trainer.push_to_hub()\n    shutil.rmtree(models_dir)\n    os.makedirs(models_dir)","metadata":{"id":"nj5v3nT9i2Nw","outputId":"512d759b-0343-4f83-e36c-cf15fec503a3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using wandb documentation: https://docs.wandb.ai/guides/artifacts\ndef log_csv_wandb(results_path, model_name):\n    artifact = wandb.Artifact(name=model_name, type=\"predictions\")\n    for root, dirs, files in os.walk(results_path):\n        for file in files:\n            artifact.add_file(local_path=os.path.join(root, file), name=file)\n    wandb.log_artifact(artifact)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_csv_wandb(results_dir, run_name)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Finished all training and evaluation for\", run_name)\nwandb.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Results uploaded\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}